<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/site.jpg"><link rel="icon" href="/img/site.jpg"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content=""><meta name="author" content="John Doe"><meta name="keywords" content=""><meta name="description" content="1.文章来源Matt Scarpino Crunching Numbers with AVX and AVX2 - CodeProject 2.介绍在2003年，Alex Fr写了一篇优秀的文章[该文章现在已经被原作者删除]，解释了如何使用Intel的流式SIMD扩展(SSE)执行SIMD(单指令，多数据)处理。SSE是英特尔处理器支持的一组指令，可对大量数据执行高速运算。 2008年，英特尔推出"><meta property="og:type" content="article"><meta property="og:title" content="如何使用AVX和AVX2处理数据(个人翻译)[未完成]"><meta property="og:url" content="http://example.com/2023/01/28/avx006/index.html"><meta property="og:site_name" content="Amicoyuan"><meta property="og:description" content="1.文章来源Matt Scarpino Crunching Numbers with AVX and AVX2 - CodeProject 2.介绍在2003年，Alex Fr写了一篇优秀的文章[该文章现在已经被原作者删除]，解释了如何使用Intel的流式SIMD扩展(SSE)执行SIMD(单指令，多数据)处理。SSE是英特尔处理器支持的一组指令，可对大量数据执行高速运算。 2008年，英特尔推出"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://example.com/2023/01/28/avx006/image-20230129153048825.png"><meta property="article:published_time" content="2023-01-28T06:51:44.000Z"><meta property="article:modified_time" content="2023-02-04T14:05:51.992Z"><meta property="article:author" content="John Doe"><meta property="article:tag" content="AVX"><meta property="article:tag" content="AVX2"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://example.com/2023/01/28/avx006/image-20230129153048825.png"><title>如何使用AVX和AVX2处理数据(个人翻译)[未完成] - Amicoyuan</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/androidstudio.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"example.com",root:"/",version:"1.8.12",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"g10sppACiB0iwBrOiERhucmg-MdYXbMMI",app_key:"f7eskymhpDIBDrODMFqlWwQU",server_url:null,path:"window.location.pathname"}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body><header style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Amicoyuan</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/tools/"><i class="iconfont icon-playstation-fill"></i> 工具</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="如何使用AVX和AVX2处理数据(个人翻译)[未完成]"></span><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-01-28 14:51" pubdate>2023年1月28日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 7k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 22 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">如何使用AVX和AVX2处理数据(个人翻译)[未完成]</h1><div class="markdown-body"><h2 id="1-文章来源"><a href="#1-文章来源" class="headerlink" title="1.文章来源"></a>1.文章来源</h2><p><strong>Matt Scarpino</strong></p><p><a target="_blank" rel="noopener" href="https://www.codeproject.com/Articles/874396/Crunching-Numbers-with-AVX-and-AVX">Crunching Numbers with AVX and AVX2 - CodeProject</a></p><h2 id="2-介绍"><a href="#2-介绍" class="headerlink" title="2.介绍"></a>2.介绍</h2><p>在2003年，<a target="_blank" rel="noopener" href="https://www.codeproject.com/script/Membership/View.aspx?mid=22834">Alex Fr</a>写了一篇优秀的<a target="_blank" rel="noopener" href="https://www.codeproject.com/Articles/4522/Introduction-to-SSE-Programming">文章</a>[该文章现在已经被原作者删除]，解释了如何使用Intel的流式SIMD扩展(SSE)执行SIMD(单指令，多数据)处理。SSE是英特尔处理器支持的一组指令，可对大量数据执行高速运算。</p><p>2008年，英特尔推出了一套新的高性能指令，称为高级向量扩展(AVX)。AVX执行许多与SSE指令相同的操作，但以更快的速度对更大的数据块进行操作。最近，英特尔在AVX2和AVX512系列中发布了额外的指令。本文的重点是通过称为intrinsic funtions的特殊C函数访问AVX和AVX2指令。</p><p>本文不介绍整个AVX&#x2F;AVX2 intrinsics，而是侧重于数学计算。特别地，目标是复数相乘。要使用AVX&#x2F;AVX2执行此操作，需要三种类型的intrinsic:</p><ol><li>Initialization intrinscis</li><li>Arithmetic intrinsics</li><li>Permute&#x2F;shuffle intrinsics</li></ol><p></p><p>本文讨论每个类别中的intrinsics，并解释如何在代码中使用它们。本文的最后将展示如何用这些intrinsic进行乘法复数运算。</p><p>理解处理器指令和intrinsic function之间的区别是很重要的。AVX指令是执行不可分割操作的汇编命令。例如，AVX指令vaddps添加了两个操作数，并将结果放在第三个操作数中。</p><p>要在C&#x2F;C++中执行操作，the intrinsic funtion _mm256_add_ps()直接映射到vaddps，将汇编的性能与高级函数的便利性结合起来。An intrinsic funtion不一定映射到单个指令，但与其他C&#x2F; C++函数相比，AVX&#x2F;AVX2 intrinsics提供了可靠的高性能。</p><h2 id="3-基本要求"><a href="#3-基本要求" class="headerlink" title="3.基本要求"></a>3.基本要求</h2><p>要理解本文的内容，您需要基本熟悉C语言和SIMD处理。要执行代码，您需要一个支持AVX或AVX&#x2F;AVX2的CPU。以下是支持AVX的cpu:</p><ul><li>Intel’s Sandy Bridge&#x2F;Sandy Bridge E&#x2F;Ivy Bridge&#x2F;Ivy Bridge E</li><li>Intel’s Haswell&#x2F;Haswell E&#x2F;Broadwell&#x2F;Broadwell E</li><li>AMD’s Bulldozer&#x2F;Piledriver&#x2F;Steamroller&#x2F;Excavator</li></ul><p>支持AVX2的CPU也支持AVX。以下是这些设备:</p><ul><li>Intel’s Haswell&#x2F;Haswell E&#x2F;Broadwell&#x2F;Broadwell E</li><li>AMD’s Excavator</li></ul><p>本文中讨论的大多数函数都是由AVX提供的。但也有一些是AVX2特有的。为了区分它们，在本文的表中，我在AVX2 intrinsic的名称前面加上(2)。</p><p>[个人补充]</p><p>判断自己电脑CPU是否支持AVX和AVX2，最简单的就是在命令行执行以下命令：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">lscpu<br></code></pre></div></td></tr></table></figure><p>你会得到以下结果：</p><p><img src="/2023/01/28/avx006/image-20230129153048825.png" srcset="/img/loading.gif" lazyload alt="image-20230129153048825"></p><p>在Flags里面你可以清楚的看到你的电脑是否支持AVX以及AVX2。</p><h2 id="4-向量化概述"><a href="#4-向量化概述" class="headerlink" title="4.向量化概述"></a>4.向量化概述</h2><p>AVX指令通过同时处理大块值而不是单独处理值来提高应用程序的性能。这些值块称为向量，AVX向量最多可以包含256位数据。</p><p>常见的AVX向量包含4个double (4 x 64位&#x3D; 256)，8个float (8 x 32位&#x3D; 256)或8个int (8 x 32位&#x3D; 256)。[double 8B, flout 4B, int 4B]</p><p>一个示例将演示AVX&#x2F;AVX2处理的强大功能。假设一个函数需要将一个数组的8个浮点数乘以第二个数组的8个浮点数，并将结果添加到第三个数组。如果没有向量化，函数可能是这样的:</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-built_in">multiply_and_add</span>(<span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span>* a, <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span>* b, <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span>* c, <span class="hljs-keyword">float</span>* d) &#123;  <br><br>  <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;<span class="hljs-number">8</span>; i++) &#123;<br>    d[i] = a[i] * b[i];<br>    d[i] = d[i] + c[i];<br>  &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>下面是使用AVX2函数的例子:</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-function">__m256 <span class="hljs-title">multiply_and_add</span><span class="hljs-params">(__m256 a, __m256 b, __m256 c)</span> </span>&#123;<br><br>  <span class="hljs-keyword">return</span> _mm256_fmadd_ps(a, b, c);<br>&#125;<br></code></pre></div></td></tr></table></figure><p>This AVX2 intrinsic funtion _mm256_fmadd_ps处理24个floats，但它不映射到单个指令。相反，它执行三个指令:vfmadd132ps、vfmadd213ps和vfmadd231ps。尽管如此，它执行得很快，比遍历单个元素快得多。尽管英特尔的intrinsics功能强大，但它们还是让许多程序员感到紧张。这通常有两个原因。首先，数据类型有奇怪的名字，比如__m256。其次，函数有奇怪的名称，如_mm256_fmadd_ps。因此，在详细讨论intrinsic funtions之前，我想先讨论一下Intel的数据类型和命名约定。</p><h2 id="5-AVX编程基础"><a href="#5-AVX编程基础" class="headerlink" title="5.AVX编程基础"></a>5.AVX编程基础</h2><p>本文主要关注AVX和AVX2提供的与数学相关的intrinsic functions。但在看函数之前，有三点很重要:</p><ul><li>Data types</li><li>Function naming conventions</li><li>Compiling AVX applications</li></ul><p>本节涉及这些要点，并提供一个简单的应用程序，用于从一个向量减去另一个向量。</p><h3 id="5-1数据类型"><a href="#5-1数据类型" class="headerlink" title="5.1数据类型"></a>5.1数据类型</h3><p>少数intrinsic接受传统的数据类型，如ints或floats，但大多数intrinsic操作有特定的AVX和AVX2的数据类型。有六种主要的向量类型，表1列出了它们。</p><p><strong>Table 1:AVX&#x2F;AVX2 Data Types</strong></p><table><thead><tr><th>Data Type</th><th>Description</th></tr></thead><tbody><tr><td><code>__m128</code></td><td>128-bit vector containing 4 <code>float</code>s</td></tr><tr><td><code>__m128d</code></td><td>128-bit vector containing 2 <code>double</code>s</td></tr><tr><td><code>__m128i</code></td><td>128-bit vector containing integers</td></tr><tr><td><code>__m256</code></td><td>256-bit vector containing 8 <code>float</code>s</td></tr><tr><td><code>__m256d</code></td><td>256-bit vector containing 4 <code>double</code>s</td></tr><tr><td><code>__m256i</code></td><td>256-bit vector containing integers</td></tr></tbody></table><p>每种类型都以两个下划线、一个m和向量的宽度(以位为单位)开始。AVX512支持以_m512开头的512位向量类型，但AVX&#x2F;AVX2向量不超过256位。如果向量类型以d结尾，则代表double，如果没有后缀，则代表float。看起来_m128i和_m256i向量必须包含int型，但事实并非如此。整数向量类型可以包含任何类型的整数，from chars to shorts to unsigned long longs.That is, an _m256i may contain 32 chars, 16 shorts, 8 ints, or 4 longs. These integers can be signed or unsigned.</p><h3 id="5-3函数命名约定"><a href="#5-3函数命名约定" class="headerlink" title="5.3函数命名约定"></a>5.3函数命名约定</h3><p>AVX&#x2F;AVX2 intrinsics的名称一开始可能令人困惑，但命名约定确是非常直白的。一旦你理解了它，你就可以通过看它的名字来大致判断一个函数是做什么的。AVX&#x2F;AVX2 intrinsics的一般形式如下:</p><p>_mm<bit_width>_<name>_<data_type></data_type></name></bit_width></p><p>该格式的各部分如下所示:</p><ol><li><code>&lt;bit_width&gt;</code> identifies the size of the vector returned by the function. For 128-bit vectors, this is empty. For 256-bit vectors, this is set to <code>256</code>.</li><li><code>&lt;name&gt;</code> describes the operation performed by the intrinsic</li><li><code>&lt;data_type&gt;</code> identifies the data type of the function’s primary arguments</li></ol><p>最后一部分<data_type>有点复杂。它标识输入值的内容，可以设置为以下任何值:</data_type></p><ul><li><code>ps</code> - vectors contain <code>float</code>s (<code>ps</code> stands for packed single-precision)</li><li><code>pd</code> - vectors contain <code>double</code>s (<code>pd</code> stands for packed double-precision)</li><li><code>epi8/epi16/epi32/epi64</code> - vectors contain 8-bit&#x2F;16-bit&#x2F;32-bit&#x2F;64-bit signed integers</li><li><code>epu8/epu16/epu32/epu64</code> - vectors contain 8-bit&#x2F;16-bit&#x2F;32-bit&#x2F;64-bit unsigned integers</li><li><code>si128</code>&#x2F;<code>si256</code> - unspecified 128-bit vector or 256-bit vector</li><li><code>m128/m128i/m128d/m256/m256i/m256d</code> - identifies input vector types when they’re different than the type of the returned vector</li></ul><p>例如，考虑_mm256_srlv_epi64。即使您不知道srlv是什么意思，_mm256前缀告诉您该函数返回一个256位向量，_epi64告诉您参数包含64位有符号整数。</p><p>作为第二个示例，考虑_mm_testnzc_ps。_mm表示函数返回一个128位的向量。末尾的_ps表示参数向量包含浮点数。</p><p>AVX数据类型以两个下划线和一个m开头。函数以一个下划线和两个ms开头。我很容易搞混这一点，所以我想出了一种方法来记住它们的区别:数据类型代表内存，函数代表多媒体操作。这是我能做的最好的了。</p><h3 id="5-4构建AVX应用程序"><a href="#5-4构建AVX应用程序" class="headerlink" title="5.4构建AVX应用程序"></a>5.4构建AVX应用程序</h3><p>要构建使用AVX intrinsic的应用程序，不需要链接任何库。但是您需要包含imminrin .h头文件。此头文件包括将AVX&#x2F;AVX2函数映射到指令的其他头文件。</p><p>hello_avx.c中的代码显示了一个基本的AVX应用程序的样子:</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;immintrin.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdio.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br><br>  <span class="hljs-comment">/* Initialize the two argument vectors */</span>			<span class="hljs-comment">//初始化</span><br>  __m256 evens = _mm256_set_ps(<span class="hljs-number">2.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">6.0</span>, <span class="hljs-number">8.0</span>, <span class="hljs-number">10.0</span>, <span class="hljs-number">12.0</span>, <span class="hljs-number">14.0</span>, <span class="hljs-number">16.0</span>);<br>  __m256 odds = _mm256_set_ps(<span class="hljs-number">1.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">7.0</span>, <span class="hljs-number">9.0</span>, <span class="hljs-number">11.0</span>, <span class="hljs-number">13.0</span>, <span class="hljs-number">15.0</span>);<br><br>  <span class="hljs-comment">/* Compute the difference between the two vectors */</span><br>  __m256 result = _mm256_sub_ps(evens, odds);			<span class="hljs-comment">//减法</span><br><br>  <span class="hljs-comment">/* Display the elements of the result vector */</span><br>  <span class="hljs-keyword">float</span>* f = (<span class="hljs-keyword">float</span>*)&amp;result;					<span class="hljs-comment">//类型转换</span><br>  <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%f %f %f %f %f %f %f %f\n&quot;</span>,<br>    f[<span class="hljs-number">0</span>], f[<span class="hljs-number">1</span>], f[<span class="hljs-number">2</span>], f[<span class="hljs-number">3</span>], f[<span class="hljs-number">4</span>], f[<span class="hljs-number">5</span>], f[<span class="hljs-number">6</span>], f[<span class="hljs-number">7</span>]);<br><br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>要构建应用程序，需要告诉编译器该体系结构支持AVX。这个标志取决于编译器，gcc需要-mavx标志。因此，可以使用以下命令编译hello_avx.c源文件:</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">gcc -mavx -o hello_avx hello_avx.c<br></code></pre></div></td></tr></table></figure><p>在本例中，所有函数都以_mm256开始，以_ps结束，因此我希望所有操作都清楚地涉及包含floats的256位向量。我还希望结果向量中的每个元素都等于1.0。如果运行应用程序，您将看到情况就是这样。</p><h3 id="5-5初始化intrinsics"><a href="#5-5初始化intrinsics" class="headerlink" title="5.5初始化intrinsics"></a>5.5初始化intrinsics</h3><p>在对AVX向量进行操作之前，需要用数据填充向量。因此，本文讨论的第一组intrinsics用数据初始化向量。有两种方法:用标量值初始化向量和用从内存加载的数据初始化向量。</p><h4 id="5-5-4使用标量值初始化"><a href="#5-5-4使用标量值初始化" class="headerlink" title="5.5.4使用标量值初始化"></a>5.5.4使用标量值初始化</h4><p>AVX提供了将一个或多个值组合成256位向量的intrinsics funtions。表2列出了它们的名称，并提供了每个名称的描述。也有类似的intrinsics初始化128位向量，但它们是由SSE提供的，而不是AVX。函数名的唯一区别是_mm256_被替换为_mm_。</p><p><strong>Table 2: Initialization Intrinsics</strong></p><table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody><tr><td><code>_mm256_setzero_ps/pd</code></td><td>Returns a floating-point vector filled with zeros</td></tr><tr><td><code>_mm256_setzero_si256</code></td><td>Returns an integer vector whose bytes are set to zero</td></tr><tr><td><code>_mm256_set1_ps/pd</code></td><td>Fill a vector with a floating-point value</td></tr><tr><td><code>_mm256_set1_epi8/epi16</code> <code>_mm256_set1_epi32/epi64</code></td><td>Fill a vector with an integer</td></tr><tr><td><code>_mm256_set_ps/pd</code></td><td>Initialize a vector with eight floats (ps) or four doubles (pd)</td></tr><tr><td><code>_mm256_set_epi8/epi16</code> <code>_mm256_set_epi32/epi64</code></td><td>Initialize a vector with integers</td></tr><tr><td><code>_mm256_set_m128/m128d/</code> <code>_mm256_set_m128i</code></td><td>Initialize a 256-bit vector with two 128-bit vectors</td></tr><tr><td><code>_mm256_setr_ps/pd</code></td><td>Initialize a vector with eight floats (ps) or four doubles (pd) in reverse order</td></tr><tr><td><code>_mm256_setr_epi8/epi16</code> <code>_mm256_setr_epi32/epi64</code></td><td>Initialize a vector with integers in reverse order</td></tr></tbody></table><p>表中的第一个函数是最容易理解的。_m256_setzero_ps返回一个__m256向量，包含8个设置为0的浮点数。类似地，_m256_setzero_si256返回一个__m256i向量，其字节被设置为0。例如，下面这行代码创建了一个256位的向量，其中包含4个设为0的double:</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++">_m256d dbl_vector = _m256_setzero_pd();<br></code></pre></div></td></tr></table></figure><p>名称中包含set1的函数接受一个值，并在整个向量中重复该值。例如，下面这行代码创建了一个__m256i，它的16个short value被设置为47:</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++">_m256i short_vector = _m256_set1_pd();<br></code></pre></div></td></tr></table></figure><p>表2中的其他函数包含_set_或_setr_。这些函数接受一系列值，每个向量的元素对应一个值。这些值被放置在返回的向量中，理解顺序很重要。下面的函数调用返回一个包含8个整数的向量，其值范围为1到8:</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++">_m256i int_vector = _m256_set_epi32(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>);<br></code></pre></div></td></tr></table></figure><p>您可能希望值按照给定的顺序存储。但英特尔的架构是小端存储类型的，所以最低有效值(8)先存储，最高有效值(1)最后存储。您可以通过将int_vector转换为int指针并打印存储的值来验证这一点。如下代码所示:</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++">__m256i int_vector = _mm256_set_epi32(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>);<br><span class="hljs-keyword">int</span> *ptr = (<span class="hljs-keyword">int</span>*)&amp;int_vector;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d %d %d %d %d %d %d %d\n&quot;</span>, ptr[<span class="hljs-number">0</span>], ptr[<span class="hljs-number">1</span>], ptr[<span class="hljs-number">2</span>], ptr[<span class="hljs-number">3</span>], ptr[<span class="hljs-number">4</span>], ptr[<span class="hljs-number">5</span>], ptr[<span class="hljs-number">6</span>], ptr[<span class="hljs-number">7</span>]);<br>--&gt; <span class="hljs-number">8</span> <span class="hljs-number">7</span> <span class="hljs-number">6</span> <span class="hljs-number">5</span> <span class="hljs-number">4</span> <span class="hljs-number">3</span> <span class="hljs-number">2</span> <span class="hljs-number">1</span><br></code></pre></div></td></tr></table></figure><p>如果希望值按给定顺序存储，可以使用_setr_函数之一创建向量，其中r可能代表reverse。下面的代码展示了它是如何工作的:</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++">__m256i int_vector = _mm256_setr_epi32(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>);<br><span class="hljs-keyword">int</span> *ptr = (<span class="hljs-keyword">int</span>*)&amp;int_vector;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d %d %d %d %d %d %d %d\n&quot;</span>, ptr[<span class="hljs-number">0</span>], ptr[<span class="hljs-number">1</span>], ptr[<span class="hljs-number">2</span>], ptr[<span class="hljs-number">3</span>], ptr[<span class="hljs-number">4</span>], ptr[<span class="hljs-number">5</span>], ptr[<span class="hljs-number">6</span>], ptr[<span class="hljs-number">7</span>]);<br>--&gt; <span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span> <span class="hljs-number">6</span> <span class="hljs-number">7</span> <span class="hljs-number">8</span><br></code></pre></div></td></tr></table></figure><p>有趣的是，AVX和AVX2都没有提供用无符号整数初始化向量的intrinsic。但是，它们提供了对带无符号整数的向量进行操作的函数。</p></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/HPC/">HPC</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/AVX/">AVX</a> <a class="hover-with-bg" href="/tags/AVX2/">AVX2</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2023/01/28/cuda006/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">CUDA线程管理</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2023/01/17/cuda005/"><span class="hidden-mobile">CUDA内存管理</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="waline"></div><script type="text/javascript">Fluid.utils.loadComments("#waline",(function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/@waline/client@1/dist/Waline.min.js",(function(){var i=Object.assign({serverURL:"https://example.xingyuanjie.top/",path:"window.location.pathname",placeholder:"欢迎留言~(填写邮箱可在被回复时收到邮件提醒哦)",meta:["nick","mail","link"],requiredMeta:["nick"],lang:"zh-CN",emoji:["https://cdn.jsdelivr.net/gh/walinejs/emojis/weibo"],dark:'html[data-user-color-scheme="dark"]',avatar:"retro",avatarCDN:"https://seccdn.libravatar.org/avatar/",avatarForce:!1,wordLimit:0,pageSize:10,highlight:!0},{el:"#waline",path:window.location.pathname});new Waline(i),Fluid.utils.waitElementVisible("#waline .vcontent",()=>{Fluid.plugins.initFancyBox("#waline .vcontent img:not(.vemoji)")})}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/local-search.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js"></script><script>!function(t,i){(0,Fluid.plugins.typing)(i.getElementById("subtitle").title)}(window,document)</script><script src="/js/boot.js"></script></body></html>