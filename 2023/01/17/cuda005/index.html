<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/site.jpg"><link rel="icon" href="/img/site.jpg"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content=""><meta name="author" content="John Doe"><meta name="keywords" content=""><meta name="description" content="1.内存管理CUDA编程模型假设系统是由一个主机和一个设备组成的，而且各自拥有独立的内存。核函数是在设备上运行的。为使你拥有充分的控制权并使系统达到最佳性能，CUDA运行时负责分配与释放设备内存，并且在主机内存和设备内存之间传输数据。表2-1列出了标准的C函数以及相应地针对内存操作的CUDA C函数。 用于执行GPU内存分配的是cudaMalloc函数，其函数原型为： 1cudaError_t c"><meta property="og:type" content="article"><meta property="og:title" content="CUDA内存管理"><meta property="og:url" content="http://example.com/2023/01/17/cuda005/index.html"><meta property="og:site_name" content="Amicoyuan"><meta property="og:description" content="1.内存管理CUDA编程模型假设系统是由一个主机和一个设备组成的，而且各自拥有独立的内存。核函数是在设备上运行的。为使你拥有充分的控制权并使系统达到最佳性能，CUDA运行时负责分配与释放设备内存，并且在主机内存和设备内存之间传输数据。表2-1列出了标准的C函数以及相应地针对内存操作的CUDA C函数。 用于执行GPU内存分配的是cudaMalloc函数，其函数原型为： 1cudaError_t c"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://example.com/2023/01/17/cuda005/image-20230117223254853.png"><meta property="og:image" content="http://example.com/2023/01/17/cuda005/image-20230128140743600.png"><meta property="og:image" content="http://example.com/2023/01/17/cuda005/image-20230128141008674.png"><meta property="article:published_time" content="2023-01-17T14:03:10.000Z"><meta property="article:modified_time" content="2023-01-28T06:49:23.935Z"><meta property="article:author" content="John Doe"><meta property="article:tag" content="CUDA"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://example.com/2023/01/17/cuda005/image-20230117223254853.png"><title>CUDA内存管理 - Amicoyuan</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/androidstudio.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"example.com",root:"/",version:"1.8.12",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"g10sppACiB0iwBrOiERhucmg-MdYXbMMI",app_key:"f7eskymhpDIBDrODMFqlWwQU",server_url:null,path:"window.location.pathname"}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="baidu-site-verification" content="codeva-U4QF0Alodb"><meta name="generator" content="Hexo 5.4.0"></head><body><header style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Amicoyuan</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/tools/"><i class="iconfont icon-playstation-fill"></i> 工具</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="CUDA内存管理"></span><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-01-17 22:03" pubdate>2023年1月17日 晚上</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 3.3k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 10 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">CUDA内存管理</h1><div class="markdown-body"><h3 id="1-内存管理"><a href="#1-内存管理" class="headerlink" title="1.内存管理"></a>1.内存管理</h3><p>CUDA编程模型假设系统是由一个主机和一个设备组成的，而且各自拥有独立的内存。核函数是在设备上运行的。为使你拥有充分的控制权并使系统达到最佳性能，CUDA运行时负责分配与释放设备内存，并且在主机内存和设备内存之间传输数据。表2-1列出了标准的C函数以及相应地针对内存操作的CUDA C函数。</p><p>用于执行GPU内存分配的是cudaMalloc函数，其函数原型为：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-function">cudaError_t <span class="hljs-title">cudaMalloc</span><span class="hljs-params">(<span class="hljs-keyword">void</span>** devPtr, <span class="hljs-keyword">size_t</span> size)</span></span><br></code></pre></div></td></tr></table></figure><p><img src="/2023/01/17/cuda005/image-20230117223254853.png" srcset="/img/loading.gif" lazyload alt="image-20230117223254853"></p><p>该函数负责向设备分配一定字节的线性内存，并以devPtr的形式返回指向所分配内存的指针。cudaMalloc与标准C语言中的malloc函数几乎一样，只是此函数在GPU的内存里分配内存。通过充分保持与标准C语言运行库中的接口一致性，可以实现CUDA应用程序的轻松接入。</p><p>cudaMemcpy函数负责主机和设备之间的数据传输，其函数原型为：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-function">cudaError_t <span class="hljs-title">cudaMencpy</span><span class="hljs-params">( <span class="hljs-keyword">void</span>* dst, <span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span>* src, <span class="hljs-keyword">size_t</span> count, cudaMemcpyKind kind)</span></span><br></code></pre></div></td></tr></table></figure><p>此函数从src指向的源存储区复制一定数量的字节到dst指向的目标存储区。复制方向由kind指定，其中的kind有以下几种。</p><ol><li>cudaMemcpyHostToHost</li><li>cudaMemcpyHostToDevice</li><li>cudaMemcpyDeviceToHost</li><li>cudaMemcpyDeviceToDevice</li></ol><p>这个函数以同步方式执行，因为在cudaMemcpy函数返回以及传输操作完成之前主机应用程序是阻塞的。除了内核启动之外的CUDA调用都会返回一个错误的枚举类型cudaError_t。如果GPU内存分配成功，函数返回：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++">cudaSuccess<br></code></pre></div></td></tr></table></figure><p>否则返回：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++">cudaErrorMemoryAllocation<br></code></pre></div></td></tr></table></figure><p>可以使用以下CUDA运行时函数将错误代码转化为可读的错误消息：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">char</span>* <span class="hljs-title">cudaGetErroeString</span><span class="hljs-params">(cudaError_t error)</span></span><br></code></pre></div></td></tr></table></figure><p>cudaGetErrorString函数和C语言中的strerror函数类似。</p><p>CUDA编程模型从GPU架构中抽象出一个内存层次结构，图2-3所示的是一个简化的GPU内存结构，它主要包含两部分：全局内存和共享内存。</p><h3 id="2-内存层次结构"><a href="#2-内存层次结构" class="headerlink" title="2.内存层次结构"></a>2.内存层次结构</h3><p>CUDA编程模型最显著的一个特点就是揭示了内存层次结构。每一个GPU设备都有用于不同用途的存储类型。</p><p>在GPU内存层次结构中，最主要的两种内存是全局内存和共享内存。全局类似于CPU的系统内存，而共享内存类似于CPU的缓存。然而GPU的共享内存可以由CUDA C的内核直接控制。</p><p><img src="/2023/01/17/cuda005/image-20230128140743600.png" srcset="/img/loading.gif" lazyload alt="image-20230128140743600"></p><p>下面，我们将通过一个简单的两个数组相加的例子来学习如何在主机和设备之间进行数据传输，以及如何使用CUDA C编程。如图2-4所示，数组a的第一个元素与数组b的第一个元素相加，得到的结果作为数组c的第一个元素，重复这个过程直到数组中的所有元素都进行了一次运算。‘</p><p><img src="/2023/01/17/cuda005/image-20230128141008674.png" srcset="/img/loading.gif" lazyload alt="image-20230128141008674"></p><p>首先，执行主机端代码使两个数组相加（如代码清单2-1所示）。</p><h4 id="代码清单2-1-sumArraysOnHost-c"><a href="#代码清单2-1-sumArraysOnHost-c" class="headerlink" title="代码清单2-1 sumArraysOnHost.c"></a>代码清单2-1 sumArraysOnHost.c</h4><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;string.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;time.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">sumArraysOnHost</span><span class="hljs-params">(<span class="hljs-keyword">float</span> *A, <span class="hljs-keyword">float</span> *B, <span class="hljs-keyword">float</span> *C, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> N)</span></span>&#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> idx=<span class="hljs-number">0</span>;idx&lt;n;idx++)<br>        C[idx]=A[idx]+B[idx];<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">initialData</span><span class="hljs-params">(<span class="hljs-keyword">float</span> *ip,<span class="hljs-keyword">int</span> size)</span></span>&#123;<br>    <span class="hljs-comment">//generate different seed for random number time_t t;</span><br>    <span class="hljs-built_in">srand</span>((<span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span>) <span class="hljs-built_in">time</span> (&amp;t));<br>    <br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>;i&lt;size;i++)&#123;<br>        ip[i]=(<span class="hljs-keyword">float</span>)(<span class="hljs-built_in">rand</span>() &amp; OxFF)/<span class="hljs-number">10.0f</span>;<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span> **argv)</span></span>&#123;<br>    <span class="hljs-keyword">int</span> nElem =<span class="hljs-number">1024</span>;<br>    <span class="hljs-keyword">size_t</span> nBytes = nElem *<span class="hljs-built_in"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword">float</span>);<br>    <br>    <span class="hljs-keyword">float</span> *h_A, *h_B, *h_C;<br>    h_A = (<span class="hljs-keyword">float</span> *)<span class="hljs-built_in">malloc</span>(nBytes);<br>    h_B = (<span class="hljs-keyword">float</span> *)<span class="hljs-built_in">malloc</span>(nBytes);<br>    h_C = (<span class="hljs-keyword">float</span> *)<span class="hljs-built_in">malloc</span>(nBytes);<br>    <br>    <span class="hljs-built_in">initialData</span>(h_A, nElem);<br>    <span class="hljs-built_in">initialData</span>(h_B, nElem);<br>    <br>    <span class="hljs-built_in">sumArraysOnHost</span>(h_A, h_B, h_C, nElem);<br>    <br>    <span class="hljs-built_in">free</span>(h_A);<br>    <span class="hljs-built_in">free</span>(h_B);<br>    <span class="hljs-built_in">free</span>(h_C);<br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></div></td></tr></table></figure><p>这是一个纯C语言编写的程序，你可以用C语言编译器进行编译，也可以像下面这样用nvcc进行编译。</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">nvcc -Xcompiler -std=c99 sumArraysOnHost.c -o sum<br>./sum<br></code></pre></div></td></tr></table></figure><p>nvcc封装了几种内部编译工具，CUDA编译器允许通过命令行选项在不同阶段启动不同的工具完成编译工作。-Xcompiler用于指定命令行选项是指向C编译器还是预处理器。在前面的例子中，将-std&#x3D;c99传递给编译器，因为这里的C程序是按照C99标准编写的。</p><p>现在，你可以在GPU上修改代码来进行数组加法运算，用cudaMalloc在GPU上申请内存。</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-keyword">float</span> *h_A, *h_B, *h_C;<br><span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-keyword">float</span>**)&amp;d_A, nBytes);<br><span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-keyword">float</span>**)&amp;d_B, nBytes);<br><span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-keyword">float</span>**)&amp;d_C, nBytes);<br></code></pre></div></td></tr></table></figure><p>使用cudaMemcpy函数把数据从主机内存拷贝到GPU的全局内存中，参考cudaMemcpyHostToDevice指定数据拷贝方向。</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-built_in">cudaMemcpy</span>(d_A, h_A, nBytes, cudaMemcpyHostToDevice);<br><span class="hljs-built_in">cudaMemcpy</span>(d_B, h_B, nBytes, cudaMemcpyHostToDevice);<br></code></pre></div></td></tr></table></figure><p>当数据被转移到GPU的全局内存后，主机端调用核函数在GPU上进行数组求和。一旦内核被调用，控制权立刻被传回主机，这样的话，当核函数在GPU上运行时，主机可以执行其他函数。因此，内核与主机是异步的。</p><p>当内核在GPU上完成了对所有数组元素的处理后，其结果将以数组d_C的形式存储在GPU的全局内存中，然后用cudaMemcpy函数把结果从GPU复制回到主机的数组gpuRef中。</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-built_in">cudaMemcpy</span>(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);<br></code></pre></div></td></tr></table></figure><p>cudaMemcpy的调用会导致主机运行阻塞。cudaMemcpyDeviceToHost的作用就是将存储在GPU上的数组d_C中的结果复制到gpuRef中。最后，调用cudaFree释放GPU的内存。</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-built_in">cudaFree</span>(d_A);<br><span class="hljs-built_in">cudaFree</span>(d_B);<br><span class="hljs-built_in">cudaFree</span>(d_C);<br></code></pre></div></td></tr></table></figure><h3 id="3-不同的存储空间"><a href="#3-不同的存储空间" class="headerlink" title="3.不同的存储空间"></a>3.不同的存储空间</h3><p>使用CUDA C进行编程的人最常犯的错误就是对不同内存空间的不恰当引用。对于在GPU上被分配的内存来说，设备指针在主机代码中可能并没有被引用。如果你执行了错误的内存分配，如：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++">gpuRef = d_C<br></code></pre></div></td></tr></table></figure><p>而不是用：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-built_in">cudaMemcpy</span>(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);<br></code></pre></div></td></tr></table></figure><p>应用程序在运行时将会崩溃。</p><p>为了避免这类错误，CUDA6.0提出了统一寻址，使用一个指针来访问CPU和GPU的内存</p><h3 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4.参考资料"></a>4.参考资料</h3><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher</p></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/HPC/">HPC</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/CUDA/">CUDA</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2023/01/28/avx006/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">如何使用AVX和AVX2处理数据(个人翻译)[未完成]</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2023/01/17/cuda004/"><span class="hidden-mobile">CUDA编程结构</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="waline"></div><script type="text/javascript">Fluid.utils.loadComments("#waline",(function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/@waline/client@1/dist/Waline.min.js",(function(){var i=Object.assign({serverURL:"https://example.xingyuanjie.top/",path:"window.location.pathname",placeholder:"欢迎留言~(填写邮箱可在被回复时收到邮件提醒哦)",meta:["nick","mail","link"],requiredMeta:["nick"],lang:"zh-CN",emoji:["https://cdn.jsdelivr.net/gh/walinejs/emojis/weibo"],dark:'html[data-user-color-scheme="dark"]',avatar:"retro",avatarCDN:"https://seccdn.libravatar.org/avatar/",avatarForce:!1,wordLimit:0,pageSize:10,highlight:!0},{el:"#waline",path:window.location.pathname});new Waline(i),Fluid.utils.waitElementVisible("#waline .vcontent",()=>{Fluid.plugins.initFancyBox("#waline .vcontent img:not(.vemoji)")})}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/local-search.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js"></script><script>!function(t,i){(0,Fluid.plugins.typing)(i.getElementById("subtitle").title)}(window,document)</script><script src="/js/boot.js"></script></body></html>