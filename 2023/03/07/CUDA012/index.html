<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/site.jpg"><link rel="icon" href="/img/site.jpg"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content=""><meta name="author" content="John Doe"><meta name="keywords" content=""><meta name="description" content="CUDA给核函数计时在内核的性能转换过程中，了解核函数的执行需要多长时间是很有帮助并且十分关键的。衡量核函数性能的方法有很多。最简单的方法是在主机端使用一个CPU或GPU计时器来计算内核的执行时间。在本节，你需要设置一个CPU计时器，并使用NVIDIA分析工具来计算执行时间。 用CPU计时器计时可以使用gettimeofday系统调用来创建一个CPU计时器，以获取系统的时钟时间，它将返回自1970"><meta property="og:type" content="article"><meta property="og:title" content="CUDA给核函数计时"><meta property="og:url" content="https://xingyuanjie.top/2023/03/07/CUDA012/index.html"><meta property="og:site_name" content="Amicoyuan"><meta property="og:description" content="CUDA给核函数计时在内核的性能转换过程中，了解核函数的执行需要多长时间是很有帮助并且十分关键的。衡量核函数性能的方法有很多。最简单的方法是在主机端使用一个CPU或GPU计时器来计算内核的执行时间。在本节，你需要设置一个CPU计时器，并使用NVIDIA分析工具来计算执行时间。 用CPU计时器计时可以使用gettimeofday系统调用来创建一个CPU计时器，以获取系统的时钟时间，它将返回自1970"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://xingyuanjie.top/2023/03/07/CUDA012/image-20230307120643741.png"><meta property="og:image" content="https://xingyuanjie.top/2023/03/07/CUDA012/image-20230307142027522.png"><meta property="og:image" content="https://xingyuanjie.top/2023/03/07/CUDA012/image-20230307145539161.png"><meta property="article:published_time" content="2023-03-07T01:53:34.000Z"><meta property="article:modified_time" content="2023-03-07T07:16:19.161Z"><meta property="article:author" content="John Doe"><meta property="article:tag" content="CUDA"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://xingyuanjie.top/2023/03/07/CUDA012/image-20230307120643741.png"><title>CUDA给核函数计时 - Amicoyuan</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/androidstudio.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"xingyuanjie.top",root:"/",version:"1.8.12",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"g10sppACiB0iwBrOiERhucmg-MdYXbMMI",app_key:"f7eskymhpDIBDrODMFqlWwQU",server_url:null,path:"window.location.pathname"}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body><header style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Amicoyuan</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/tools/"><i class="iconfont icon-playstation-fill"></i> 工具</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="CUDA给核函数计时"></span><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-03-07 09:53" pubdate>2023年3月7日 上午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 5.2k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 16 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">CUDA给核函数计时</h1><div class="markdown-body"><h2 id="CUDA给核函数计时"><a href="#CUDA给核函数计时" class="headerlink" title="CUDA给核函数计时"></a>CUDA给核函数计时</h2><p>在内核的性能转换过程中，了解核函数的执行需要多长时间是很有帮助并且十分关键的。衡量核函数性能的方法有很多。最简单的方法是在主机端使用一个CPU或GPU计时器来计算内核的执行时间。在本节，你需要设置一个CPU计时器，并使用NVIDIA分析工具来计算执行时间。</p><h3 id="用CPU计时器计时"><a href="#用CPU计时器计时" class="headerlink" title="用CPU计时器计时"></a>用CPU计时器计时</h3><p>可以使用gettimeofday系统调用来创建一个CPU计时器，以获取系统的时钟时间，它将返回自1970年1月1日零点以来，到现在的秒数。程序中需要添加sys&#x2F;time.h头文件，如代码清单2-5所示。</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">double</span> <span class="hljs-title">cpuSecond</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">timeval</span> <span class="hljs-title">tp</span>;</span><br>    <span class="hljs-built_in">gettimeofday</span>(&amp;tp,<span class="hljs-literal">NULL</span>);<br>    <br>    <span class="hljs-keyword">return</span> ((<span class="hljs-keyword">double</span>)tp.tv_sec + (<span class="hljs-keyword">double</span>)tp.tv_usec*<span class="hljs-number">1.e-6</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure><p>你可以用cpuSecond函数来测试你的核函数：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-keyword">double</span> iStart = <span class="hljs-built_in">cpuSecond</span>();<br>kernel_name&lt;&lt;&lt;grid,block&gt;&gt;&gt;(argument list);<br><span class="hljs-built_in">cudaDeviceSynchronize</span>();<br><span class="hljs-keyword">double</span> iElaps = <span class="hljs-built_in">cpuSecond</span>() - iStart;<br></code></pre></div></td></tr></table></figure><p>由于核函数调用与主机端程序是异步的，你需要用cudaDeviceSynchronize函数来等待所有的GPU线程运行结束。变量iElaps表示程序运行的时间，就像你用手表记录的核函数的执行时间（用秒计算）。</p><p>现在，通过设置数据集大小来对一个有16M个元素的大向量进行测试：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-keyword">int</span> nElem = <span class="hljs-number">1</span>&lt;&lt;<span class="hljs-number">24</span>;<br></code></pre></div></td></tr></table></figure><p>由于GPU的可扩展性，你需要借助块和线程的索引来计算一个按行优先的数组索引 i ，并对核函数进行修改，添加限定条件（i &lt; N）来检验索引值是否越界，如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-keyword">void</span> <span class="hljs-title">sumArraysOnGPU</span><span class="hljs-params">(<span class="hljs-keyword">float</span> *A, <span class="hljs-keyword">float</span> *B, <span class="hljs-keyword">float</span> *C, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> N)</span></span>&#123;<br>    <span class="hljs-keyword">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-keyword">if</span>( n &lt; N) C[i] = A[i] + B[i];<br>&#125;<br></code></pre></div></td></tr></table></figure><p>有了这些更改，可以使用不同的执行配置来衡量核函数。为了解决创建的线程总数大于向量元素总数的情况，你需要限制内核不能非法访问全局内存，如图2-7所示。</p><p><img src="/2023/03/07/CUDA012/image-20230307120643741.png" srcset="/img/loading.gif" lazyload alt="image-20230307120643741"></p><p>代码清单2-5展示了如何在主函数中用CPU计时器测试向量加法的核函数。</p><p>代码清单2-5	测试向量加法的核函数（sumArraysOnGPU-timer.cu）</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;cuda_runtime.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;sys/time.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc,<span class="hljs-keyword">char</span> **argv)</span></span>&#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%s Starting...\n&quot;</span>,argv[<span class="hljs-number">0</span>]);<br>    <br>    <span class="hljs-comment">//set up device</span><br>    <span class="hljs-keyword">int</span> dev = <span class="hljs-number">0</span>;<br>    cudaDeviceProp deviceProp;<br>    <span class="hljs-built_in">CHECK</span>(<span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;deviceProp, dev));<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Using Device %d: %s\n&quot;</span>, dev, deviceProp.name);<br>    <span class="hljs-built_in">CHECK</span>(<span class="hljs-built_in">cudaSetDevice</span>(dev));<br>    <br>    <span class="hljs-comment">//set up data size of vectors</span><br>    <span class="hljs-keyword">int</span> nElem = <span class="hljs-number">1</span>&lt;&lt;<span class="hljs-number">24</span>;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Vector size %d\n&quot;</span>,nElem);<br>    <br>    <span class="hljs-comment">//malloc host memory</span><br>    <span class="hljs-keyword">size_t</span> nBytes = nElem * <span class="hljs-built_in"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword">float</span>);<br>    <br>    <span class="hljs-keyword">float</span> *h_A, *h_B, *hostRef, *gpuRef;<br>    h_A = (<span class="hljs-keyword">float</span>*)<span class="hljs-built_in">malloc</span>(nBytes);<br>    h_B = (<span class="hljs-keyword">float</span>*)<span class="hljs-built_in">malloc</span>(nBytes);<br>    hostRef = (<span class="hljs-keyword">float</span>*)<span class="hljs-built_in">malloc</span>(nBytes);<br>    gpuRef = (<span class="hljs-keyword">float</span>*)<span class="hljs-built_in">malloc</span>(nBytes);<br>    <br>    <span class="hljs-keyword">double</span> iStart,iElaps;<br>    <br>    <span class="hljs-comment">//initialize data at host side</span><br>    iStart = <span class="hljs-built_in">cpuSecond</span>();<br>    <span class="hljs-built_in">initialData</span>(h_A, nElem);<br>    <span class="hljs-built_in">initialData</span>(h_B, nElem);<br>    iElaps = <span class="hljs-built_in">cpuSecond</span>() - iStart;<br>    <br>    <span class="hljs-built_in">memset</span>(hostRef, <span class="hljs-number">0</span> ,nBytes);<br>    <span class="hljs-built_in">memset</span>(gpuRef, <span class="hljs-number">0</span> ,nBytes);<br>    <br>    <span class="hljs-comment">//add vector at host side for result checks</span><br>    iStart = <span class="hljs-built_in">cpuSecond</span>();<br>    <span class="hljs-built_in">sumArraysOnHost</span>(h_A, h_B, hostRef, nElem);<br>    iElaps = <span class="hljs-built_in">cpuSecond</span>() - iStart;<br>    <br>    <span class="hljs-comment">//malloc device global memory</span><br>    <span class="hljs-keyword">float</span> *d_A, *d_B, *d_C;<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-keyword">float</span>**)&amp;d_A, nBytes);<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-keyword">float</span>**)&amp;d_B, nBytes);<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-keyword">float</span>**)&amp;d_C, nBytes);<br>    <br>    <span class="hljs-comment">//transfer data from host to device</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_A, h_A, nBytes, cudaMemcpyHostTodevice);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_B, h_B, nBytes, cudaMemcpyHostTodevice);<br>    <br>    <span class="hljs-comment">//invoke kernel at host side</span><br>    <span class="hljs-keyword">int</span> iLen = <span class="hljs-number">1024</span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">block</span><span class="hljs-params">(iLen)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">grid</span><span class="hljs-params">((nElem+block.x<span class="hljs-number">-1</span>))</span>/block.x)</span>;<br>    <br>    iStart = <span class="hljs-built_in">cpuSecond</span>();<br>    sumArraysOnGPU&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_A, d_B, d_C,nElem);<br>    <span class="hljs-built_in">cudaDeviceSynchronize</span>();<br>    iElaps = <span class="hljs-built_in">cpuSecond</span>() - iStart;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;sumArraysOnGPU&lt;&lt;&lt;%d,%d&gt;&gt;&gt; Time elapsed %f sec\n&quot;</span>,grid.x, block.x, iElaps);<br>    <br>    <span class="hljs-comment">//copy kernel result back to host side</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);<br>    <br>    <span class="hljs-comment">//check device results</span><br>    <span class="hljs-built_in">checkResult</span>(hostRef, gpuRef, nElem);<br>    <br>    <span class="hljs-comment">//free device global memory</span><br>    <span class="hljs-built_in">cudaFree</span>(d_A);<br>    <span class="hljs-built_in">cudaFree</span>(d_B);<br>    <span class="hljs-built_in">cudaFree</span>(d_C);<br>    <br>    <span class="hljs-comment">//free host memory</span><br>    <span class="hljs-built_in">free</span>(h_A);<br>    <span class="hljs-built_in">free</span>(h_B);<br>    <span class="hljs-built_in">free</span>(hostRef);<br>    <span class="hljs-built_in">free</span>(gpuRef);<br>    <br>    <span class="hljs-keyword">return</span>(<span class="hljs-number">0</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure><p>默认的执行配置被设置为一个包含16384个块的一维网格，每个块包含1024个线程。用以下命令编译并运行程序：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">nvcc sumArraysOnGPU-timer.cu -o sumArraysOnGPU-timer<br>./sumArraysOnGPU-timer<br></code></pre></div></td></tr></table></figure><p>在基于英特尔Sandy Bridge架构的系统上进行测试，从代码清单2-5的示例中可以看出，在GPU上进行的向量加法的运算速度是在CPU上运行向量加法的3.86倍。</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">./sumArraysOnGPU-timer Starting...<br>Using Device 0:Tesia M2070<br>Vector size 16777216<br>sumArraysOnGPU&lt;&lt;&lt;16384, 1024&gt;&gt;&gt;		Time elapsed 0.002456 sec<br>Arrays match.<br></code></pre></div></td></tr></table></figure><p>把块的维度减少到512可以创建32768个块。在这个新的配置下，内核的性能提升了1.19倍。</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">sumArraysOnGPU&lt;&lt;&lt;32768, 512&gt;&gt;&gt;	Time elapsed 0.002058 sec<br></code></pre></div></td></tr></table></figure><p>如果进一步将块的维度降低到256，系统将提示以下错误信息，信息表示块的总数超过一维网格的限制。</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">./sumArraysOnGPU-timer Starting...<br>Using Device 0:	Tesla M2070<br>Vector size 16777216<br>sumArraysOnGPU&lt;&lt;&lt;65536, 256&gt;&gt;&gt;  Time elapsed 0.000183 sec<br>Error: sumArraysOnGPU-timer.cu:153, code:9, reason: invalid configuration argument<br></code></pre></div></td></tr></table></figure><h3 id="了解自身局限性"><a href="#了解自身局限性" class="headerlink" title="了解自身局限性"></a>了解自身局限性</h3><p>在调整执行配置时需要了解的一个关键点是对网格和块维度的限制。线程层次结构中每个层次的最大尺寸取决于设备。</p><p>CUDA提供了通过查询GPU来了解这些限制的能力。</p><p>对于Fermi设备，每个块的最大线程数是1024，且网格的x,y,z三个方向上的维度最大值是65535</p><h3 id="用nvprof工具计时"><a href="#用nvprof工具计时" class="headerlink" title="用nvprof工具计时"></a>用nvprof工具计时</h3><p>自CUDA 5.0以来，NVIDIA提供了一个名为nvprof的命令行分析工具，可以帮助从应用程序的CPU和GPU活动情况中获取时间线信息，其包括内核执行，内存传输以及CUDA API的调用。其用法如下。</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">nvprof [nvprof_args] &lt;application&gt;  [application_args]<br></code></pre></div></td></tr></table></figure><p>可以使用以下命令获取更多关于nvprof的帮助信息：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">nvprof --help<br></code></pre></div></td></tr></table></figure><p>你可以用如下命令去测试内核：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">nvprof  ./sumArraysOnGPU-timer<br></code></pre></div></td></tr></table></figure><p>nvprof的输出结果会因为你使用的GPU类型不同而有所差异。以下结果是从Tesla GPU中得到的：</p><p><img src="/2023/03/07/CUDA012/image-20230307142027522.png" srcset="/img/loading.gif" lazyload alt="image-20230307142027522"></p><p>以上结果的前半部分来自于程序的输出，后半部分来自于nvprof的输出。可以注意到，CPU计时器显示消耗的内核时间为3.26ms，而nvprof显示消耗的内核时间为2.90ms。在这个例子中，nvprof的结果更为精确，因为CPU计时器测量的时间中包含了来自nvprof附加的时间。</p><p>nvprof是一个能帮助你理解在执行应用程序时所花费的时间主要用在何处的强大工具。可以注意到，在这个例子中，主机和设备之间的数据传输需要的时间比内核执行的时间要多。图2-8所描绘的时间线（未按比例绘制），显示了在CPU上消耗的时间，数据传输所用的时间以及在GPU上计算所用的时间。</p><p><img src="/2023/03/07/CUDA012/image-20230307145539161.png" srcset="/img/loading.gif" lazyload alt="image-20230307145539161"></p><p>对于HPC工作负载，理解程序中通信比的计算是非常重要的。如果你的应用程序用于计算的时间大于数据传输所用的时间，那么或许可以压缩这些操作，并完全隐藏与传输数据有关的延迟。如果你的应用程序用于计算的时间少于数据传输所用的时间，那么需要尽量减少主机和设备之间的传输。</p><h3 id="比较应用程序的性能将理论界限最大化"><a href="#比较应用程序的性能将理论界限最大化" class="headerlink" title="比较应用程序的性能将理论界限最大化"></a>比较应用程序的性能将理论界限最大化</h3><p>在进行程序优化时，如何将应用程序和理论界限进行比较是很重要的。由nvprof得到的计数器可以帮助你获取应用程序的指令和内存吞吐量。如果将应用程序的测量值与理论峰值进行比较，可以判定你的应用程序的性能是受限于算法还是受限于内存带宽的。以Tesla K10为例，可以得到理论上的比率：</p><p>Tesla K10单精度峰值浮点运算次数</p><p>745 MHz核心频率*2 GPU&#x2F;芯片* （8个多处理器<em>192个浮点单元</em>32核心&#x2F;多处理器）*2OPS&#x2F;周期 &#x3D; 4.58 TFLOPS （FLOPS表示每秒浮点运算次数）</p><p>Tesla K10内存带宽峰值</p><p>2 GPU&#x2F;芯片<em>256位</em>2500 MHz内存时钟*2 DDR&#x2F;8位&#x2F;字节 &#x3D; 320 GB&#x2F;s</p><p>指令比：字节</p><p>4.58 TFLOPS&#x2F;320 GB&#x2F;s,	也就是13.6个指令：1个字节</p><p>对于Tesla K10而言，如果你的应用程序每访问一个字节所产生的指令数多于13.6，那么你的应用程序受算法性能限制。大多数HPC工作负载受内存带宽的限制。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher</p></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/HPC/">HPC</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/CUDA/">CUDA</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p><div class="post-prevnext"><article class="post-prev col-6"><a href="/2023/03/08/cuda013/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">组织并行编程</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2023/03/06/ML001/"><span class="hidden-mobile">线性回归模型</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="waline"></div><script type="text/javascript">Fluid.utils.loadComments("#waline",(function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/@waline/client@1/dist/Waline.min.js",(function(){var i=Object.assign({serverURL:"https://example.xingyuanjie.top/",path:"window.location.pathname",placeholder:"欢迎留言~(填写邮箱可在被回复时收到邮件提醒哦)",meta:["nick","mail","link"],requiredMeta:["nick"],lang:"zh-CN",emoji:["https://cdn.jsdelivr.net/gh/walinejs/emojis/weibo"],dark:'html[data-user-color-scheme="dark"]',avatar:"retro",avatarCDN:"https://seccdn.libravatar.org/avatar/",avatarForce:!1,wordLimit:0,pageSize:10,highlight:!0},{el:"#waline",path:window.location.pathname});new Waline(i),Fluid.utils.waitElementVisible("#waline .vcontent",()=>{Fluid.plugins.initFancyBox("#waline .vcontent img:not(.vemoji)")})}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/local-search.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js"></script><script>!function(t,i){(0,Fluid.plugins.typing)(i.getElementById("subtitle").title)}(window,document)</script><script src="/js/boot.js"></script></body></html>