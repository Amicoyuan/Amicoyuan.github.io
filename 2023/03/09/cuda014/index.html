<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/site.jpg"><link rel="icon" href="/img/site.jpg"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content=""><meta name="author" content="John Doe"><meta name="keywords" content=""><meta name="description" content="CUDA使用块和线程建立矩阵索引通常情况下，一个矩阵用行优先的方法在全局内存中进行线性存储。图2-9所示的是一个8×6矩阵的小例子。 在一个矩阵加法核函数中，一个线程通常被分配一个数据元素来处理。首先要完成的任务是使用块和线程索引从全局内存中访问指定的数据。通常情况下，对一个二维示例来说，需要管理3种索引。   线程和块索引 矩阵中给定点的坐标 全局线性内存中的偏移量  对于一个给定的线程，首先可"><meta property="og:type" content="article"><meta property="og:title" content="CUDA使用块和线程建立矩阵索引"><meta property="og:url" content="https://xingyuanjie.top/2023/03/09/cuda014/index.html"><meta property="og:site_name" content="Amicoyuan"><meta property="og:description" content="CUDA使用块和线程建立矩阵索引通常情况下，一个矩阵用行优先的方法在全局内存中进行线性存储。图2-9所示的是一个8×6矩阵的小例子。 在一个矩阵加法核函数中，一个线程通常被分配一个数据元素来处理。首先要完成的任务是使用块和线程索引从全局内存中访问指定的数据。通常情况下，对一个二维示例来说，需要管理3种索引。   线程和块索引 矩阵中给定点的坐标 全局线性内存中的偏移量  对于一个给定的线程，首先可"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://xingyuanjie.top/2023/03/09/cuda014/image-20230309113733674.png"><meta property="og:image" content="https://xingyuanjie.top/2023/03/09/cuda014/image-20230309114815497.png"><meta property="og:image" content="https://xingyuanjie.top/2023/03/09/cuda014/image-20230309115229368.png"><meta property="article:published_time" content="2023-03-09T03:32:36.000Z"><meta property="article:modified_time" content="2023-03-09T04:24:09.128Z"><meta property="article:author" content="John Doe"><meta property="article:tag" content="CUDA"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://xingyuanjie.top/2023/03/09/cuda014/image-20230309113733674.png"><title>CUDA使用块和线程建立矩阵索引 - Amicoyuan</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/androidstudio.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><script id="fluid-configs">var Fluid=window.Fluid||{},CONFIG={hostname:"xingyuanjie.top",root:"/",version:"1.8.12",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},copy_btn:!0,image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"g10sppACiB0iwBrOiERhucmg-MdYXbMMI",app_key:"f7eskymhpDIBDrODMFqlWwQU",server_url:null,path:"window.location.pathname"}},search_path:"/local-search.xml"}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body><header style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Amicoyuan</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/tools/"><i class="iconfont icon-playstation-fill"></i> 工具</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner" id="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="page-header text-center fade-in-up"><span class="h2" id="subtitle" title="CUDA使用块和线程建立矩阵索引"></span><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-03-09 11:32" pubdate>2023年3月9日 中午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 2.8k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 9 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto"><h1 style="display:none">CUDA使用块和线程建立矩阵索引</h1><div class="markdown-body"><h2 id="CUDA使用块和线程建立矩阵索引"><a href="#CUDA使用块和线程建立矩阵索引" class="headerlink" title="CUDA使用块和线程建立矩阵索引"></a>CUDA使用块和线程建立矩阵索引</h2><p>通常情况下，一个矩阵用行优先的方法在全局内存中进行线性存储。图2-9所示的是一个8×6矩阵的小例子。</p><p>在一个矩阵加法核函数中，一个线程通常被分配一个数据元素来处理。首先要完成的任务是使用块和线程索引从全局内存中访问指定的数据。通常情况下，对一个二维示例来说，需要管理3种索引。</p><p><img src="/2023/03/09/cuda014/image-20230309113733674.png" srcset="/img/loading.gif" lazyload alt="image-20230309113733674"></p><ul><li>线程和块索引</li><li>矩阵中给定点的坐标</li><li>全局线性内存中的偏移量</li></ul><p>对于一个给定的线程，首先可以通过把线程和块索引映射到矩阵坐标上来获取线程块和线程索引的全局内存偏移量，然后将这些矩阵坐标映射到全局内存的存储单元中。</p><p>第一步，可以用以下公式把线程和块索引映射到矩阵坐标上：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++">ix = threadIdx.x + blockIdx.x * blockDim.x;<br>iy = threadIdx.y + blockIdx.y * blockDim.y;<br></code></pre></div></td></tr></table></figure><p>第二步，可以用以下公式把矩阵坐标映射到全局内存中的索引&#x2F;存储单元上:</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++">idx = iy * nx + ix<br></code></pre></div></td></tr></table></figure><p>图2-10说明了块和线程索引，矩阵坐标以及线性全局内存索引之间的对应关系。</p><p><img src="/2023/03/09/cuda014/image-20230309114815497.png" srcset="/img/loading.gif" lazyload alt="image-20230309114815497"></p><p>printThreadInfo函数被用于输出关于每个线程的以下信息：</p><ul><li>线程索引</li><li>块索引</li><li>矩阵坐标</li><li>线性全局内存偏移量</li><li>相应元素的值</li></ul><p>用以下命令编译并运行该程序：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">nvcc -arch=sm_20 checkThreadIndex.cu -o checkIndex<br>./checkIndex<br></code></pre></div></td></tr></table></figure><p>对于每个线程，你可以获取以下信息：</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-built_in">thread_id</span>(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)	<span class="hljs-built_in">block_id</span>(<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)	<span class="hljs-built_in">coordinate</span>(<span class="hljs-number">6</span>,<span class="hljs-number">1</span>)	global index <span class="hljs-number">14</span> ival <span class="hljs-number">14</span><br></code></pre></div></td></tr></table></figure><p>图2-11说明了这三项索引之间的关系。</p><p><img src="/2023/03/09/cuda014/image-20230309115229368.png" srcset="/img/loading.gif" lazyload alt="image-20230309115229368"></p><p>代码清单2-6 检查块和线程索引（checkT和readIndex.cu）</p><figure class="highlight c++"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;cuda_runtime.h&gt;</span></span><br><span class="hljs-meta">#inclde <span class="hljs-meta-string">&lt;stdio.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> CHECK(call)</span><br>&#123;<br>    <span class="hljs-keyword">const</span> cudaError_t error = call;<br>    <span class="hljs-keyword">if</span>(error != cudaSuccess)<br>    &#123;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Error: %s:%d, &quot;</span>,__FILE__, __LINE__);<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;code:%d, reason: %s\n&quot;</span>,error, <span class="hljs-built_in">cudaGetErrorString</span>(error));<br>        <span class="hljs-built_in">exit</span>(<span class="hljs-number">-10</span>*error);<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">initialInt</span><span class="hljs-params">(<span class="hljs-keyword">int</span> *p, <span class="hljs-keyword">int</span> size)</span></span>&#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>;i&lt;size;i++)&#123;<br>        ip[i] = i;<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">printMateix</span><span class="hljs-params">(<span class="hljs-keyword">int</span> *C,<span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> nx, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> ny)</span></span>&#123;<br>    <span class="hljs-keyword">int</span> *ic = C;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;\nMatrix:	(%d.%d)\n&quot;</span>.nx,ny);<br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> iy=<span class="hljs-number">0</span>;iy&lt;ny;iy++)&#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> ix=<span class="hljs-number">0</span>; ix&lt;nx;ix++)&#123;<br>            <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%3d&quot;</span>,ic[ix]);<br>        &#125;<br>        ic += nx;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;\n&quot;</span>);<br>    &#125;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;\n&quot;</span>);<br>&#125;<br><br><span class="hljs-function">__global__ <span class="hljs-keyword">void</span> <span class="hljs-title">printThreadIndex</span><span class="hljs-params">(<span class="hljs-keyword">int</span> *A, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> nx, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> ny)</span></span>&#123;<br>    <span class="hljs-keyword">int</span> ix = threadIdx.x + blockIdx.x * blockDim.x;<br>    <span class="hljs-keyword">int</span> iy = threadIdx.y + blockIdx.y * blockDim.y;<br>    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span> idx = iy*nx + ix;<br>    <br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;thread_id (%d,%d) block_id (%d,%d) coordinate (%d,%d) global index %2d ival %2d\n&quot;</span>, threadIdx.x, threadIdx.y, blockIdx.x,blockIdx.y,ix,iy,idx,A[idx]);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc,<span class="hljs-keyword">char</span> **argv)</span></span>&#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%s Starting...\n&quot;</span>,argv[<span class="hljs-number">0</span>]);<br>    <br>    <span class="hljs-comment">//get device information</span><br>    <span class="hljs-keyword">int</span> dev = <span class="hljs-number">0</span>;<br>    cudaDeviceProp deviceProp;<br>    <span class="hljs-built_in">CHECK</span>(<span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;deviceProp, dev));<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Using Device %d: %s\n&quot;</span>, dev, deviceProp.name);<br>    <br>    <span class="hljs-comment">//set matrix dimension</span><br>    <span class="hljs-keyword">int</span> nx = <span class="hljs-number">8</span>;<br>    <span class="hljs-keyword">int</span> ny = <span class="hljs-number">6</span>;<br>    <span class="hljs-keyword">int</span> nxy = nx*ny;<br>    <span class="hljs-keyword">int</span> nBytes = nxy * <span class="hljs-built_in"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword">float</span>);<br>    <br>    <span class="hljs-comment">//malloc host memory</span><br>    <span class="hljs-keyword">int</span> *h_A;<br>    h_A = (<span class="hljs-keyword">int</span> *)<span class="hljs-built_in">malloc</span>(nBytes);<br>    <br>    <span class="hljs-comment">//initialize host matrix with interger</span><br>    <span class="hljs-built_in">initialInt</span>(h_A, nxy);<br>    <span class="hljs-built_in">printMatrix</span>(h_A, nx, ny);<br>    <br>    <span class="hljs-comment">//malloc device memory</span><br>    <span class="hljs-keyword">int</span> *d_MatA;<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-keyword">void</span>**)&amp;d_MatA, nBytes);<br>    <br>    <span class="hljs-comment">//transfer data from host to device</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_MatA, h_A, nBytes, cudaMemcpyHostToDevice);<br>    <br>    <span class="hljs-comment">//set up execution configuration</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">block</span><span class="hljs-params">(<span class="hljs-number">4</span>,<span class="hljs-number">2</span>)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">grid</span><span class="hljs-params">((nx+block.x<span class="hljs-number">-1</span>)/block.x,(ny+block.y<span class="hljs-number">-1</span>)/block.y)</span></span>;<br>    <br>    <span class="hljs-comment">//invoke the kernel</span><br>    printThreadIndex&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_MatA,nx,ny);<br>    <span class="hljs-built_in">cudaDeviceSynchronize</span>();<br>    <br>    <span class="hljs-comment">//free host and device memory</span><br>    <span class="hljs-built_in">cudaFree</span>(d_MatA);<br>    <span class="hljs-built_in">free</span>(h_A);<br>    <br>    <span class="hljs-comment">//reset device</span><br>    <span class="hljs-built_in">cudaDeviceReset</span>();<br>    <br>    <span class="hljs-keyword">return</span>(<span class="hljs-number">0</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher</p></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/HPC/">HPC</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/CUDA/">CUDA</a></div></div><p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p><div class="post-prevnext"><article class="post-prev col-6"></article><article class="post-next col-6"><a href="/2023/03/08/cuda013/"><span class="hidden-mobile">CUDA组织并行编程</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments" lazyload><div id="waline"></div><script type="text/javascript">Fluid.utils.loadComments("#waline",(function(){Fluid.utils.createScript("https://cdn.jsdelivr.net/npm/@waline/client@1/dist/Waline.min.js",(function(){var i=Object.assign({serverURL:"https://example.xingyuanjie.top/",path:"window.location.pathname",placeholder:"欢迎留言~(填写邮箱可在被回复时收到邮件提醒哦)",meta:["nick","mail","link"],requiredMeta:["nick"],lang:"zh-CN",emoji:["https://cdn.jsdelivr.net/gh/walinejs/emojis/weibo"],dark:'html[data-user-color-scheme="dark"]',avatar:"retro",avatarCDN:"https://seccdn.libravatar.org/avatar/",avatarForce:!1,wordLimit:0,pageSize:10,highlight:!0},{el:"#waline",path:window.location.pathname});new Waline(i),Fluid.utils.waitElementVisible("#waline .vcontent",()=>{Fluid.plugins.initFancyBox("#waline .vcontent img:not(.vemoji)")})}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer class="text-center mt-5 py-3"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></footer><script src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/local-search.js"></script><script src="/js/img-lazyload.js"></script><script src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script><script defer src="/js/leancloud.js"></script><script src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js"></script><script>!function(t,i){(0,Fluid.plugins.typing)(i.getElementById("subtitle").title)}(window,document)</script><script src="/js/boot.js"></script></body></html>