{
    "version": "https://jsonfeed.org/version/1",
    "title": "Amicoyuan",
    "description": "",
    "home_page_url": "https://xingyuanjie.top",
    "items": [
        {
            "id": "https://xingyuanjie.top/2023/03/13/CMU15-213001/",
            "url": "https://xingyuanjie.top/2023/03/13/CMU15-213001/",
            "title": "",
            "date_published": "2023-03-13T12:09:44.000Z",
            "content_html": "<h2 id=\"2015-CMU-15-213-CSAPP-深入理解计算机系统-Lecture-01-Course-Overview\"><a href=\"#2015-CMU-15-213-CSAPP-深入理解计算机系统-Lecture-01-Course-Overview\" class=\"headerlink\" title=\"2015 CMU 15-213 CSAPP 深入理解计算机系统 Lecture 01: Course Overview\"></a>2015 CMU 15-213 CSAPP 深入理解计算机系统 Lecture 01: Course Overview</h2><h3 id=\"例子一：\"><a href=\"#例子一：\" class=\"headerlink\" title=\"例子一：\"></a>例子一：</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span>&#123;</span><br>    <span class=\"hljs-keyword\">int</span> a[<span class=\"hljs-number\">2</span>];<br>    <span class=\"hljs-keyword\">double</span> d;<br>&#125;<span class=\"hljs-keyword\">struct_t</span>;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">double</span> <span class=\"hljs-title\">fun</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> i)</span></span>&#123;<br>    <span class=\"hljs-keyword\">volatile</span> <span class=\"hljs-keyword\">struct_t</span> s;   <span class=\"hljs-comment\">//volatile关键字</span><br>    s.d = <span class=\"hljs-number\">3.14</span>;<br>    s.a[i] = <span class=\"hljs-number\">1073741824</span>;   <span class=\"hljs-comment\">/*Possibly out of bounds*/</span><br>    <span class=\"hljs-keyword\">return</span> s.d;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">fun(0)   -&gt;   3.14<br>fun(1)   -&gt;   3.14<br>fun(2)   -&gt;   3.1399998664856<br>fun(3)   -&gt;   2.00000061035156<br>fun(4)   -&gt;   3.14<br>fun(6)   -&gt;   Segmentation falut<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/CMU15-213001/image-20230313201550219.png\" alt=\"image-20230313201550219\"></p>\n<p>【图中假设memory line大小为4B】根据结构体可知我们拥有一个int型的数组大小为2，一个double型的变量。因为int数组的大小为2，当fun(0),fun(1)时，s.a[i]访问是正确的，所以fun(0),fun(1)返回正确值s.d及3.14。而当fun(i):i&gt;1时，就会返回奇怪的结果，这是因为数组大小为2，我们越界了，实际上s.a[i]写的是double的内存空间，如图中的2，3。而6代表程序状态，我们去修改它就会造成程序状态的改变，导致Segmentation fault。这里提醒我们在写C代码的时候一定要注意边界处理。【这里需要清楚C语言中堆区和栈区存的是什么】</p>\n<h3 id=\"例子二：\"><a href=\"#例子二：\" class=\"headerlink\" title=\"例子二：\"></a>例子二：</h3><p><img src=\"/2023/03/13/CMU15-213001/image-20230313202535864.png\" alt=\"image-20230313202535864\"></p>\n<p>【src和dst是大小2048*2048的二维数组】上面的图片，我们可以十分清楚代码的逻辑。他想把src数组的值拷贝到dst。而左右代码的功能完全一样，仅仅是for循环顺序不一样，但是却会有这么大的性能差距，这是什么原因呢？总的来说就是左边代码cache命中率高，右边cache命中率的。cache命中和cache miss的速度差距很大甚至是数量级别的差距，这是导致两者差距巨大的原因。【注意这里还可以更细致的分析，但是会有很多其他因素会影响】</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"http://www.cs.cmu.edu/afs/cs/academic/class/15213-f15/www/index.html\">15-213: Introduction to Computer Systems (cmu.edu)</a></p>\n",
            "tags": [
                "CMU",
                "CSAPP"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/13/CMU15-213/",
            "url": "https://xingyuanjie.top/2023/03/13/CMU15-213/",
            "title": "2015 CMU 15-213 CSAPP 深入理解计算机系统",
            "date_published": "2023-03-13T10:29:35.000Z",
            "content_html": "<h1 id=\"2015-CMU-15-213-CSAPP-深入理解计算机系统\"><a href=\"#2015-CMU-15-213-CSAPP-深入理解计算机系统\" class=\"headerlink\" title=\"2015 CMU 15-213 CSAPP 深入理解计算机系统\"></a>2015 CMU 15-213 CSAPP 深入理解计算机系统</h1><p><strong>项目地址：</strong><a href=\"https://github.com/EugeneLiu/translationCSAPP\">EugeneLiu&#x2F;translationCSAPP: 为 CSAPP 视频课程提供字幕，翻译 PPT，Lab。 (github.com)</a></p>\n<p><strong>bilibili翻译：</strong><a href=\"https://www.bilibili.com/video/av31289365/\">【精校中英字幕】2015 CMU 15-213 CSAPP 深入理解计算机系统 课程视频_哔哩哔哩_bilibili</a></p>\n<h2 id=\"CSAPP-3e-官方链接\"><a href=\"#CSAPP-3e-官方链接\" class=\"headerlink\" title=\"CSAPP:3e 官方链接\"></a>CSAPP:3e 官方链接</h2><ul>\n<li><a href=\"http://csapp.cs.cmu.edu/\">课程主页</a></li>\n<li><a href=\"http://www.cs.cmu.edu/afs/cs/academic/class/15213-f15/www/schedule.html\">课件下载链接</a></li>\n<li><a href=\"http://csapp.cs.cmu.edu/3e/labs.html\">课程 Lab 页面</a></li>\n<li><a href=\"https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%22b96d90ae-9871-4fae-91e2-b1627b43e25e%22&sortColumn=0&sortAscending=true\">课程视频地址</a></li>\n</ul>\n",
            "tags": [
                "CMU",
                "CSAPP"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/13/ML003/",
            "url": "https://xingyuanjie.top/2023/03/13/ML003/",
            "title": "线性回归的梯度下降",
            "date_published": "2023-03-13T06:37:12.000Z",
            "content_html": "<h2 id=\"线性回归的梯度下降\"><a href=\"#线性回归的梯度下降\" class=\"headerlink\" title=\"线性回归的梯度下降\"></a>线性回归的梯度下降</h2><p><img src=\"/2023/03/13/ML003/image-20230313145346118.png\" alt=\"image-20230313145346118\"></p>\n<h2 id=\"Goals\"><a href=\"#Goals\" class=\"headerlink\" title=\"Goals\"></a>Goals</h2><p>在本实验中，您将:</p>\n<ul>\n<li>使用梯度下降自动优化w和b的过程</li>\n</ul>\n<h2 id=\"Tools\"><a href=\"#Tools\" class=\"headerlink\" title=\"Tools\"></a>Tools</h2><p>在本实验中，我们将使用:</p>\n<ul>\n<li>NumPy，一个用于科学计算的流行库</li>\n<li>Matplotlib，用于绘制数据的流行库</li>\n<li>在本地目录的lab_utils.py文件中绘制例程</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> math, copy<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br>plt.style.use(<span class=\"hljs-string\">&#x27;./deeplearning.mplstyle&#x27;</span>)<br><span class=\"hljs-keyword\">from</span> lab_utils_uni <span class=\"hljs-keyword\">import</span> plt_house_x, plt_contour_wgrad, plt_divergence, plt_gradients<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"Problem-Statement\"><a href=\"#Problem-Statement\" class=\"headerlink\" title=\"Problem Statement\"></a>Problem Statement</h2><p>让我们使用与之前相同的两个数据点——1000平方英尺的房子以30万美元的价格出售，2000平方英尺的房子以50万美元的价格出售。</p>\n<table>\n<thead>\n<tr>\n<th>Size(1000 sqft)</th>\n<th>Price(1000s of dollars)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>300</td>\n</tr>\n<tr>\n<td>2</td>\n<td>500</td>\n</tr>\n</tbody></table>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\">#Load our data set</span><br>x_train = np.array([<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">2.0</span>])\t<span class=\"hljs-comment\">#features</span><br>y_train = np.array([<span class=\"hljs-number\">300.0</span>,<span class=\"hljs-number\">500.0</span>])\t<span class=\"hljs-comment\">#target value</span><br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"Compute-Cost\"><a href=\"#Compute-Cost\" class=\"headerlink\" title=\"Compute_Cost\"></a>Compute_Cost</h2><p>这是上一个实验室开发的。我们在这里还会用到它。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs pyhton\">#Function to calculate the cost<br>def compute_cost(x, y, w, b,):<br>\t<br>\tm = x.shape[0]<br>\tcost = 0<br>\t<br>\tfor i in range(m):<br>\t\tf_wb = w * x[i] + b<br>\t\tcost = cost + (f_wb - y[i])**2<br>\ttotal_cost = 1 / (2 * m)*cost<br>\t<br>\treturn total_cost<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"Gradient-descent-summary\"><a href=\"#Gradient-descent-summary\" class=\"headerlink\" title=\"Gradient descent summary\"></a>Gradient descent summary</h2><p>到目前为止，在这门课程中，你已经建立了一个线性模型来预测f_w,b(x^i):</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313150848463.png\" alt=\"image-20230313150848463\"></p>\n<p>在线性回归中，您使用输入训练数据来拟合参数𝑤,𝑏;来最小化我们的预测之间的误差测量f_𝑤，𝑏(𝑥^(𝑖))和实际数据𝑦(𝑖)。这种测量成为代价，J（w,b）。在训练中，你可以衡量我们所有训练样本的成本𝑥(𝑖)，𝑦(𝑖)。</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313151251919.png\" alt=\"image-20230313151251919\"></p>\n<p>在课堂上，梯度下降被描述为:</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313151329621.png\" alt=\"image-20230313151329621\"></p>\n<p>其中参数𝑤,𝑏同时更新。</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313151450500.png\" alt=\"image-20230313151450500\"></p>\n<p>这里同时意味着在更新任何参数之前计算所有参数的偏导数。</p>\n<h2 id=\"Implement-Gradient-Descent\"><a href=\"#Implement-Gradient-Descent\" class=\"headerlink\" title=\"Implement Gradient Descent\"></a>Implement Gradient Descent</h2><p>你将为一个特征实现梯度下降算法。你需要三个函数。</p>\n<ul>\n<li>compute_gradient实现上述式(4)和(5)</li>\n<li>上面的compute_cost实现方程(2)(代码来自以前的实验室)</li>\n<li>gradient_descent，使用compute_gradient和compute_cost</li>\n</ul>\n<p>Conventions:</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313151857315.png\" alt=\"image-20230313151857315\"></p>\n<h2 id=\"compute-gradient\"><a href=\"#compute-gradient\" class=\"headerlink\" title=\"compute_gradient\"></a>compute_gradient</h2><p><img src=\"/2023/03/13/ML003/image-20230313151947363.png\" alt=\"image-20230313151947363\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">compute_gradient</span>(<span class=\"hljs-params\">x, y, w, b</span>):</span><br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    Computes the gradient for linear regression</span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">    \tx (ndarray (m,)): Data, m examples</span><br><span class=\"hljs-string\">    \ty (ndarray (m,)): target values</span><br><span class=\"hljs-string\">    \tw,b (scalar)\t: model parameters</span><br><span class=\"hljs-string\">    Returns</span><br><span class=\"hljs-string\">    \tdj_dw (scalar): The gradient of the cost w.r.t. the parameters w</span><br><span class=\"hljs-string\">    \tdj_db (scalar): The gradient of the cost w.r.t. the parameter b </span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <br>    <span class=\"hljs-comment\">#Number of training examples</span><br>    m = x.shape[<span class=\"hljs-number\">0</span>]<br>    dj_de = <span class=\"hljs-number\">0</span><br>    dj_db = <span class=\"hljs-number\">0</span><br>    <br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(m):<br>        f_wb = w * x[i] + b;<br>        dj_dw_i = (f_wb - y[i]) * x[i]<br>        dj_db_i = f_wb - y[i]<br>        dj_db += dj_db_i<br>        dj_dw += dj_dw_i<br>    dj_dw = dj_dw / m<br>    dj_db = dj_db / m<br>    <br>    <span class=\"hljs-keyword\">return</span> dj_dw, dj_db<br></code></pre></div></td></tr></table></figure>\n\n<p>课程描述了梯度下降如何利用在某一点上对参数代价的偏导数来更新该参数。</p>\n<p>让我们使用compute_gradient函数来查找并绘制代价函数相对于其中一个参数𝑤0的偏导数。</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313154012173.png\" alt=\"image-20230313154012173\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">plt_gradients(x_train,y_train, compute_cost, compute_gradient)<br>plt.show()<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/ML003/image-20230313154210478.png\" alt=\"image-20230313154210478\"></p>\n<p><img src=\"/2023/03/13/ML003/image-20230313154333429.png\" alt=\"image-20230313154333429\"></p>\n<h2 id=\"Gradient-Descent\"><a href=\"#Gradient-Descent\" class=\"headerlink\" title=\"Gradient Descent\"></a>Gradient Descent</h2><p>现在可以计算梯度，上面公式(3)中描述的梯度下降可以在下面的gradient_descent中实现。注释中描述了实现的细节。下面，您将利用这个函数在训练数据上找到w和b的最佳值。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">gradient_descent</span>(<span class=\"hljs-params\">x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function</span>):</span> <br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    Performs gradient descent to fit w,b. Updates w,b by taking </span><br><span class=\"hljs-string\">    num_iters gradient steps with learning rate alpha</span><br><span class=\"hljs-string\">    </span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">      x (ndarray (m,))  : Data, m examples </span><br><span class=\"hljs-string\">      y (ndarray (m,))  : target values</span><br><span class=\"hljs-string\">      w_in,b_in (scalar): initial values of model parameters  </span><br><span class=\"hljs-string\">      alpha (float):     Learning rate</span><br><span class=\"hljs-string\">      num_iters (int):   number of iterations to run gradient descent</span><br><span class=\"hljs-string\">      cost_function:     function to call to produce cost</span><br><span class=\"hljs-string\">      gradient_function: function to call to produce gradient</span><br><span class=\"hljs-string\">      </span><br><span class=\"hljs-string\">    Returns:</span><br><span class=\"hljs-string\">      w (scalar): Updated value of parameter after running gradient descent</span><br><span class=\"hljs-string\">      b (scalar): Updated value of parameter after running gradient descent</span><br><span class=\"hljs-string\">      J_history (List): History of cost values</span><br><span class=\"hljs-string\">      p_history (list): History of parameters [w,b] </span><br><span class=\"hljs-string\">      &quot;&quot;&quot;</span><br>    <br>    w = copy.deepcopy(w_in) <span class=\"hljs-comment\"># avoid modifying global w_in</span><br>    <span class=\"hljs-comment\"># An array to store cost J and w&#x27;s at each iteration primarily for graphing later</span><br>    J_history = []<br>    p_history = []<br>    b = b_in<br>    w = w_in<br>    <br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(num_iters):<br>        <span class=\"hljs-comment\"># Calculate the gradient and update the parameters using gradient_function</span><br>        dj_dw, dj_db = gradient_function(x, y, w , b)     <br><br>        <span class=\"hljs-comment\"># Update Parameters using equation (3) above</span><br>        b = b - alpha * dj_db                            <br>        w = w - alpha * dj_dw                            <br><br>        <span class=\"hljs-comment\"># Save cost J at each iteration</span><br>        <span class=\"hljs-keyword\">if</span> i&lt;<span class=\"hljs-number\">100000</span>:      <span class=\"hljs-comment\"># prevent resource exhaustion </span><br>            J_history.append( cost_function(x, y, w , b))<br>            p_history.append([w,b])<br>        <span class=\"hljs-comment\"># Print cost every at intervals 10 times or as many iterations if &lt; 10</span><br>        <span class=\"hljs-keyword\">if</span> i% math.ceil(num_iters/<span class=\"hljs-number\">10</span>) == <span class=\"hljs-number\">0</span>:<br>            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;Iteration <span class=\"hljs-subst\">&#123;i:<span class=\"hljs-number\">4</span>&#125;</span>: Cost <span class=\"hljs-subst\">&#123;J_history[-<span class=\"hljs-number\">1</span>]:<span class=\"hljs-number\">0.2</span>e&#125;</span> &quot;</span>,<br>                  <span class=\"hljs-string\">f&quot;dj_dw: <span class=\"hljs-subst\">&#123;dj_dw: <span class=\"hljs-number\">0.3</span>e&#125;</span>, dj_db: <span class=\"hljs-subst\">&#123;dj_db: <span class=\"hljs-number\">0.3</span>e&#125;</span>  &quot;</span>,<br>                  <span class=\"hljs-string\">f&quot;w: <span class=\"hljs-subst\">&#123;w: <span class=\"hljs-number\">0.3</span>e&#125;</span>, b:<span class=\"hljs-subst\">&#123;b: <span class=\"hljs-number\">0.5</span>e&#125;</span>&quot;</span>)<br> <br>    <span class=\"hljs-keyword\">return</span> w, b, J_history, p_history <span class=\"hljs-comment\">#return w and J,w history for graphing</span><br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">Iteration    <span class=\"hljs-number\">0</span>: Cost <span class=\"hljs-number\">7.93e+04</span>  dj_dw: -<span class=\"hljs-number\">6.500e+02</span>, dj_db: -<span class=\"hljs-number\">4.000e+02</span>   w:  <span class=\"hljs-number\">6.500e+00</span>, b: <span class=\"hljs-number\">4.00000e+00</span><br>Iteration <span class=\"hljs-number\">1000</span>: Cost <span class=\"hljs-number\">3.41e+00</span>  dj_dw: -<span class=\"hljs-number\">3.712e-01</span>, dj_db:  <span class=\"hljs-number\">6.007e-01</span>   w:  <span class=\"hljs-number\">1.949e+02</span>, b: <span class=\"hljs-number\">1.08228e+02</span><br>Iteration <span class=\"hljs-number\">2000</span>: Cost <span class=\"hljs-number\">7.93e-01</span>  dj_dw: -<span class=\"hljs-number\">1.789e-01</span>, dj_db:  <span class=\"hljs-number\">2.895e-01</span>   w:  <span class=\"hljs-number\">1.975e+02</span>, b: <span class=\"hljs-number\">1.03966e+02</span><br>Iteration <span class=\"hljs-number\">3000</span>: Cost <span class=\"hljs-number\">1.84e-01</span>  dj_dw: -<span class=\"hljs-number\">8.625e-02</span>, dj_db:  <span class=\"hljs-number\">1.396e-01</span>   w:  <span class=\"hljs-number\">1.988e+02</span>, b: <span class=\"hljs-number\">1.01912e+02</span><br>Iteration <span class=\"hljs-number\">4000</span>: Cost <span class=\"hljs-number\">4.28e-02</span>  dj_dw: -<span class=\"hljs-number\">4.158e-02</span>, dj_db:  <span class=\"hljs-number\">6.727e-02</span>   w:  <span class=\"hljs-number\">1.994e+02</span>, b: <span class=\"hljs-number\">1.00922e+02</span><br>Iteration <span class=\"hljs-number\">5000</span>: Cost <span class=\"hljs-number\">9.95e-03</span>  dj_dw: -<span class=\"hljs-number\">2.004e-02</span>, dj_db:  <span class=\"hljs-number\">3.243e-02</span>   w:  <span class=\"hljs-number\">1.997e+02</span>, b: <span class=\"hljs-number\">1.00444e+02</span><br>Iteration <span class=\"hljs-number\">6000</span>: Cost <span class=\"hljs-number\">2.31e-03</span>  dj_dw: -<span class=\"hljs-number\">9.660e-03</span>, dj_db:  <span class=\"hljs-number\">1.563e-02</span>   w:  <span class=\"hljs-number\">1.999e+02</span>, b: <span class=\"hljs-number\">1.00214e+02</span><br>Iteration <span class=\"hljs-number\">7000</span>: Cost <span class=\"hljs-number\">5.37e-04</span>  dj_dw: -<span class=\"hljs-number\">4.657e-03</span>, dj_db:  <span class=\"hljs-number\">7.535e-03</span>   w:  <span class=\"hljs-number\">1.999e+02</span>, b: <span class=\"hljs-number\">1.00103e+02</span><br>Iteration <span class=\"hljs-number\">8000</span>: Cost <span class=\"hljs-number\">1.25e-04</span>  dj_dw: -<span class=\"hljs-number\">2.245e-03</span>, dj_db:  <span class=\"hljs-number\">3.632e-03</span>   w:  <span class=\"hljs-number\">2.000e+02</span>, b: <span class=\"hljs-number\">1.00050e+02</span><br>Iteration <span class=\"hljs-number\">9000</span>: Cost <span class=\"hljs-number\">2.90e-05</span>  dj_dw: -<span class=\"hljs-number\">1.082e-03</span>, dj_db:  <span class=\"hljs-number\">1.751e-03</span>   w:  <span class=\"hljs-number\">2.000e+02</span>, b: <span class=\"hljs-number\">1.00024e+02</span><br>(w,b) found by gradient descent: (<span class=\"hljs-number\">199.9929</span>,<span class=\"hljs-number\">100.0116</span>)<br></code></pre></div></td></tr></table></figure>\n\n<p>花点时间，注意上面打印的梯度下降过程的一些特征。</p>\n<ul>\n<li>正如课堂上的幻灯片所描述的，成本开始很大，然后迅速下降。</li>\n<li>偏导数dj_dw和dj_db也变小了，起初很快，然后变慢。正如课堂上的图表所示，随着过程接近“碗底”，由于在这一点上的导数值较小，进程会变慢。</li>\n<li>尽管学习率alpha保持不变，但进程会减慢</li>\n</ul>\n<p><img src=\"/2023/03/13/ML003/image-20230313155614815.png\" alt=\"image-20230313155614815\"></p>\n<h2 id=\"Cost-versus-iterations-of-gradient-descent\"><a href=\"#Cost-versus-iterations-of-gradient-descent\" class=\"headerlink\" title=\"Cost versus iterations of gradient descent\"></a>Cost versus iterations of gradient descent</h2><p>成本与迭代的关系图是衡量梯度下降技术进展的有用方法。在成功的运行中，成本总是会降低。最初成本的变化如此之快，用不同于最终下降的尺度来描绘最初的上升是有用的。</p>\n<p>在下面的图表中，请注意轴上的成本规模和迭代步骤。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># plot cost versus iteration  </span><br>fig, (ax1, ax2) = plt.subplots(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, constrained_layout=<span class=\"hljs-literal\">True</span>, figsize=(<span class=\"hljs-number\">12</span>,<span class=\"hljs-number\">4</span>))<br>ax1.plot(J_hist[:<span class=\"hljs-number\">100</span>])<br>ax2.plot(<span class=\"hljs-number\">1000</span> + np.arange(<span class=\"hljs-built_in\">len</span>(J_hist[<span class=\"hljs-number\">1000</span>:])), J_hist[<span class=\"hljs-number\">1000</span>:])<br>ax1.set_title(<span class=\"hljs-string\">&quot;Cost vs. iteration(start)&quot;</span>);  ax2.set_title(<span class=\"hljs-string\">&quot;Cost vs. iteration (end)&quot;</span>)<br>ax1.set_ylabel(<span class=\"hljs-string\">&#x27;Cost&#x27;</span>)            ;  ax2.set_ylabel(<span class=\"hljs-string\">&#x27;Cost&#x27;</span>) <br>ax1.set_xlabel(<span class=\"hljs-string\">&#x27;iteration step&#x27;</span>)  ;  ax2.set_xlabel(<span class=\"hljs-string\">&#x27;iteration step&#x27;</span>) <br>plt.show()<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/ML003/image-20230313160112122.png\" alt=\"image-20230313160112122\"></p>\n<h2 id=\"Predictions\"><a href=\"#Predictions\" class=\"headerlink\" title=\"Predictions\"></a>Predictions</h2><p>现在您已经发现了参数𝑤的最佳值和𝑏，您现在可以使用该模型根据我们学习的参数来预测房屋价值。正如预期的那样，在相同的住房条件下，预测值与训练值几乎相同。进一步，不在预测中的值与期望值一致。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;1000 sqft house prediction <span class=\"hljs-subst\">&#123;w_final*<span class=\"hljs-number\">1.0</span> + b_final:<span class=\"hljs-number\">0.1</span>f&#125;</span> Thousand dollars&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;1200 sqft house prediction <span class=\"hljs-subst\">&#123;w_final*<span class=\"hljs-number\">1.2</span> + b_final:<span class=\"hljs-number\">0.1</span>f&#125;</span> Thousand dollars&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;2000 sqft house prediction <span class=\"hljs-subst\">&#123;w_final*<span class=\"hljs-number\">2.0</span> + b_final:<span class=\"hljs-number\">0.1</span>f&#125;</span> Thousand dollars&quot;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-number\">1000</span> sqft house prediction <span class=\"hljs-number\">300.0</span> Thousand dollars<br><span class=\"hljs-number\">1200</span> sqft house prediction <span class=\"hljs-number\">340.0</span> Thousand dollars<br><span class=\"hljs-number\">2000</span> sqft house prediction <span class=\"hljs-number\">500.0</span> Thousand dollars<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"Plotting\"><a href=\"#Plotting\" class=\"headerlink\" title=\"Plotting\"></a>Plotting</h2><p>您可以通过在代价(w,b)的等高线图上绘制迭代的代价来显示梯度下降在执行过程中的进度。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">fig, ax = plt.subplots(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>, figsize=(<span class=\"hljs-number\">12</span>, <span class=\"hljs-number\">6</span>))<br>plt_contour_wgrad(x_train, y_train, p_hist, ax)<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/ML003/image-20230313160446994.png\" alt=\"image-20230313160446994\"></p>\n<p>上面的等高线图显示了𝑤和𝑏范围内的𝑐𝑜𝑠𝑡(𝑤，𝑏)。成本水平由圆环表示。用红色箭头覆盖的是梯度下降的路径。这里有一些需要注意的事情:</p>\n<ul>\n<li>这条路径朝着它的目标稳步(单调)前进。</li>\n<li>最初的步骤比接近目标的步骤要大得多。</li>\n</ul>\n<p>放大，我们可以看到梯度下降的最后步骤。注意，阶梯之间的距离随着梯度趋近于零而缩小。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">fig, ax = plt.subplots(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>, figsize=(<span class=\"hljs-number\">12</span>, <span class=\"hljs-number\">4</span>))<br>plt_contour_wgrad(x_train, y_train, p_hist, ax, w_range=[<span class=\"hljs-number\">180</span>, <span class=\"hljs-number\">220</span>, <span class=\"hljs-number\">0.5</span>], b_range=[<span class=\"hljs-number\">80</span>, <span class=\"hljs-number\">120</span>, <span class=\"hljs-number\">0.5</span>],<br>            contours=[<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">5</span>,<span class=\"hljs-number\">10</span>,<span class=\"hljs-number\">20</span>],resolution=<span class=\"hljs-number\">0.5</span>)<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/ML003/image-20230313160944244.png\" alt=\"image-20230313160944244\"></p>\n<h2 id=\"Increased-Learning-Rate\"><a href=\"#Increased-Learning-Rate\" class=\"headerlink\" title=\"Increased Learning Rate\"></a>Increased Learning Rate</h2><p>在这节课中，在式(3)中有一个关于学习率的合适值𝛼的讨论。𝛼越大，梯度下降收敛到解的速度就越快。但是，如果它太大，梯度下降就会发散。上面有一个很好收敛的解的例子。让我们试着增加𝛼的值看看会发生什么:</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313161516209.png\" alt=\"image-20230313161516209\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># initialize parameters</span><br>w_init = <span class=\"hljs-number\">0</span><br>b_init = <span class=\"hljs-number\">0</span><br><span class=\"hljs-comment\"># set alpha to a large value</span><br>iterations = <span class=\"hljs-number\">10</span><br>tmp_alpha = <span class=\"hljs-number\">8.0e-1</span><br><span class=\"hljs-comment\"># run gradient descent</span><br>w_final, b_final, J_hist, p_hist = gradient_descent(x_train ,y_train, w_init, b_init, tmp_alpha, <br>                                                    iterations, compute_cost, compute_gradient)<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs pyhton\">Iteration    0: Cost 2.58e+05  dj_dw: -6.500e+02, dj_db: -4.000e+02   w:  5.200e+02, b: 3.20000e+02<br>Iteration    1: Cost 7.82e+05  dj_dw:  1.130e+03, dj_db:  7.000e+02   w: -3.840e+02, b:-2.40000e+02<br>Iteration    2: Cost 2.37e+06  dj_dw: -1.970e+03, dj_db: -1.216e+03   w:  1.192e+03, b: 7.32800e+02<br>Iteration    3: Cost 7.19e+06  dj_dw:  3.429e+03, dj_db:  2.121e+03   w: -1.551e+03, b:-9.63840e+02<br>Iteration    4: Cost 2.18e+07  dj_dw: -5.974e+03, dj_db: -3.691e+03   w:  3.228e+03, b: 1.98886e+03<br>Iteration    5: Cost 6.62e+07  dj_dw:  1.040e+04, dj_db:  6.431e+03   w: -5.095e+03, b:-3.15579e+03<br>Iteration    6: Cost 2.01e+08  dj_dw: -1.812e+04, dj_db: -1.120e+04   w:  9.402e+03, b: 5.80237e+03<br>Iteration    7: Cost 6.09e+08  dj_dw:  3.156e+04, dj_db:  1.950e+04   w: -1.584e+04, b:-9.80139e+03<br>Iteration    8: Cost 1.85e+09  dj_dw: -5.496e+04, dj_db: -3.397e+04   w:  2.813e+04, b: 1.73730e+04<br>Iteration    9: Cost 5.60e+09  dj_dw:  9.572e+04, dj_db:  5.916e+04   w: -4.845e+04, b:-2.99567e+04<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/ML003/image-20230313161636772.png\" alt=\"image-20230313161636772\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">plt_divergence(p_hist, J_hist,x_train, y_train)<br>plt.show()<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/ML003/image-20230313161959222.png\" alt=\"image-20230313161959222\"></p>\n<p>上图中，左图显示了𝑤在梯度下降的前几个步骤中的进展。𝑤从正振荡到负，成本迅速增长。梯度下降同时在𝑤和𝑏上运行，所以需要右边的3d图才能看到完整的图片。</p>\n<h2 id=\"Congratulations\"><a href=\"#Congratulations\" class=\"headerlink\" title=\"Congratulations!\"></a>Congratulations!</h2><p>在这个实验室里，你:</p>\n<ul>\n<li>深入研究单个变量的梯度下降的细节。</li>\n<li>开发了一个计算梯度的程序</li>\n<li>看看梯度是什么</li>\n<li>完成一个梯度下降程序</li>\n<li>利用梯度下降法寻找参数</li>\n<li>检查了学习率大小的影响</li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://www.bilibili.com/video/BV1Pa411X76s?p=5&amp;vd_source=3ae32e36058f58c5b85935fca9b77797\">https://www.bilibili.com/video/BV1Pa411X76s?p=5&amp;vd_source=3ae32e36058f58c5b85935fca9b77797</a></p>\n<p><a href=\"https://github.com/kaieye/2022-Machine-Learning-Specialization\">kaieye&#x2F;2022-Machine-Learning-Specialization (github.com)</a></p>\n",
            "tags": [
                "Tensorflow",
                "Machine Learning"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/12/ML002/",
            "url": "https://xingyuanjie.top/2023/03/12/ML002/",
            "title": "代价函数",
            "date_published": "2023-03-12T08:33:17.000Z",
            "content_html": "<h2 id=\"代价函数\"><a href=\"#代价函数\" class=\"headerlink\" title=\"代价函数\"></a>代价函数</h2><p><img src=\"/2023/03/12/ML002/image-20230312164306128.png\" alt=\"image-20230312164306128\"></p>\n<h2 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标\"></a>目标</h2><p>在本实验中，你将:</p>\n<ul>\n<li>你将实现和探索成本函数的线性回归伴随一个变量。</li>\n</ul>\n<h2 id=\"工具\"><a href=\"#工具\" class=\"headerlink\" title=\"工具\"></a>工具</h2><p>在本实验室中，我们将使用:</p>\n<ul>\n<li>NumPy，一个用于科学计算的流行库</li>\n<li>Matplotlib，用于绘制数据的流行库</li>\n<li>本地目录的lab_utils_uni.py文件中的本地绘图例程</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> nunpy <span class=\"hljs-keyword\">as</span> np<br>%matplotlib widget<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">from</span> lab_utils_uni <span class=\"hljs-keyword\">import</span> plt_intuition, plt_stationary, plt_updata_onclick, soup_bowl<br>plt.style.use(<span class=\"hljs-string\">&#x27;./deeplearning.mplstyle&#x27;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"问题意境\"><a href=\"#问题意境\" class=\"headerlink\" title=\"问题意境\"></a>问题意境</h2><p>你想要一个模型，它可以根据房子的大小预测房价。让我们使用与上一个实验室之前相同的两个数据点——一个1000平方英尺的房子卖了30万美元，一个2000平方英尺的房子卖了50万美元。</p>\n<table>\n<thead>\n<tr>\n<th>Size(1000 sqft)</th>\n<th>Price(1000s of dollars)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>300</td>\n</tr>\n<tr>\n<td>2</td>\n<td>500</td>\n</tr>\n</tbody></table>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">x_train = np.array([<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">2.0</span>])   <span class=\"hljs-comment\">#(size in 1000 square feet)</span><br>y_train = np.zrray([<span class=\"hljs-number\">300.0</span>, <span class=\"hljs-number\">500.0</span>])\t<span class=\"hljs-comment\">#(price in 1000s of dollars)</span><br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"计算代价\"><a href=\"#计算代价\" class=\"headerlink\" title=\"计算代价\"></a>计算代价</h2><p>这个作业中的术语“成本”可能会让人有点困惑，因为数据是住房成本。在这里，成本是衡量我们的模型预测房子目标价格的好坏。“价格”一词指的是住房数据。</p>\n<p>含一个变量的成本方程为:</p>\n<p><img src=\"/2023/03/12/ML002/image-20230312165434160.png\" alt=\"image-20230312165434160\"></p>\n<p>在这里</p>\n<p><img src=\"/2023/03/12/ML002/image-20230312165503613.png\" alt=\"image-20230312165503613\"></p>\n<ul>\n<li>f_w,b(x^i)是我们使用参数w,b来预测例子i。</li>\n<li>（f_w,b(x^i) - y^i）^2  是目标值与预测值之间的差的平方</li>\n<li>这些差异被加在所有m例子上，再除以2m，得到代价函数 <strong>J（w,b）</strong></li>\n</ul>\n<p>注意，在讲座中，总和的范围通常是从1到m，而代码将从0到m-1。</p>\n<p>下面的代码通过遍历每个示例来计算成本。在每个循环中:</p>\n<ul>\n<li>f_wb，计算一个预测</li>\n<li>目标和预测之间的差值被计算和平方。</li>\n<li>这被加到总成本中。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">compute_cost</span>(<span class=\"hljs-params\">x, y, w, b</span>):</span><br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    Computes the cost function for linear regression</span><br><span class=\"hljs-string\">    </span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">    \tx (ndarray (m,)):Data, m examples</span><br><span class=\"hljs-string\">    \ty (ndarray (m,)):target values</span><br><span class=\"hljs-string\">    \tw,b (scalar)\t:model parameters</span><br><span class=\"hljs-string\">    </span><br><span class=\"hljs-string\">    Returns</span><br><span class=\"hljs-string\">    \ttotal_cost (float):The cost of using w,b as the parameters for linear regression to fit the data points in x and y</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\">#number of training examples</span><br>    m = x.shape[<span class=\"hljs-number\">0</span>]<br>    <br>    cost_sum = <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(m):<br>        f_wb = w * x[i] + b<br>        cost = (f_wb - y[i])**<span class=\"hljs-number\">2</span><br>        cost_sum = cost_sum + cost<br>    total_cost = (<span class=\"hljs-number\">1</span>/(<span class=\"hljs-number\">2</span>*m)) * cost_sum<br>    <br>    <span class=\"hljs-keyword\">return</span> total_cost<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"Cost-Function-Intuition\"><a href=\"#Cost-Function-Intuition\" class=\"headerlink\" title=\"Cost Function Intuition\"></a>Cost Function Intuition</h2><p><img src=\"/2023/03/12/ML002/image-20230312172325465.png\" alt=\"image-20230312172325465\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">plt_intuition(x_train, y_train)<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/12/ML002/image-20230313144221393.png\" alt=\"image-20230313144221393\"></p>\n<p>情节中有几点值得一提。</p>\n<ul>\n<li>当𝑤&#x3D;200时，成本最小化，这与之前实验室的结果相吻合。</li>\n<li>因为在成本方程中，目标和预测之间的差异是平方，当𝑤时，成本迅速增加不是太大就是太小。</li>\n<li>使用通过最小化成本选择的w和b，可以得到与数据完美匹配的直线。</li>\n</ul>\n<h2 id=\"Cost-Function-Visualiztion-3D\"><a href=\"#Cost-Function-Visualiztion-3D\" class=\"headerlink\" title=\"Cost Function Visualiztion-3D\"></a>Cost Function Visualiztion-3D</h2><p>你可以通过三维绘图或等高线图看到成本是如何随w和b变化的。</p>\n<p>值得注意的是，这门课的一些情节会变得相当复杂。本文提供了绘图例程，虽然通读代码以熟悉这些方法是有指导意义的，但要成功完成课程并不需要这样做。例程在本地目录lab_utils_uni.py中。</p>\n<h2 id=\"Larger-Data-Set\"><a href=\"#Larger-Data-Set\" class=\"headerlink\" title=\"Larger Data Set\"></a>Larger Data Set</h2><p>较大的数据集用更多的数据点来观察一个场景是很有指导意义的。该数据集包括不在同一线上的数据点。这对成本方程意味着什么?我们能找到𝑤、𝑏那样使得代价是0?</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">x_train = np.array([<span class=\"hljs-number\">1.0</span>,<span class=\"hljs-number\">1.7</span>,<span class=\"hljs-number\">2.0</span>,<span class=\"hljs-number\">2.5</span>,<span class=\"hljs-number\">3.0</span>,<span class=\"hljs-number\">3.2</span>])<br>y_train = np.array([<span class=\"hljs-number\">250</span>,<span class=\"hljs-number\">300</span>,<span class=\"hljs-number\">480</span>,<span class=\"hljs-number\">430</span>,<span class=\"hljs-number\">630</span>,<span class=\"hljs-number\">730</span>])<br></code></pre></div></td></tr></table></figure>\n\n<p>在等高线图中，点击一个点，选择w和b，以达到最低的成本。使用轮廓来指导你的选择。注意，更新图形可能需要几秒钟的时间。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">plt.close(<span class=\"hljs-string\">&#x27;all&#x27;</span>)<br>fig, ax ,dyn_items = plt_stationary(x_train, y_train)<br>updater = plt_update_onclick(fig, ax, x_train,y_train,dyn_items)<br></code></pre></div></td></tr></table></figure>\n\n<p>上面，注意左边图中的虚线。这些代表了你的训练集中每个例子所贡献的代价的部分。在本例中，值约为𝑤&#x3D;209和𝑏&#x3D; 2.4提供低代价。请注意，因为我们的训练示例不在一条线上，所以最小代价不为零。</p>\n<h2 id=\"Convex-Cost-surface\"><a href=\"#Convex-Cost-surface\" class=\"headerlink\" title=\"Convex Cost surface\"></a>Convex Cost surface</h2><p>成本函数平方损失的事实确保了“误差曲面”像汤碗一样凸出。它总是有一个最小值，可以通过在所有维度上跟随梯度来达到。在前面的图中，因为𝑤和𝑏尺寸比例不同，这是不容易识别的。下图，其中𝑤和𝑏都是对称的，在讲座中展示过:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">soup_bowl()<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"Congratulations\"><a href=\"#Congratulations\" class=\"headerlink\" title=\"Congratulations!\"></a>Congratulations!</h2><p>您已经学习了以下内容:</p>\n<ul>\n<li>成本方程提供了一种衡量预测与训练数据匹配程度的方法。</li>\n<li>最小化成本可以提供𝑤和b的最优值。</li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://www.bilibili.com/video/BV1Pa411X76s?p=5&amp;vd_source=3ae32e36058f58c5b85935fca9b77797\">https://www.bilibili.com/video/BV1Pa411X76s?p=5&amp;vd_source=3ae32e36058f58c5b85935fca9b77797</a></p>\n<p><a href=\"https://github.com/kaieye/2022-Machine-Learning-Specialization\">kaieye&#x2F;2022-Machine-Learning-Specialization (github.com)</a></p>\n",
            "tags": [
                "Tensorflow",
                "Machine Learning"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/10/avx006/",
            "url": "https://xingyuanjie.top/2023/03/10/avx006/",
            "title": "如何使用AVX和AVX2处理数据(个人翻译)",
            "date_published": "2023-03-10T06:51:44.000Z",
            "content_html": "<h2 id=\"1-文章来源\"><a href=\"#1-文章来源\" class=\"headerlink\" title=\"1.文章来源\"></a>1.文章来源</h2><p><strong>Matt Scarpino（USA）</strong></p>\n<p><a href=\"https://www.codeproject.com/Articles/874396/Crunching-Numbers-with-AVX-and-AVX\">Crunching Numbers with AVX and AVX2 - CodeProject</a></p>\n<h2 id=\"2-介绍\"><a href=\"#2-介绍\" class=\"headerlink\" title=\"2.介绍\"></a>2.介绍</h2><p>在2003年，<a href=\"https://www.codeproject.com/script/Membership/View.aspx?mid=22834\">Alex Fr</a>写了一篇优秀的<a href=\"https://www.codeproject.com/Articles/4522/Introduction-to-SSE-Programming\">文章</a>[该文章现在已经被原作者删除]，解释了如何使用Intel的流式SIMD扩展(SSE)执行SIMD(单指令，多数据)处理。SSE是英特尔处理器支持的一组指令，可对大量数据执行高速运算。</p>\n<p>2008年，英特尔推出了一套新的高性能指令，称为高级向量扩展(AVX)。AVX执行许多与SSE指令相同的操作，但以更快的速度对更大的数据块进行操作。最近，英特尔在AVX2和AVX512系列中发布了额外的指令。本文的重点是通过称为intrinsic funtions的特殊C函数访问AVX和AVX2指令。</p>\n<p>本文不介绍整个AVX&#x2F;AVX2 intrinsics，而是侧重于数学计算。特别地，目标是复数相乘。要使用AVX&#x2F;AVX2执行此操作，需要三种类型的intrinsic:</p>\n<ol>\n<li>Initialization intrinscis</li>\n<li>Arithmetic intrinsics</li>\n<li>Permute&#x2F;shuffle intrinsics</li>\n</ol>\n<p>\t\t</p>\n<p>本文讨论每个类别中的intrinsics，并解释如何在代码中使用它们。本文的最后将展示如何用这些intrinsic进行乘法复数运算。</p>\n<p>理解处理器指令和intrinsic function之间的区别是很重要的。AVX指令是执行不可分割操作的汇编命令。例如，AVX指令vaddps添加了两个操作数，并将结果放在第三个操作数中。</p>\n<p>要在C&#x2F;C++中执行操作，the intrinsic funtion _mm256_add_ps()直接映射到vaddps，将汇编的性能与高级函数的便利性结合起来。An intrinsic funtion不一定映射到单个指令，但与其他C&#x2F; C++函数相比，AVX&#x2F;AVX2 intrinsics提供了可靠的高性能。</p>\n<h2 id=\"3-基本要求\"><a href=\"#3-基本要求\" class=\"headerlink\" title=\"3.基本要求\"></a>3.基本要求</h2><p>要理解本文的内容，您需要基本熟悉C语言和SIMD处理。要执行代码，您需要一个支持AVX或AVX&#x2F;AVX2的CPU。以下是支持AVX的cpu:</p>\n<ul>\n<li>Intel’s Sandy Bridge&#x2F;Sandy Bridge E&#x2F;Ivy Bridge&#x2F;Ivy Bridge E</li>\n<li>Intel’s Haswell&#x2F;Haswell E&#x2F;Broadwell&#x2F;Broadwell E</li>\n<li>AMD’s Bulldozer&#x2F;Piledriver&#x2F;Steamroller&#x2F;Excavator</li>\n</ul>\n<p>支持AVX2的CPU也支持AVX。以下是这些设备:</p>\n<ul>\n<li>Intel’s Haswell&#x2F;Haswell E&#x2F;Broadwell&#x2F;Broadwell E</li>\n<li>AMD’s Excavator</li>\n</ul>\n<p>本文中讨论的大多数函数都是由AVX提供的。但也有一些是AVX2特有的。为了区分它们，在本文的表中，我在AVX2 intrinsic的名称前面加上(2)。</p>\n<p>[个人补充]</p>\n<p>判断自己电脑CPU是否支持AVX和AVX2，最简单的就是在命令行执行以下命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">lscpu<br></code></pre></div></td></tr></table></figure>\n\n<p>你会得到以下结果：</p>\n<p><img src=\"/2023/03/10/avx006/image-20230129153048825.png\" alt=\"image-20230129153048825\"></p>\n<p>在Flags里面你可以清楚的看到你的电脑是否支持AVX以及AVX2。</p>\n<h2 id=\"4-向量化概述\"><a href=\"#4-向量化概述\" class=\"headerlink\" title=\"4.向量化概述\"></a>4.向量化概述</h2><p>AVX指令通过同时处理大块值而不是单独处理值来提高应用程序的性能。这些值大块称为向量，AVX向量最多可以包含256位数据。</p>\n<p>常见的AVX向量包含4个double (4 x 64位&#x3D; 256)，8个float (8 x 32位&#x3D; 256)或8个int (8 x 32位&#x3D; 256)。[double 8B, flout 4B, int 4B]</p>\n<p>一个示例将演示AVX&#x2F;AVX2处理的强大功能。假设一个函数需要将一个数组的8个浮点数乘以第二个数组的8个浮点数，并将结果添加到第三个数组。如果没有向量化，函数可能是这样的:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">multiply_and_add</span>(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">float</span>* a, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">float</span>* b, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">float</span>* c, <span class=\"hljs-keyword\">float</span>* d) &#123;  <br><br>  <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i=<span class=\"hljs-number\">0</span>; i&lt;<span class=\"hljs-number\">8</span>; i++) &#123;<br>    d[i] = a[i] * b[i];<br>    d[i] = d[i] + c[i];<br>  &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>下面是使用AVX2函数的例子:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__m256 <span class=\"hljs-title\">multiply_and_add</span><span class=\"hljs-params\">(__m256 a, __m256 b, __m256 c)</span> </span>&#123;<br><br>  <span class=\"hljs-keyword\">return</span> _mm256_fmadd_ps(a, b, c);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>This AVX2 intrinsic funtion <strong>_mm256_fmadd_ps</strong>处理24个floats，但它不映射到单个指令。相反，它执行三个指令:<strong>vfmadd132ps</strong>、<strong>vfmadd213ps</strong>和<strong>vfmadd231ps</strong>。尽管如此，它执行得很快，比遍历单个元素快得多。</p>\n<p>尽管英特尔的intrinsics功能强大，但它们还是让许多程序员感到紧张。这通常有两个原因。首先，数据类型有奇怪的名字，比如**__m256<strong>。其次，函数有奇怪的名称，如</strong>_mm256_fmadd_ps**。因此，在详细讨论intrinsic funtions之前，我想先讨论一下Intel的数据类型和命名约定。</p>\n<h2 id=\"5-AVX编程基础\"><a href=\"#5-AVX编程基础\" class=\"headerlink\" title=\"5.AVX编程基础\"></a>5.AVX编程基础</h2><p>本文主要关注AVX和AVX2提供的与数学相关的intrinsic functions。但在看函数之前，有三点很重要:</p>\n<ul>\n<li>Data types</li>\n<li>Function naming conventions</li>\n<li>Compiling AVX applications</li>\n</ul>\n<p>本节涉及这些要点，并提供一个简单的应用程序，用于一个向量减去另一个向量。</p>\n<h3 id=\"5-1数据类型\"><a href=\"#5-1数据类型\" class=\"headerlink\" title=\"5.1数据类型\"></a>5.1数据类型</h3><p>少数intrinsic接受传统的数据类型，如<strong>int</strong>或<strong>float</strong>，但大多数intrinsic操作有特定的AVX和AVX2的数据类型。有六种主要的向量类型，表1列出了它们。</p>\n<p><strong>Table 1:AVX&#x2F;AVX2 Data Types</strong></p>\n<table>\n<thead>\n<tr>\n<th>Data Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>__m128</code></td>\n<td>128-bit vector containing 4 <code>float</code>s</td>\n</tr>\n<tr>\n<td><code>__m128d</code></td>\n<td>128-bit vector containing 2 <code>double</code>s</td>\n</tr>\n<tr>\n<td><code>__m128i</code></td>\n<td>128-bit vector containing integers</td>\n</tr>\n<tr>\n<td><code>__m256</code></td>\n<td>256-bit vector containing 8 <code>float</code>s</td>\n</tr>\n<tr>\n<td><code>__m256d</code></td>\n<td>256-bit vector containing 4 <code>double</code>s</td>\n</tr>\n<tr>\n<td><code>__m256i</code></td>\n<td>256-bit vector containing integers</td>\n</tr>\n</tbody></table>\n<p>每种类型都以两个下划线、一个m和向量的宽度(以位为单位)开始。AVX512支持以_m512开头的512位向量类型，但AVX&#x2F;AVX2向量不超过256位。如果向量类型以d结尾，则代表double，如果没有后缀，则代表float。看起来_m128i和_m256i向量必须包含int型，但事实并非如此。整数向量类型可以包含任何类型的整数，from chars to shorts to unsigned long longs.That is, an _m256i may contain 32 chars, 16 shorts, 8 ints, or 4 longs.  These integers can be signed or unsigned.</p>\n<h3 id=\"5-3函数命名约定\"><a href=\"#5-3函数命名约定\" class=\"headerlink\" title=\"5.3函数命名约定\"></a>5.3函数命名约定</h3><p>AVX&#x2F;AVX2 intrinsics的名称一开始可能令人困惑，但命名约定确是非常直白的。一旦你理解了它，你就可以通过看它的名字来大致判断一个函数是做什么的。AVX&#x2F;AVX2 intrinsics的一般形式如下:</p>\n<p>_mm<bit_width>_<name>_<data_type></data_type></name></bit_width></p>\n<p>该格式的各部分如下所示:</p>\n<ol>\n<li><code>&lt;bit_width&gt;</code> identifies the size of the vector returned by the function. For 128-bit vectors, this is empty. For 256-bit vectors, this is set to <code>256</code>.</li>\n<li><code>&lt;name&gt;</code> describes the operation performed by the intrinsic</li>\n<li><code>&lt;data_type&gt;</code> identifies the data type of the function’s primary arguments</li>\n</ol>\n<p>最后一部分<data_type>有点复杂。它标识输入值的内容，可以设置为以下任何值:</data_type></p>\n<ul>\n<li><code>ps</code> - vectors contain <code>float</code>s (<code>ps</code> stands for packed single-precision)</li>\n<li><code>pd</code> - vectors contain <code>double</code>s (<code>pd</code> stands for packed double-precision)</li>\n<li><code>epi8/epi16/epi32/epi64</code> - vectors contain 8-bit&#x2F;16-bit&#x2F;32-bit&#x2F;64-bit signed integers</li>\n<li><code>epu8/epu16/epu32/epu64</code> - vectors contain 8-bit&#x2F;16-bit&#x2F;32-bit&#x2F;64-bit unsigned integers</li>\n<li><code>si128</code>&#x2F;<code>si256</code> - unspecified 128-bit vector or 256-bit vector</li>\n<li><code>m128/m128i/m128d/m256/m256i/m256d</code> - identifies input vector types when they’re different than the type of the returned vector</li>\n</ul>\n<p>例如，考虑_mm256_srlv_epi64。即使您不知道srlv是什么意思，_mm256前缀告诉您该函数返回一个256位向量，_epi64告诉您参数包含64位有符号整数。</p>\n<p>作为第二个示例，考虑_mm_testnzc_ps。_mm表示函数返回一个128位的向量。末尾的_ps表示参数向量包含浮点数。</p>\n<p>AVX数据类型以两个下划线和一个m开头。函数以一个下划线和两个m开头。我很容易搞混这一点，所以我想出了一种方法来记住它们的区别:数据类型代表内存（<strong>m</strong>emory），函数代表多媒体操作（<strong>m</strong>ulti<strong>m</strong>edia）。这是我能做的最好的了。</p>\n<h3 id=\"5-4构建AVX应用程序\"><a href=\"#5-4构建AVX应用程序\" class=\"headerlink\" title=\"5.4构建AVX应用程序\"></a>5.4构建AVX应用程序</h3><p>要构建使用AVX intrinsic的应用程序，不需要链接任何库。但是您需要包含<strong>imminrin .h</strong>头文件。此头文件包括将AVX&#x2F;AVX2函数映射到指令的其他头文件。</p>\n<p>hello_avx.c中的代码显示了一个基本的AVX应用程序的样子:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;immintrin.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br><br>  <span class=\"hljs-comment\">/* Initialize the two argument vectors */</span>\t\t\t<span class=\"hljs-comment\">//初始化</span><br>  __m256 evens = _mm256_set_ps(<span class=\"hljs-number\">2.0</span>, <span class=\"hljs-number\">4.0</span>, <span class=\"hljs-number\">6.0</span>, <span class=\"hljs-number\">8.0</span>, <span class=\"hljs-number\">10.0</span>, <span class=\"hljs-number\">12.0</span>, <span class=\"hljs-number\">14.0</span>, <span class=\"hljs-number\">16.0</span>);<br>  __m256 odds = _mm256_set_ps(<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">3.0</span>, <span class=\"hljs-number\">5.0</span>, <span class=\"hljs-number\">7.0</span>, <span class=\"hljs-number\">9.0</span>, <span class=\"hljs-number\">11.0</span>, <span class=\"hljs-number\">13.0</span>, <span class=\"hljs-number\">15.0</span>);<br><br>  <span class=\"hljs-comment\">/* Compute the difference between the two vectors */</span><br>  __m256 result = _mm256_sub_ps(evens, odds);\t\t\t<span class=\"hljs-comment\">//减法</span><br><br>  <span class=\"hljs-comment\">/* Display the elements of the result vector */</span><br>  <span class=\"hljs-keyword\">float</span>* f = (<span class=\"hljs-keyword\">float</span>*)&amp;result;\t\t\t\t\t<span class=\"hljs-comment\">//类型转换</span><br>  <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%f %f %f %f %f %f %f %f\\n&quot;</span>,<br>    f[<span class=\"hljs-number\">0</span>], f[<span class=\"hljs-number\">1</span>], f[<span class=\"hljs-number\">2</span>], f[<span class=\"hljs-number\">3</span>], f[<span class=\"hljs-number\">4</span>], f[<span class=\"hljs-number\">5</span>], f[<span class=\"hljs-number\">6</span>], f[<span class=\"hljs-number\">7</span>]);<br><br>  <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>要构建应用程序，需要告诉编译器该体系结构支持AVX。这个标志取决于编译器，gcc需要-mavx标志。因此，可以使用以下命令编译hello_avx.c源文件:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">gcc -mavx -o hello_avx hello_avx.c<br></code></pre></div></td></tr></table></figure>\n\n<p>在本例中，所有函数都以_mm256开始，以_ps结束，因此我希望所有操作都清楚地涉及包含floats的256位向量。我还希望结果向量中的每个元素都等于1.0。如果运行应用程序，您将看到情况就是这样。</p>\n<p>[这就是一个简单的向量减法例子，大家可以对应数据看一下]</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"5-5初始化intrinsics\"><a href=\"#5-5初始化intrinsics\" class=\"headerlink\" title=\"5.5初始化intrinsics\"></a>5.5初始化intrinsics</h3><p>在对AVX向量进行操作之前，需要用数据填充向量。因此，本文讨论的第一组intrinsics用数据初始化向量。有两种方法:用标量值初始化向量和用从内存加载的数据初始化向量。</p>\n<h4 id=\"5-5-1使用标量值初始化\"><a href=\"#5-5-1使用标量值初始化\" class=\"headerlink\" title=\"5.5.1使用标量值初始化\"></a>5.5.1使用标量值初始化</h4><p>AVX提供了将一个或多个值组合成256位向量的intrinsics funtions。表2列出了它们的名称，并提供了每个名称的描述。也有类似的intrinsics初始化128位向量，但它们是由SSE提供的，而不是AVX。函数名的唯一区别是_mm256_被替换为_mm_。</p>\n<p><strong>Table 2: Initialization Intrinsics</strong></p>\n<table>\n<thead>\n<tr>\n<th>Function</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>_mm256_setzero_ps/pd</code></td>\n<td>Returns a floating-point vector filled with zeros</td>\n</tr>\n<tr>\n<td><code>_mm256_setzero_si256</code></td>\n<td>Returns an integer vector whose bytes are set to zero</td>\n</tr>\n<tr>\n<td><code>_mm256_set1_ps/pd</code></td>\n<td>Fill a vector with a floating-point value</td>\n</tr>\n<tr>\n<td><code>_mm256_set1_epi8/epi16</code> <code>_mm256_set1_epi32/epi64</code></td>\n<td>Fill a vector with an integer</td>\n</tr>\n<tr>\n<td><code>_mm256_set_ps/pd</code></td>\n<td>Initialize a vector with eight floats (ps) or four doubles (pd)</td>\n</tr>\n<tr>\n<td><code>_mm256_set_epi8/epi16</code> <code>_mm256_set_epi32/epi64</code></td>\n<td>Initialize a vector with integers</td>\n</tr>\n<tr>\n<td><code>_mm256_set_m128/m128d/</code> <code>_mm256_set_m128i</code></td>\n<td>Initialize a 256-bit vector with two 128-bit vectors</td>\n</tr>\n<tr>\n<td><code>_mm256_setr_ps/pd</code></td>\n<td>Initialize a vector with eight floats (ps) or four doubles (pd) in reverse order</td>\n</tr>\n<tr>\n<td><code>_mm256_setr_epi8/epi16</code> <code>_mm256_setr_epi32/epi64</code></td>\n<td>Initialize a vector with integers in reverse order</td>\n</tr>\n</tbody></table>\n<p>表中的第一个函数是最容易理解的。_m256_setzero_ps返回一个__m256向量，包含8个设置为0的浮点数。类似地，_m256_setzero_si256返回一个__m256i向量，其字节被设置为0。例如，下面这行代码创建了一个256位的向量，其中包含4个设为0的double:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">_m256d dbl_vector = _m256_setzero_pd();<br></code></pre></div></td></tr></table></figure>\n\n<p>名称中包含set1的函数接受一个值，并在整个向量中重复该值。例如，下面这行代码创建了一个__m256i，它的16个short value被设置为47:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">_m256i short_vector = _m256_set1_pd();<br></code></pre></div></td></tr></table></figure>\n\n<p>表2中的其他函数包含_set_或_setr_。这些函数接受一系列值，每个向量的元素对应一个值。这些值被放置在返回的向量中，理解顺序很重要。下面的函数调用返回一个包含8个整数的向量，其值范围为1到8:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">_m256i int_vector = _m256_set_epi32(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">6</span>, <span class=\"hljs-number\">7</span>, <span class=\"hljs-number\">8</span>);<br></code></pre></div></td></tr></table></figure>\n\n<p>您可能希望值按照给定的顺序存储。但英特尔的架构是<strong>小端</strong>存储类型的[这里很重要]，所以最低有效值(8)先存储，最高有效值(1)最后存储。您可以通过将int_vector转换为int指针并打印存储的值来验证这一点。如下代码所示:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">__m256i int_vector = _mm256_set_epi32(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">6</span>, <span class=\"hljs-number\">7</span>, <span class=\"hljs-number\">8</span>);<br><span class=\"hljs-keyword\">int</span> *ptr = (<span class=\"hljs-keyword\">int</span>*)&amp;int_vector;<br><span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%d %d %d %d %d %d %d %d\\n&quot;</span>, ptr[<span class=\"hljs-number\">0</span>], ptr[<span class=\"hljs-number\">1</span>], ptr[<span class=\"hljs-number\">2</span>], ptr[<span class=\"hljs-number\">3</span>], ptr[<span class=\"hljs-number\">4</span>], ptr[<span class=\"hljs-number\">5</span>], ptr[<span class=\"hljs-number\">6</span>], ptr[<span class=\"hljs-number\">7</span>]);<br>--&gt; <span class=\"hljs-number\">8</span> <span class=\"hljs-number\">7</span> <span class=\"hljs-number\">6</span> <span class=\"hljs-number\">5</span> <span class=\"hljs-number\">4</span> <span class=\"hljs-number\">3</span> <span class=\"hljs-number\">2</span> <span class=\"hljs-number\">1</span><br></code></pre></div></td></tr></table></figure>\n\n<p>如果希望值按给定顺序存储，可以使用_setr_函数之一创建向量，其中r可能代表reverse。下面的代码展示了它是如何工作的:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">__m256i int_vector = _mm256_setr_epi32(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">6</span>, <span class=\"hljs-number\">7</span>, <span class=\"hljs-number\">8</span>);<br><span class=\"hljs-keyword\">int</span> *ptr = (<span class=\"hljs-keyword\">int</span>*)&amp;int_vector;<br><span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%d %d %d %d %d %d %d %d\\n&quot;</span>, ptr[<span class=\"hljs-number\">0</span>], ptr[<span class=\"hljs-number\">1</span>], ptr[<span class=\"hljs-number\">2</span>], ptr[<span class=\"hljs-number\">3</span>], ptr[<span class=\"hljs-number\">4</span>], ptr[<span class=\"hljs-number\">5</span>], ptr[<span class=\"hljs-number\">6</span>], ptr[<span class=\"hljs-number\">7</span>]);<br>--&gt; <span class=\"hljs-number\">1</span> <span class=\"hljs-number\">2</span> <span class=\"hljs-number\">3</span> <span class=\"hljs-number\">4</span> <span class=\"hljs-number\">5</span> <span class=\"hljs-number\">6</span> <span class=\"hljs-number\">7</span> <span class=\"hljs-number\">8</span><br></code></pre></div></td></tr></table></figure>\n\n<p>有趣的是，AVX和AVX2都没有提供用无符号整数初始化向量的intrinsic。但是，它们提供了对带无符号整数的向量进行操作的函数。</p>\n<h4 id=\"5-5-2从内存加载数据\"><a href=\"#5-5-2从内存加载数据\" class=\"headerlink\" title=\"5.5.2从内存加载数据\"></a>5.5.2从内存加载数据</h4><p>AVX&#x2F;AVX2的一个常见用法是将数据从内存加载到向量中，对向量进行处理，并将结果存储回内存。第一步是使用表3中列出的intrinsic funtions完成的。最后两个函数前面有(2)，因为它们是由AVX2而不是AVX提供的。</p>\n<p><strong>Table 3: Vector Load Intrinsics</strong></p>\n<table>\n<thead>\n<tr>\n<th>Data Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>_mm256_load_ps/pd</code></td>\n<td>Loads a floating-point vector from an  aligned memory address</td>\n</tr>\n<tr>\n<td><code>_mm256_load_si256</code></td>\n<td>Loads an integer vector from an aligned memory address</td>\n</tr>\n<tr>\n<td><code>_mm256_loadu_ps/pd</code></td>\n<td>Loads a floating-point vector from an  unaligned memory address</td>\n</tr>\n<tr>\n<td><code>_mm256_loadu_si256</code></td>\n<td>Loads an integer vector from an unaligned memory address</td>\n</tr>\n<tr>\n<td><code>_mm_maskload_ps/pd</code> <code>_mm256_maskload_ps/pd</code></td>\n<td>Load portions of a 128-bit&#x2F;256-bit floating-point vector according to a mask</td>\n</tr>\n<tr>\n<td><code>(2)_mm_maskload_epi32/64</code> <code>(2)_mm256_maskload_epi32/64</code></td>\n<td>Load portions of a 128-bit&#x2F;256-bit integer vector according to a mask</td>\n</tr>\n</tbody></table>\n<p>当将数据加载到向量中时，内存对齐变得特别重要。每个<strong>_mm256_load_</strong>* intrinsic接受一个必须在32字节边界上对齐的内存地址。即地址必须能被32整除。下面的代码展示了如何在实践中使用它:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">float</span>* aligned_floats = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">aligned_alloc</span>(<span class=\"hljs-number\">32</span>, <span class=\"hljs-number\">64</span> * <span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">float</span>));\t\t<span class=\"hljs-comment\">//这里使用了内存对齐</span><br>... Initialize data ...<br>__m256 vec = _mm256_load_ps(aligned_floats);<br></code></pre></div></td></tr></table></figure>\n\n<p>【个人补充】关于内存对齐以及相关函数</p>\n<p><a href=\"https://xingyuanjie.top/2022/06/12/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/\">内存对齐 - Amicoyuan (xingyuanjie.top)</a></p>\n<p><a href=\"https://xingyuanjie.top/2022/06/12/AVX%E5%90%91%E9%87%8F%E5%8C%96%E5%AD%A6%E4%B9%A0(%E4%BA%8C)-%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90%E7%9A%84%E5%BA%94%E7%94%A8/\">AVX向量化学习(二)-内存对齐的应用 - Amicoyuan (xingyuanjie.top)</a></p>\n<p>任何使用_m256_load_*加载未对齐数据的尝试都会造成<strong>segmentation fault</strong>。如果数据不是以32位边界对齐，则应该使用_m256_loadu_*函数。如下代码所示:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">float</span>* unaligned_floats = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(<span class=\"hljs-number\">64</span> * <span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">float</span>));\t\t\t\t<span class=\"hljs-comment\">//未使用内存对齐</span><br>... Initialize data ...<br>__m256 vec = _mm256_loadu_ps(unaligned_floats);<br></code></pre></div></td></tr></table></figure>\n\n<p>假设你想用AVX向量处理一个浮点数组(float)，但是数组的长度是11，不能被8整除。在这种情况下，第二个__m256向量的最后五个浮点数需要设置为0[或者使用非向量计算手段]，这样它们就不会影响计算。这种选择性加载可以用表3底部的**_maskload_**函数来完成。</p>\n<p>每个_maskload_函数接受两个参数:一个内存地址和一个与返回向量元素数量相同的整数向量。对于整数向量中最高位为1的每个元素，将从内存中读取返回向量中相应的元素。如果整数向量中的最高位为零，则返回向量中的相应元素被设置为零。</p>\n<p>一个示例将说明如何使用这些函数。mask_load.c中的代码将8个整型读入一个向量，最后3个应该设置为0。要使用的函数是_mm256_maskload_epi32，它的第二个参数应该是__m256i掩码向量。这个掩码向量包含5个最高位为1的整数和3个最高位为0的整数。下面是代码的样子:</p>\n<p>【int型在计算机的存储是补码，正数的补码最高位为0，所以这里返回0，负数的补码最高位为1，所以这里返回的是内存中相应的元素】</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;immintrin.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br><br>  <span class=\"hljs-keyword\">int</span> i;<br>  <br>  <span class=\"hljs-keyword\">int</span> int_array[<span class=\"hljs-number\">8</span>] = &#123;<span class=\"hljs-number\">100</span>, <span class=\"hljs-number\">200</span>, <span class=\"hljs-number\">300</span>, <span class=\"hljs-number\">400</span>, <span class=\"hljs-number\">500</span>, <span class=\"hljs-number\">600</span>, <span class=\"hljs-number\">700</span>, <span class=\"hljs-number\">800</span>&#125;;<br>  <br>  <span class=\"hljs-comment\">/* Initialize the mask vector */</span><br>  __m256i mask = _mm256_setr_epi32(<span class=\"hljs-number\">-20</span>, <span class=\"hljs-number\">-72</span>, <span class=\"hljs-number\">-48</span>, <span class=\"hljs-number\">-9</span>, <span class=\"hljs-number\">-100</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">8</span>);\t<span class=\"hljs-comment\">//这里需要充分理解计算机组成原理中的补码</span><br><br>  <span class=\"hljs-comment\">/* Selectively load data into the vector */</span><br>  __m256i result = _mm256_maskload_epi32(int_array, mask);<br>  <br>  <span class=\"hljs-comment\">/* Display the elements of the result vector */</span><br>  <span class=\"hljs-keyword\">int</span>* res = (<span class=\"hljs-keyword\">int</span>*)&amp;result;<br>  <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%d %d %d %d %d %d %d %d\\n&quot;</span>, <br>    res[<span class=\"hljs-number\">0</span>], res[<span class=\"hljs-number\">1</span>], res[<span class=\"hljs-number\">2</span>], res[<span class=\"hljs-number\">3</span>], res[<span class=\"hljs-number\">4</span>], res[<span class=\"hljs-number\">5</span>], res[<span class=\"hljs-number\">6</span>], res[<span class=\"hljs-number\">7</span>]);<br>  <br>  <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>如果您在支持AVX2的系统上运行此应用程序，它将打印以下结果:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-number\">100</span> <span class=\"hljs-number\">200</span> <span class=\"hljs-number\">300</span> <span class=\"hljs-number\">400</span> <span class=\"hljs-number\">500</span> <span class=\"hljs-number\">0</span> <span class=\"hljs-number\">0</span> <span class=\"hljs-number\">0</span><br></code></pre></div></td></tr></table></figure>\n\n<p>有三点是需要注意的：</p>\n<ol>\n<li>代码使用_setr_函数而不是_set_来设置掩码向量的内容，因为它在将向量元素传递给函数时对它们进行排序。</li>\n<li>负整数的最高位总是1。这就是掩码向量包含五个负数和三个正数的原因。</li>\n<li>_mm256_maskload_epi32函数由AVX2提供，而不是AVX。因此，要用gcc编译这段代码，必须使用-mavx2标志而不是-mavx。</li>\n</ol>\n<p>除了表3中列出的函数之外，AVX2还提供了从内存加载索引数据的集合函数。</p>\n<h2 id=\"6-Arithmetic-Intrinsics\"><a href=\"#6-Arithmetic-Intrinsics\" class=\"headerlink\" title=\"6.Arithmetic Intrinsics\"></a>6.Arithmetic Intrinsics</h2><p>数学是AVX存在的主要原因，基本操作是加、减、乘和除。本节将介绍执行这些操作的intrinsic funtions，还将介绍AVX2提供的新的融合乘法和加法函数。</p>\n<h3 id=\"6-1加法和减法\"><a href=\"#6-1加法和减法\" class=\"headerlink\" title=\"6.1加法和减法\"></a>6.1加法和减法</h3><p>表4列出了执行加法和减法的AVX&#x2F;AVX2 intrinsic。由于考虑到饱和度，它们大多数都作用于包含整数的向量。</p>\n<p><strong>Table 4: Addition and Subtraction Intrinsics</strong></p>\n<table>\n<thead>\n<tr>\n<th>Data Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>_mm256_add_ps/pd</code></td>\n<td>Add two floating-point vectors</td>\n</tr>\n<tr>\n<td><code>_mm256_sub_ps/pd</code></td>\n<td>Subtract two floating-point vectors</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_add_epi8/16/32/64 </code></td>\n<td>Add two integer vectors</td>\n</tr>\n<tr>\n<td><code>(2)_mm236_sub_epi8/16/32/64</code></td>\n<td>Subtract two integer vectors</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_adds_epi8/16</code> <code>(2)_mm256_adds_epu8/16 </code></td>\n<td>Add two integer vectors with saturation</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_subs_epi8/16</code> <code>(2)_mm256_subs_epu8/16</code></td>\n<td>Subtract two integer vectors with saturation</td>\n</tr>\n<tr>\n<td><code>_mm256_hadd_ps/pd</code></td>\n<td>Add two floating-point vectors horizontally</td>\n</tr>\n<tr>\n<td><code>_mm256_hsub_ps/pd</code></td>\n<td>Subtract two floating-point vectors horizontally</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_hadd_epi16/32</code></td>\n<td>Add two integer vectors horizontally</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_hsub_epi16/32</code></td>\n<td>Subtract two integer vectors horizontally</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_hadds_epi16</code></td>\n<td>Add two vectors containing shorts horizontally with saturation</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_hsubs_epi16</code></td>\n<td>Subtract two vectors containing shorts horizontally with saturation</td>\n</tr>\n<tr>\n<td><code>_mm256_addsub_ps/pd</code></td>\n<td>Add and subtract two floating-point vectors</td>\n</tr>\n</tbody></table>\n<p>加法和减法整数向量时，重要的是要查看_add_&#x2F;_sub_函数和_adds_&#x2F;_subs_函数之间的区别。额外的s代表饱和，当结果需要的内存超过向量可以存储的内存时，就会产生饱和。Functions that take saturation into account clamp the result to the minimum&#x2F;maximum value that can be stored.没有饱和的函数在发生饱和时忽略内存问题。</p>\n<p>例如，假设一个向量包含有符号字节，那么每个元素的最大值是127 (0x7F)。如果一个运算将98加到85，数学和是183 (0xB7)。</p>\n<ul>\n<li>如果使用_mm256_add_epi8添加这些值，饱和度将被忽略，存储的结果将是-73 (0xB7)。</li>\n<li>如果使用_mm256_adds_epi8添加这些值，结果将被固定为最大值127 (0x7F)。</li>\n</ul>\n<p>作为另一个例子，考虑两个包含有符号短整数的向量。最小值为-32,768。如果计算-18,000 - 19,000，数学结果是-37,000 (0xFFFF6F78作为32位整数)。</p>\n<ul>\n<li>如果用_mm256_sub_epi16减去这些值，饱和度将被忽略，存储的结果将是28,536 (0x6F78)。</li>\n<li>如果用_mm256_subs_epi16减去这些值，结果将被压缩到最小值-32,768 (0x8000)。</li>\n</ul>\n<p>_hadd_&#x2F;_hsub_函数水平执行加法和减法。也就是说，它们不是添加或减去不同向量的元素，而是在每个向量中添加或减去<strong>相邻</strong>的元素。结果以交错的方式存储。图1显示了_mm256_hadd_pd的工作原理，它水平地添加了两个向量A和B:</p>\n<p><img src=\"/2023/03/10/avx006/Fig1.jpg\" alt=\"Image 1\"></p>\n<p><strong>Figure 1: Horizontal Addition of Two Vectors</strong></p>\n<p>水平加减元素看起来可能很奇怪，但这些操作在复数相乘时很有用。本文稍后将对此进行解释。表4中的最后一个函数_mm256_addsub_ps&#x2F;pd交替减法和加法两个浮点向量的元素。也就是说，偶数元素被减去，奇数元素被加上。例如，如果vec_a包含(0.1,0.2,0.3,0.4)，vec_b包含(0.5,0.6,0.7,0.8)，则_mm256_addsub_pd(vec_a, vec_b)等于(-0.4,0.8，-0.4,1.2)【需要注意数组下标从0开始】。</p>\n<h3 id=\"6-2乘法和除法\"><a href=\"#6-2乘法和除法\" class=\"headerlink\" title=\"6.2乘法和除法\"></a>6.2乘法和除法</h3><p>表5列出了执行乘法和除法的AVX&#x2F;AVX2 intrinsic。与加法和减法一样，对整数进行运算也有一些特殊的特性。</p>\n<p><strong>Table 5: Multiplication and Division Intrinsics</strong></p>\n<table>\n<thead>\n<tr>\n<th>Data Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>_mm256_mul_ps/pd</code></td>\n<td>Multiply two floating-point vectors</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_mul_epi32/</code> <code>(2)_mm256_mul_epu32 </code></td>\n<td>Multiply the lowest four elements of vectors containing 32-bit integers</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_mullo_epi16/32</code></td>\n<td>Multiply integers and store low halves</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_mulhi_epi16/</code> <code>(2)_mm256_mulhi_epu16</code></td>\n<td>Multiply integers and store high halves</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_mulhrs_epi16</code></td>\n<td>Multiply 16-bit elements to form 32-bit elements</td>\n</tr>\n<tr>\n<td><code>_mm256_div_ps/pd</code></td>\n<td>Divide two floating-point vectors</td>\n</tr>\n</tbody></table>\n<p>如果两个N位的数字在计算机上相乘，结果可以占用2N位【这里你需要熟悉计算机组成原理中的乘法原理，同时思考会不会在某些函数出现精度损失的情况】。因此，只有_mm256_mul_epi32和_mm256_mul_epu32的四个低元素被乘在一起，结果是一个包含四个长整数的向量。</p>\n<p><strong>___m256i _mm256_mul_epi32 (m256i a, __m256i b)</strong></p>\n<p><strong>Description</strong></p>\n<p>Multiply the low signed 32-bit integers from each packed 64-bit element in a and b, and store the signed 64-bit results in dst.</p>\n<p><strong>Operation</strong></p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">FOR</span> j := <span class=\"hljs-number\">0</span> to <span class=\"hljs-number\">3</span> <br>\t<span class=\"hljs-attribute\">i</span> := j*<span class=\"hljs-number\">64</span> <br>\t<span class=\"hljs-attribute\">dst</span>[i+<span class=\"hljs-number\">63</span>:i] := SignExtend<span class=\"hljs-number\">64</span>(a[i+<span class=\"hljs-number\">31</span>:i]) * SignExtend<span class=\"hljs-number\">64</span>(b[i+<span class=\"hljs-number\">31</span>:i]) <br><span class=\"hljs-attribute\">ENDFOR</span> <br><span class=\"hljs-attribute\">dst</span>[MAX:<span class=\"hljs-number\">256</span>] := <span class=\"hljs-number\">0</span><br></code></pre></div></td></tr></table></figure>\n\n<p><strong>图2:整数向量的低元素相乘</strong></p>\n<p>_mullo_函数类似于整数_mul_函数，但它们不是乘低元素，而是乘两个向量的每个元素，只存储每个乘积的低一半。</p>\n<p><strong>Synopsis</strong></p>\n<p><strong>m256i _mm256_mullo_epi32 (m256i a, __m256i b)</strong><br>#include &lt;immintrin.h&gt;<br>Instruction: vpmulld ymm, ymm, ymm<br>CPUID Flags: AVX2</p>\n<p><strong>Description</strong></p>\n<p>Multiply the packed signed 32-bit integers in a and b, producing intermediate 64-bit integers, and store the low 32 bits of the intermediate integers in dst.</p>\n<p><strong>Operation</strong></p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">FOR</span> j := <span class=\"hljs-number\">0</span> to <span class=\"hljs-number\">7</span> <br>\t\t<span class=\"hljs-attribute\">i</span> := j*<span class=\"hljs-number\">32</span> <br>\t\t<span class=\"hljs-attribute\">tmp</span>[<span class=\"hljs-number\">63</span>:<span class=\"hljs-number\">0</span>] := a[i+<span class=\"hljs-number\">31</span>:i] * b[i+<span class=\"hljs-number\">31</span>:i] <br>\t\t<span class=\"hljs-attribute\">dst</span>[i+<span class=\"hljs-number\">31</span>:i] := tmp[<span class=\"hljs-number\">31</span>:<span class=\"hljs-number\">0</span>] <br><span class=\"hljs-attribute\">ENDFOR</span> <br><span class=\"hljs-attribute\">dst</span>[MAX:<span class=\"hljs-number\">256</span>] := <span class=\"hljs-number\">0</span><br></code></pre></div></td></tr></table></figure>\n\n<p><strong>图3:整数相乘和存储低二分之一</strong></p>\n<p>_mm256_mulhi_epi16和_mm256_mulhi_epu16 intrinsics类似，但是它们存储整数积的高一半。</p>\n<p><strong>Synopsis</strong></p>\n<p><strong>m256i _mm256_mulhi_epi16 (m256i a, __m256i b)</strong><br>#include &lt;immintrin.h&gt;<br>Instruction: vpmulhw ymm, ymm, ymm<br>CPUID Flags: AVX2</p>\n<p><strong>Description</strong></p>\n<p>Multiply the packed signed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst.</p>\n<p><strong>Operation</strong></p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">FOR</span> j := <span class=\"hljs-number\">0</span> to <span class=\"hljs-number\">15</span> <br>\t<span class=\"hljs-attribute\">i</span> := j*<span class=\"hljs-number\">16</span> <br>\t<span class=\"hljs-attribute\">tmp</span>[<span class=\"hljs-number\">31</span>:<span class=\"hljs-number\">0</span>] := SignExtend<span class=\"hljs-number\">32</span>(a[i+<span class=\"hljs-number\">15</span>:i]) * SignExtend<span class=\"hljs-number\">32</span>(b[i+<span class=\"hljs-number\">15</span>:i]) \t\t   \t   dst[i+<span class=\"hljs-number\">15</span>:i] := tmp[<span class=\"hljs-number\">31</span>:<span class=\"hljs-number\">16</span>] <br><span class=\"hljs-attribute\">ENDFOR</span> <br><span class=\"hljs-attribute\">dst</span>[MAX:<span class=\"hljs-number\">256</span>] := <span class=\"hljs-number\">0</span><br></code></pre></div></td></tr></table></figure>\n\n\n\n<h3 id=\"6-3Fused-Multiply-and-Add-FMA\"><a href=\"#6-3Fused-Multiply-and-Add-FMA\" class=\"headerlink\" title=\"6.3Fused Multiply and Add (FMA)\"></a>6.3Fused Multiply and Add (FMA)</h3><p>如前所述，两个N位数字相乘的结果可以占用2N位。因此，当您将两个浮点值a和b相乘时，结果实际上是四舍五入(a * b)，其中四舍五入(x)返回最接近x的浮点值。随着进一步操作的执行，这种精度损失会增加。【这里需要注意分部乘加，先乘法后加法和使用FMA两者的计算精度】</p>\n<p>AVX2提供了将乘法和加法融合在一起的指令。也就是说，它们不是返回整数(整数(a * b) + c)，而是返回整数(a * b + c)。因此，这些指令比分别执行乘法和加法提供了更高的速度和准确性【这里正是FMA的特点】。</p>\n<p>表6列出了AVX2提供的FMA intrinsic，并包括对每个函数的描述。表中的每条指令都接受三个输入向量，我把它们分别称为a、b和c。</p>\n<p><strong>Table 6: FMA Intrinsics</strong></p>\n<table>\n<thead>\n<tr>\n<th>Data Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>(2)_mm_fmadd_ps/pd/</code> <code>(2)_mm256_fmadd_ps/pd</code></td>\n<td>Multiply two vectors and add the product to a third (res &#x3D; a * b + c)</td>\n</tr>\n<tr>\n<td><code>(2)_mm_fmsub_ps/pd/</code> <code>(2)_mm256_fmsub_ps/pd</code></td>\n<td>Multiply two vectors and subtract a vector from the product (res &#x3D; a * b - c)</td>\n</tr>\n<tr>\n<td><code>(2)_mm_fmadd_ss/sd </code></td>\n<td>Multiply and add the lowest element in the vectors (res[0] &#x3D; a[0] * b[0] + c[0])</td>\n</tr>\n<tr>\n<td><code>(2)_mm_fmsub_ss/sd</code></td>\n<td>Multiply and subtract the lowest element in the vectors (res[0] &#x3D; a[0] * b[0] - c[0])</td>\n</tr>\n<tr>\n<td><code>(2)_mm_fnmadd_ps/pd</code> <code>(2)_mm256_fnmadd_ps/pd </code></td>\n<td>Multiply two vectors and add the negated product to a third (res &#x3D; -(a * b) + c)</td>\n</tr>\n<tr>\n<td><code>(2)_mm_fnmsub_ps/pd/</code> <code>(2)_mm256_fnmsub_ps/pd</code></td>\n<td>Multiply two vectors and add the negated product to a third (res &#x3D; -(a * b) - c)</td>\n</tr>\n<tr>\n<td><code>(2)_mm_fnmadd_ss/sd</code></td>\n<td>Multiply the two lowest elements and add the negated product to the lowest element of the third vector (res[0] &#x3D; -(a[0] * b[0]) + c[0])</td>\n</tr>\n<tr>\n<td><code>(2)_mm_fnmsub_ss/sd</code></td>\n<td>Multiply the lowest elements and subtract the lowest element of the third vector from the negated product (res[0] &#x3D; -(a[0] * b[0]) - c[0])</td>\n</tr>\n<tr>\n<td><code>(2)_mm_fmaddsub_ps/pd/</code> <code>(2)_mm256_fmaddsub_ps/pd</code></td>\n<td>Multiply two vectors and alternately add and subtract from the product (res &#x3D; a * b - c)</td>\n</tr>\n<tr>\n<td><code>(2)_mm_fmsubadd_ps/pd/</code> <code>(2)_mmf256_fmsubadd_ps/pd </code></td>\n<td>Multiply two vectors and alternately subtract and add from the product (res &#x3D; a * b - c)</td>\n</tr>\n</tbody></table>\n<p>如果一个内征的名称以_ps或_pd结尾，则输入向量的每个元素都包含在运算中。如果intrinsic的名称以_ss或_sd结尾，则只包括最低的元素。输出向量中的其余元素被设置为与第一个输入向量中的元素相等。例如,假设vec_a &#x3D; (1.0, 2.0)， vec_b &#x3D; (5.0, 10.0)， vec_c &#x3D;(7.0, 14.0)。在本例中，_mm_fmadd_sd(vec_a, vec_b, vec_c)返回(12.0,2.0)，因为(1.0 * 5.0)+ 7.0 &#x3D; 12.0,2.0是vec_a的第二个元素。</p>\n<p>了解_fmadd_&#x2F;_fmsub_和_fnmadd_&#x2F;_fnmsub_ intrinsic之间的区别很重要。后一种函数在加上或减去第三个输入向量之前，对前两个输入向量的乘积求反。</p>\n<p><strong>Synopsis</strong></p>\n<p><strong>__m256d _mm256_fnmadd_pd (m256d a, m256d b, m256d c)</strong><br>#include &lt;immintrin.h&gt;<br>Instruction: vfnmadd132pd ymm, ymm, ymm<br>       vfnmadd213pd ymm, ymm, ymm<br>       vfnmadd231pd ymm, ymm, ymm<br>CPUID Flags: FMA</p>\n<p><strong>Description</strong></p>\n<p>Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst.</p>\n<p><strong>Operation</strong></p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">FOR</span> j := <span class=\"hljs-number\">0</span> to <span class=\"hljs-number\">3</span> <br>\t\t<span class=\"hljs-attribute\">i</span> := j*<span class=\"hljs-number\">64</span> <br>\t\t<span class=\"hljs-attribute\">dst</span>[i+<span class=\"hljs-number\">63</span>:i] := -(a[i+<span class=\"hljs-number\">63</span>:i] * b[i+<span class=\"hljs-number\">63</span>:i]) + c[i+<span class=\"hljs-number\">63</span>:i] <br><span class=\"hljs-attribute\">ENDFOR</span>\t <br><span class=\"hljs-attribute\">dst</span>[MAX:<span class=\"hljs-number\">256</span>] := <span class=\"hljs-number\">0</span><br></code></pre></div></td></tr></table></figure>\n\n<p>_fmaddsub_和_fmsubadd_内在函数在第三个向量的加法和减法元素之间交替使用。_fmaddsub_ intrinsic奇数元素做加法而偶数元素做减法。_fmsubadd_ intrinsic奇数元素做减法而偶数元素做加法。fmatest.c中的代码展示了如何在实践中使用_mm256_fmaddsub_pd intrinsic。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;immintrin.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>  <br>  __m256d veca = _mm256_setr_pd(<span class=\"hljs-number\">6.0</span>, <span class=\"hljs-number\">6.0</span>, <span class=\"hljs-number\">6.0</span>, <span class=\"hljs-number\">6.0</span>);<br><br>  __m256d vecb = _mm256_setr_pd(<span class=\"hljs-number\">2.0</span>, <span class=\"hljs-number\">2.0</span>, <span class=\"hljs-number\">2.0</span>, <span class=\"hljs-number\">2.0</span>);<br>  <br>  __m256d vecc = _mm256_setr_pd(<span class=\"hljs-number\">7.0</span>, <span class=\"hljs-number\">7.0</span>, <span class=\"hljs-number\">7.0</span>, <span class=\"hljs-number\">7.0</span>);<br>  <br>  <span class=\"hljs-comment\">/* Alternately subtract and add the third vector</span><br><span class=\"hljs-comment\">     from the product of the first and second vectors */</span><br>  __m256d result = _mm256_fmaddsub_pd(veca, vecb, vecc);<br>  <br>  <span class=\"hljs-comment\">/* Display the elements of the result vector */</span><br>  <span class=\"hljs-keyword\">double</span>* res = (<span class=\"hljs-keyword\">double</span>*)&amp;result;<br>  <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%lf %lf %lf %lf\\n&quot;</span>, res[<span class=\"hljs-number\">0</span>], res[<span class=\"hljs-number\">1</span>], res[<span class=\"hljs-number\">2</span>], res[<span class=\"hljs-number\">3</span>]);<br>  <br>  <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>当这段代码在支持AVX2的处理器上编译和执行时，打印的结果如下:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-number\">5.000000</span> <span class=\"hljs-number\">19.000000</span> <span class=\"hljs-number\">5.000000</span> <span class=\"hljs-number\">19.000000</span><br></code></pre></div></td></tr></table></figure>\n\n<p>FMA指令是由AVX2提供的，因此您可能认为使用gcc构建应用程序需要使用-mavx2标志。但是我发现-mfma标志是<strong>必需</strong>的。否则，我会得到奇怪的编译错误。</p>\n<h2 id=\"7-Permuting-and-Shuffling\"><a href=\"#7-Permuting-and-Shuffling\" class=\"headerlink\" title=\"7.Permuting and Shuffling\"></a>7.Permuting and Shuffling</h2><p>许多应用程序必须重新排列向量元素，以确保正确执行操作。</p>\n<p>AVX&#x2F;AVX2为此目的提供了许多intrinsic funtion，其中两大类是_permute_函数和_shuffle_函数。本节介绍这两种类型的intrinsic。</p>\n<h3 id=\"7-1Permuting\"><a href=\"#7-1Permuting\" class=\"headerlink\" title=\"7.1Permuting\"></a>7.1Permuting</h3><p>AVX提供了返回一个向量的函数，该向量包含一个向量的重新排列的元素。表7列出了这些排列函数，并提供了对每个函数的描述。</p>\n<p><strong>Table 7: Permute Intrinsics</strong></p>\n<table>\n<thead>\n<tr>\n<th>Data Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>_mm_permute_ps/pd/</code> <code>_mm256_permute_ps/pd</code></td>\n<td>Select elements from the input vector based on an 8-bit control value</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_permute4x64_pd/</code> <code>(2)_mm256_permute4x64_epi64</code></td>\n<td>Select 64-bit elements from the input vector based on an 8-bit control value</td>\n</tr>\n<tr>\n<td><code>_mm256_permute2f128_ps/pd</code></td>\n<td>Select 128-bit chunks from two input vectors based on an 8-bit control value</td>\n</tr>\n<tr>\n<td><code>_mm256_permute2f128_si256 </code></td>\n<td>Select 128-bit chunks from two input vectors based on an 8-bit control value</td>\n</tr>\n<tr>\n<td><code>_mm_permutevar_ps/pd</code> <code>_mm256_permutevar_ps/pd </code></td>\n<td>Select elements from the input vector based on bits in an integer vector</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_permutevar8x32_ps</code>&#x2F; <code>(2)_mm256_permutevar8x32_epi32</code></td>\n<td>Select 32-bit elements (<code>float</code>s and <code>int</code>s) using indices in an integer vector</td>\n</tr>\n</tbody></table>\n<p>_permute_ intrinsic接受两个参数:一个输入向量和一个8位控制值。控制值的位决定输入向量的哪个元素插入到输出中。</p>\n<p>对于_mm256_permute_ps，每对控制位通过选择输入向量中的一个上或下元素来确定一个上或下输出元素。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;immintrin.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;bits/stdc++.h&gt;</span></span><br><span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> std;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>  <br>  __m128 v1 = _mm_setr_ps(<span class=\"hljs-number\">2.3</span>, <span class=\"hljs-number\">4.1</span>, <span class=\"hljs-number\">6.2</span>, <span class=\"hljs-number\">8.4</span>);<br>  <span class=\"hljs-keyword\">float</span> * a =(<span class=\"hljs-keyword\">float</span>*)&amp;v1;<br>   <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i&lt; <span class=\"hljs-number\">4</span> ;i++)<br>   &#123;<br>   \t cout&lt;&lt;a[i]&lt;&lt;<span class=\"hljs-string\">&quot; &quot;</span>;<br>   &#125;<br>   cout&lt;&lt;endl;<br>   __m128 v2 = _mm_permute_ps (v1, <span class=\"hljs-number\">3</span>);<br>   <span class=\"hljs-keyword\">float</span> * b =(<span class=\"hljs-keyword\">float</span>*)&amp;v2;<br>   <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i&lt; <span class=\"hljs-number\">4</span> ;i++)<br>   &#123;<br>   \t cout&lt;&lt;b[i]&lt;&lt;<span class=\"hljs-string\">&quot; &quot;</span>;<br>   &#125;<br>  <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2</span>.<span class=\"hljs-number\">3</span> <span class=\"hljs-number\">4</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">6</span>.<span class=\"hljs-number\">2</span> <span class=\"hljs-number\">8</span>.<span class=\"hljs-number\">4</span><br><span class=\"hljs-attribute\">8</span>.<span class=\"hljs-number\">4</span> <span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">3</span> <span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">3</span> <span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">3</span><br></code></pre></div></td></tr></table></figure>\n\n<p><strong>Figure 4: Operation of the Permute Intrinsic Function</strong></p>\n<p>如图所示，输入向量的值可以在输出中重复多次。其他输入值可能根本不被选择。</p>\n<p>在_mm256_permute_pd中，控制值的低四位在相邻的双精度数对之间进行选择。_mm256_permute4x4_pd类似，但使用所有控制位来选择将哪个64位元素放在输出中。在_permute2f128_ intrinsic中，控制值从两个输入向量中选择128位块，而不是从一个输入向量中选择元素。</p>\n<p>_permutevar_ intrinsic执行与_permute_ intrinsic相同的操作。但是它们不是使用8位控制值来选择元素，而是依赖于与输入向量大小相同的整数向量。例如，_mm256_permute_ps的输入向量是_mm256，因此整数向量是_mm256i。整数向量的高位执行选择的方式与_permute_ intrinsic的8位控制值的位相同。</p>\n<h3 id=\"7-2Shuffling\"><a href=\"#7-2Shuffling\" class=\"headerlink\" title=\"7.2Shuffling\"></a>7.2Shuffling</h3><p>像_permute_ intrinsic一样，_shuffle_ intrinsic从一个或两个输入向量中选择元素，并将它们放在输出向量中。表8列出了这些功能，并提供了每个功能的描述。</p>\n<p><strong>Table 8: Shuffle Intrinsics</strong></p>\n<table>\n<thead>\n<tr>\n<th>Data Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>_mm256_shuffle_ps/pd</code></td>\n<td>Select floating-point elements according to an 8-bit value</td>\n</tr>\n<tr>\n<td><code>_mm256_shuffle_epi8/</code> <code>_mm256_shuffle_epi32</code></td>\n<td>Select integer elements according to an 8-bit value</td>\n</tr>\n<tr>\n<td><code>(2)_mm256_shufflelo_epi16/ </code> <code>(2)_mm256_shufflehi_epi16</code></td>\n<td>Select 128-bit chunks from two input vectors based on an 8-bit control value</td>\n</tr>\n</tbody></table>\n<p>所有的shuffle_ intrinsic运算于256位向量。在每种情况下，最后一个参数是一个8位的值，它决定哪些输入元素应该放在输出向量中。</p>\n<p>对于_mm256_shuffle_ps，只使用控件值的高四位。如果输入向量包含整型或浮点数，则使用所有控制位。对于_mm256_shuffle_ps，前两对位选择第一个向量中的元素，后两对位选择第二个向量中的元素。</p>\n<p><strong>Synopsis</strong></p>\n<p><strong>m256 _mm256_shuffle_ps (m256 a, __m256 b, const int imm8)</strong><br>#include &lt;immintrin.h&gt;<br>Instruction: vshufps ymm, ymm, ymm, imm8<br>CPUID Flags: AVX</p>\n<p><strong>Description</strong></p>\n<p>Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst.</p>\n<p><strong>Operation</strong></p>\n<figure class=\"highlight stylus\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs stylus\">DEFINE SELECT4(<span class=\"hljs-attribute\">src</span>, control) &#123; <br>\t\tCASE(control<span class=\"hljs-selector-attr\">[1:0]</span>) OF <br>\t\t<span class=\"hljs-number\">0</span>:\ttmp<span class=\"hljs-selector-attr\">[31:0]</span> := <span class=\"hljs-attribute\">src</span>[<span class=\"hljs-number\">31</span>:<span class=\"hljs-number\">0</span>] <br>\t\t<span class=\"hljs-number\">1</span>:\ttmp<span class=\"hljs-selector-attr\">[31:0]</span> := <span class=\"hljs-attribute\">src</span>[<span class=\"hljs-number\">63</span>:<span class=\"hljs-number\">32</span>] <br>\t\t<span class=\"hljs-number\">2</span>:\ttmp<span class=\"hljs-selector-attr\">[31:0]</span> := <span class=\"hljs-attribute\">src</span>[<span class=\"hljs-number\">95</span>:<span class=\"hljs-number\">64</span>] <br>\t\t<span class=\"hljs-number\">3</span>:\ttmp<span class=\"hljs-selector-attr\">[31:0]</span> := <span class=\"hljs-attribute\">src</span>[<span class=\"hljs-number\">127</span>:<span class=\"hljs-number\">96</span>] <br>\t\tESAC <br>\t\tRETURN tmp<span class=\"hljs-selector-attr\">[31:0]</span> <br>\t\t&#125; <br>dst<span class=\"hljs-selector-attr\">[31:0]</span> := SELECT4(<span class=\"hljs-selector-tag\">a</span><span class=\"hljs-selector-attr\">[127:0]</span>, imm8<span class=\"hljs-selector-attr\">[1:0]</span>) <br>dst<span class=\"hljs-selector-attr\">[63:32]</span> := SELECT4(<span class=\"hljs-selector-tag\">a</span><span class=\"hljs-selector-attr\">[127:0]</span>, imm8<span class=\"hljs-selector-attr\">[3:2]</span>) <br>dst<span class=\"hljs-selector-attr\">[95:64]</span> := SELECT4(<span class=\"hljs-selector-tag\">b</span><span class=\"hljs-selector-attr\">[127:0]</span>, imm8<span class=\"hljs-selector-attr\">[5:4]</span>) <br>dst<span class=\"hljs-selector-attr\">[127:96]</span> := SELECT4(<span class=\"hljs-selector-tag\">b</span><span class=\"hljs-selector-attr\">[127:0]</span>, imm8<span class=\"hljs-selector-attr\">[7:6]</span>) <br>dst<span class=\"hljs-selector-attr\">[159:128]</span> := SELECT4(<span class=\"hljs-selector-tag\">a</span><span class=\"hljs-selector-attr\">[255:128]</span>, imm8<span class=\"hljs-selector-attr\">[1:0]</span>) <br>dst<span class=\"hljs-selector-attr\">[191:160]</span> := SELECT4(<span class=\"hljs-selector-tag\">a</span><span class=\"hljs-selector-attr\">[255:128]</span>, imm8<span class=\"hljs-selector-attr\">[3:2]</span>) <br>dst<span class=\"hljs-selector-attr\">[223:192]</span> := SELECT4(<span class=\"hljs-selector-tag\">b</span><span class=\"hljs-selector-attr\">[255:128]</span>, imm8<span class=\"hljs-selector-attr\">[5:4]</span>) <br>dst<span class=\"hljs-selector-attr\">[255:224]</span> := SELECT4(<span class=\"hljs-selector-tag\">b</span><span class=\"hljs-selector-attr\">[255:128]</span>, imm8<span class=\"hljs-selector-attr\">[7:6]</span>) <br>dst<span class=\"hljs-selector-attr\">[MAX:256]</span> := <span class=\"hljs-number\">0</span><br></code></pre></div></td></tr></table></figure>\n\n<p>为了shuffle16位值，AVX2提供了_mm256_shufflelo_epi16和_mm256_shufflehi_epi16。与_mm256_shuffle_ps一样，控制值被分成四对从八个元素中选择的位。但是对于_mm256_shufflelo_epi16, 8个元素是从8个低的16位值中取出的。对于_mm256_shufflehi_epi16, 8个元素取自8个高的16位值。</p>\n<h2 id=\"8-Complex-Multiplication\"><a href=\"#8-Complex-Multiplication\" class=\"headerlink\" title=\"8.Complex Multiplication\"></a>8.Complex Multiplication</h2><p>在信号处理应用中，复数乘法是一项必须反复执行的耗时操作。我不会深入讨论这个理论，但每个复数都可以表示为a + bi，其中a和b是浮点值，i是-1的平方根。A是实部，b是虚部。如果(a + bi)和(c + di)相乘，乘积等于(ac - bd) + (ad + bc)i。</p>\n<p>复数可以以交错的方式存储，这意味着每个实数部分后面跟着虚数部分。假设vec1是一个__m256d，存储两个复数(a + bi)和(x + yi)， vec2是一个__m256d，存储(c + di)和(z + wi)。图6说明了如何存储这些值。如图所示，prod向量存储了两个产物:(ac - bd) + (ad + bc)i和(xz - yw) + (xw + yz)i。</p>\n<p>【图片丢失】</p>\n<p><strong>Figure 6: Complex Multiplication Using Vectors</strong></p>\n<p>我不知道用AVX&#x2F;AVX2计算复杂乘积的最快方法。但我想出了一个方法，效果很好。它包括五个步骤:</p>\n<ol>\n<li>将vec1和vec2相乘，并将结果存储在vec3中。</li>\n<li>切换vec2的实&#x2F;虚值。</li>\n<li>求vec2的虚数的负数。</li>\n<li>将vec1和vec2相乘，并将结果存储在vec4中。</li>\n<li>对vec3和vec4进行水平相减，得到vec1中的答案。</li>\n</ol>\n<p>complex_multi .c中的代码展示了如何使用AVX intrinsic执行此操作:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;immintrin.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br><br>  __m256d vec1 = _mm256_setr_pd(<span class=\"hljs-number\">4.0</span>, <span class=\"hljs-number\">5.0</span>, <span class=\"hljs-number\">13.0</span>, <span class=\"hljs-number\">6.0</span>);<br>  __m256d vec2 = _mm256_setr_pd(<span class=\"hljs-number\">9.0</span>, <span class=\"hljs-number\">3.0</span>, <span class=\"hljs-number\">6.0</span>, <span class=\"hljs-number\">7.0</span>);<br>  __m256d neg = _mm256_setr_pd(<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">-1.0</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">-1.0</span>);<br>  <br>  <span class=\"hljs-comment\">/* Step 1: Multiply vec1 and vec2 */</span><br>  __m256d vec3 = _mm256_mul_pd(vec1, vec2);<br><br>  <span class=\"hljs-comment\">/* Step 2: Switch the real and imaginary elements of vec2 */</span><br>  vec2 = _mm256_permute_pd(vec2, <span class=\"hljs-number\">0x5</span>);<br>  <br>  <span class=\"hljs-comment\">/* Step 3: Negate the imaginary elements of vec2 */</span><br>  vec2 = _mm256_mul_pd(vec2, neg);  <br>  <br>  <span class=\"hljs-comment\">/* Step 4: Multiply vec1 and the modified vec2 */</span><br>  __m256d vec4 = _mm256_mul_pd(vec1, vec2);<br><br>  <span class=\"hljs-comment\">/* Horizontally subtract the elements in vec3 and vec4 */</span><br>  vec1 = _mm256_hsub_pd(vec3, vec4);<br>  <br>  <span class=\"hljs-comment\">/* Display the elements of the result vector */</span><br>  <span class=\"hljs-keyword\">double</span>* res = (<span class=\"hljs-keyword\">double</span>*)&amp;vec1;<br>  <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%lf %lf %lf %lf\\n&quot;</span>, res[<span class=\"hljs-number\">0</span>], res[<span class=\"hljs-number\">1</span>], res[<span class=\"hljs-number\">2</span>], res[<span class=\"hljs-number\">3</span>]);<br>  <br>  <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">21</span>.<span class=\"hljs-number\">000000</span> <span class=\"hljs-number\">57</span>.<span class=\"hljs-number\">000000</span> <span class=\"hljs-number\">36</span>.<span class=\"hljs-number\">000000</span> <span class=\"hljs-number\">127</span>.<span class=\"hljs-number\">000000</span><br></code></pre></div></td></tr></table></figure>\n\n<p>这段代码作用于双向量，但是可以很容易地扩展该方法以支持浮点向量。</p>\n<h2 id=\"9-Points-of-Interest\"><a href=\"#9-Points-of-Interest\" class=\"headerlink\" title=\"9.Points of Interest\"></a>9.Points of Interest</h2><p>许多开发人员可能会避免学习AVX&#x2F;AVX2，希望编译器能够执行自动向量化。自动向量化是一个很好的特性，但是如果您了解本质，就可以重新安排算法以更好地利用SIMD处理。通过插入AVX&#x2F;AVX2 intrinsic，我极大地提高了信号处理应用程序的处理速度。</p>\n<h2 id=\"10-History\"><a href=\"#10-History\" class=\"headerlink\" title=\"10.History\"></a>10.History</h2><p>2&#x2F;20 - Fixed formatting and image links</p>\n<p>4&#x2F;2 - Fixed a couple typographical errors</p>\n<h2 id=\"11-License\"><a href=\"#11-License\" class=\"headerlink\" title=\"11.License\"></a>11.License</h2><p>This article, along with any associated source code and files, is licensed under <a href=\"http://www.codeproject.com/info/cpol10.aspx\">The Code Project Open License (CPOL)</a></p>\n<p>Written By</p>\n<p><strong><a href=\"https://www.codeproject.com/Members/mattscar\">Matt Scarpino</a></strong></p>\n<p><img src=\"/2023/03/10/avx006/US.gif\" alt=\"United States\"> United States</p>\n<p>I’ve been a programmer and engineer for over 20 years. I’m a certified Azure Developer Associate and an Azure IoT Developer Specialist.</p>\n",
            "tags": [
                "AVX",
                "AVX2"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/09/cuda015/",
            "url": "https://xingyuanjie.top/2023/03/09/cuda015/",
            "title": "CUDA使用二维网格和二位块对矩阵求和",
            "date_published": "2023-03-09T04:34:51.000Z",
            "content_html": "<h2 id=\"CUDA使用二维网格和二位块对矩阵求和\"><a href=\"#CUDA使用二维网格和二位块对矩阵求和\" class=\"headerlink\" title=\"CUDA使用二维网格和二位块对矩阵求和\"></a>CUDA使用二维网格和二位块对矩阵求和</h2><p>在本节中，我们将使用一个二维网格和二位块来编写一个矩阵加法核函数。首先，应该编写一个校验主函数以验证矩阵加法核函数是否能得出正确的结果：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumMatrixOnhost</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> nx, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> ny)</span></span>&#123;<br>    <span class=\"hljs-keyword\">float</span> *ia = A;<br>    <span class=\"hljs-keyword\">float</span> *ib = B;<br>    <span class=\"hljs-keyword\">float</span> *ic = C;<br>    <br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> iy=<span class=\"hljs-number\">0</span>;iy&lt;ny;iy++)&#123;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> ix=<span class=\"hljs-number\">0</span>;ix&lt;nx;ix++)&#123;<br>            ic[ix]=ia[ix]+ib[ix];<br>        &#125;<br>        ia += nx;<br>        ib += nx;<br>        ic += nx;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>然后，创建一个新的核函数，目的是采用一个二维线程块来进行矩阵求和：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumMatrixOnGPU2D</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *MatA, <span class=\"hljs-keyword\">float</span> *MatB, <span class=\"hljs-keyword\">float</span> *MatC, <span class=\"hljs-keyword\">int</span> nx, <span class=\"hljs-keyword\">int</span> ny)</span></span>&#123;<br>    <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span> ix = threadIdx.x + blockIdx.x * blockDim.x;<br>    <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span> iy = threadIdx.y + blockIdx.y * blockDim.y;<br>    ubsigned <span class=\"hljs-keyword\">int</span> idx = iy*nx + ix;<br>    <br>    <span class=\"hljs-keyword\">if</span>(ix &lt; nx &amp;&amp; iy &lt;ny)<br>        MatC[idx] = MatA[idx] + MatB[idx];<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>这个核函数的关键步骤是将每个线程从它的线程索引映射到全局线性内存索引中，如图2-12所示。</p>\n<p>接下来，每个维度下的矩阵大小可以按如下方法设置为16384个元素：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">int</span> nx = <span class=\"hljs-number\">1</span>&lt;&lt;<span class=\"hljs-number\">14</span>;<br><span class=\"hljs-keyword\">int</span> ny = <span class=\"hljs-number\">1</span>&lt;&lt;<span class=\"hljs-number\">14</span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>然后，使用一个二维网格和二维块按如下方法设置核函数的执行配置：</p>\n<p><img src=\"/2023/03/09/cuda015/image-20230309125059653.png\" alt=\"image-20230309125059653\"></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">int</span> dimx = <span class=\"hljs-number\">32</span>;<br><span class=\"hljs-keyword\">int</span> dimy = <span class=\"hljs-number\">32</span>;<br><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(dimx, dimy)</span></span>;<br><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">((nx + block.x - <span class=\"hljs-number\">1</span>)/block.x, (ny + block.y - <span class=\"hljs-number\">1</span>)/block.y)</span></span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>把所有的代码整合到名为sumMatrixOnGPU-2D-grid-2D-block.cu的文件中。主函数代码如代码清单2-7所示。</p>\n<p>代码清单2-7 使用一个二维网格和二维块的矩阵加法(sumMatrixOnGPU-2D-grid-2D-block.cu)</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc, <span class=\"hljs-keyword\">char</span> **argv)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%s Starting...\\n&quot;</span>,zrgv[<span class=\"hljs-number\">0</span>]);<br>    <br>    <span class=\"hljs-comment\">//set up device</span><br>    <span class=\"hljs-keyword\">int</span> dev = <span class=\"hljs-number\">0</span>;<br>    cudaDeviceProp deviceProp;<br>    <span class=\"hljs-built_in\">CHECK</span>(<span class=\"hljs-built_in\">cudaGetDeviceProperties</span>(&amp;deviceProp, dev));<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Using Device %d: %s\\n&quot;</span>,dev, deviceProp.name);<br>    <span class=\"hljs-built_in\">CHECK</span>(<span class=\"hljs-built_in\">cudaSetDevice</span>(dev));<br>    <br>    <span class=\"hljs-comment\">//set up data size of matrix</span><br>    <span class=\"hljs-keyword\">int</span> nx = <span class=\"hljs-number\">1</span>&lt;&lt;<span class=\"hljs-number\">14</span>;<br>    <span class=\"hljs-keyword\">int</span> ny = <span class=\"hljs-number\">1</span>&lt;&lt;<span class=\"hljs-number\">14</span>;<br>    <br>    <span class=\"hljs-keyword\">int</span> nxy = nx*ny;<br>    <span class=\"hljs-keyword\">int</span> nBytes = nxy *<span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">float</span>);<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Matrix size: nx %d ny %d\\n&quot;</span>,nx,ny);<br>    <br>    <span class=\"hljs-comment\">//malloc host memory</span><br>    <span class=\"hljs-keyword\">float</span> *h_A, *h_B, *hostRef, *gpuRef;<br>    h_A = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    h_B = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    hostRef = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    gpuRef = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    <br>    <span class=\"hljs-comment\">//initialize data at host side</span><br>    <span class=\"hljs-keyword\">double</span> iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>    <span class=\"hljs-built_in\">initialData</span> (h_A, nxy);<br>    <span class=\"hljs-built_in\">initialData</span> (h_B, nxy);<br>    <span class=\"hljs-keyword\">double</span> iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br>    <br>    <span class=\"hljs-built_in\">memset</span>(hostRef, <span class=\"hljs-number\">0</span>, nBytes);<br>    <span class=\"hljs-built_in\">memset</span>(gpuRef, <span class=\"hljs-number\">0</span>, nBytes);<br>    <br>    <span class=\"hljs-comment\">//add matrix at host side for result checks</span><br>    iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>    <span class=\"hljs-built_in\">sumMatrixOnHost</span> (h_A, h_B, hostRef, nx,ny);<br>    iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br>    <br>    <span class=\"hljs-comment\">//malloc device global memory</span><br>    <span class=\"hljs-keyword\">float</span> *d_MatA, *d_MatB, *d_MatC;<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">void</span> **)&amp;d_MatA,nBytes);<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">void</span> **)&amp;d_MatB,nBytes);<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">void</span> **)&amp;d_MatC,nBytes);<br>    <br>    <span class=\"hljs-comment\">//transfer data from host to device</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_MatA, h_A, nBytes, cudaMemcpyHostToDevice);<br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_MatB, h_B, nBytes, cudaMemcpyHostToDevice);<br>    <br>    <span class=\"hljs-comment\">//invoke kernel at host side</span><br>    <span class=\"hljs-keyword\">int</span> dimx = <span class=\"hljs-number\">32</span>;<br>    <span class=\"hljs-keyword\">int</span> dimy = <span class=\"hljs-number\">32</span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(dimx,dimy)</span></span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">((nx+block.x<span class=\"hljs-number\">-1</span>)/block.x,(ny+block.y<span class=\"hljs-number\">-1</span>)/block.y)</span></span>;<br>    <br>    iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>    sumMatrixOnGPU2D&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_MatA, d_MatB, d_MatC, nx,ny);<br>    <span class=\"hljs-built_in\">cudaDeviceSynchronize</span>();<br>    iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;sumMatrixOnGPU2D&lt;&lt;&lt;(%d,%d),(%d,%d)&gt;&gt;&gt; elapsed %f sec\\n&quot;</span>,grid.x, grid.y, block.x,block.y,iElaps);<br>    <br>    <span class=\"hljs-comment\">//copy kernel result back to host side</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(gpuRef, d_MatC, nBytes, cudaMemcpyDeviceToHost);<br>    <br>    <span class=\"hljs-comment\">//check device results</span><br>    <span class=\"hljs-built_in\">checkResult</span>(hostRef, gpuRef,nxy);<br>    <br>    <span class=\"hljs-comment\">//free device global memory</span><br>    <span class=\"hljs-built_in\">cudaFree</span>(d_MatA);<br>    <span class=\"hljs-built_in\">cudaFree</span>(d_MatB);<br>    <span class=\"hljs-built_in\">cudaFree</span>(d_MatC);<br>    <br>    <span class=\"hljs-comment\">//free host memory</span><br>    <span class=\"hljs-built_in\">free</span>(h_A);<br>    <span class=\"hljs-built_in\">free</span>(h_B);<br>    <span class=\"hljs-built_in\">free</span>(hostRef);<br>    <span class=\"hljs-built_in\">free</span>(gpuRef);<br>    <br>    <span class=\"hljs-comment\">//reset device</span><br>    <span class=\"hljs-built_in\">cudaDeviceReset</span>();<br>    <br>    <span class=\"hljs-keyword\">return</span> (<span class=\"hljs-number\">0</span>);<br>&#125; <br></code></pre></div></td></tr></table></figure>\n\n<p>用以下命令编译并运行该代码：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc -arch=sm_20 sumMatrixOnGPU-2D-grid-2D-block.cu -o matrix2D<br>./matrix2D<br></code></pre></div></td></tr></table></figure>\n\n<p>在Tesla M2070上运行的结果：</p>\n<p><img src=\"/2023/03/09/cuda015/image-20230309224513603.png\" alt=\"image-20230309224513603\"></p>\n<p>接下来，调整块的尺寸为32×16并重新编译和运行该代码。核函数的执行速度几乎快了两倍：</p>\n<p><img src=\"/2023/03/09/cuda015/image-20230309224626772.png\" alt=\"image-20230309224626772\"></p>\n<p>你可能好奇为什么只是改变了执行配置，内核性能就几乎翻了一倍。直观地说，你可能会觉得这是因为第二次配置的线程块数是第一次配置块数的两倍，所以并行性也是两倍。你的直觉是正确的，但是，如果进一步减小块的大小变为16×16，相比第一次配置你已经将块的数量翻了四倍。如下所示，这种配置比第一个结果好但是不如第二个。</p>\n<p><img src=\"/2023/03/09/cuda015/image-20230309224912499.png\" alt=\"image-20230309224912499\"></p>\n<p>表2-3总结了不同执行配置的性能。结果显示，增加块的数量不一定能提升内核性能。</p>\n<p><img src=\"/2023/03/09/cuda015/image-20230309225004531.png\" alt=\"image-20230309225004531\"></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/09/cuda014/",
            "url": "https://xingyuanjie.top/2023/03/09/cuda014/",
            "title": "CUDA使用块和线程建立矩阵索引",
            "date_published": "2023-03-09T03:32:36.000Z",
            "content_html": "<h2 id=\"CUDA使用块和线程建立矩阵索引\"><a href=\"#CUDA使用块和线程建立矩阵索引\" class=\"headerlink\" title=\"CUDA使用块和线程建立矩阵索引\"></a>CUDA使用块和线程建立矩阵索引</h2><p>通常情况下，一个矩阵用行优先的方法在全局内存中进行线性存储。图2-9所示的是一个8×6矩阵的小例子。</p>\n<p>在一个矩阵加法核函数中，一个线程通常被分配一个数据元素来处理。首先要完成的任务是使用块和线程索引从全局内存中访问指定的数据。通常情况下，对一个二维示例来说，需要管理3种索引。</p>\n<p><img src=\"/2023/03/09/cuda014/image-20230309113733674.png\" alt=\"image-20230309113733674\"></p>\n<ul>\n<li>线程和块索引</li>\n<li>矩阵中给定点的坐标</li>\n<li>全局线性内存中的偏移量</li>\n</ul>\n<p>对于一个给定的线程，首先可以通过把线程和块索引映射到矩阵坐标上来获取线程块和线程索引的全局内存偏移量，然后将这些矩阵坐标映射到全局内存的存储单元中。</p>\n<p>第一步，可以用以下公式把线程和块索引映射到矩阵坐标上：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">ix = threadIdx.x + blockIdx.x * blockDim.x;<br>iy = threadIdx.y + blockIdx.y * blockDim.y;<br></code></pre></div></td></tr></table></figure>\n\n<p>第二步，可以用以下公式把矩阵坐标映射到全局内存中的索引&#x2F;存储单元上:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">idx = iy * nx + ix<br></code></pre></div></td></tr></table></figure>\n\n<p>图2-10说明了块和线程索引，矩阵坐标以及线性全局内存索引之间的对应关系。</p>\n<p><img src=\"/2023/03/09/cuda014/image-20230309114815497.png\" alt=\"image-20230309114815497\"></p>\n<p>printThreadInfo函数被用于输出关于每个线程的以下信息：</p>\n<ul>\n<li>线程索引</li>\n<li>块索引</li>\n<li>矩阵坐标</li>\n<li>线性全局内存偏移量</li>\n<li>相应元素的值</li>\n</ul>\n<p>用以下命令编译并运行该程序：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc -arch=sm_20 checkThreadIndex.cu -o checkIndex<br>./checkIndex<br></code></pre></div></td></tr></table></figure>\n\n<p>对于每个线程，你可以获取以下信息：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">thread_id</span>(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">1</span>)\t<span class=\"hljs-built_in\">block_id</span>(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">0</span>)\t<span class=\"hljs-built_in\">coordinate</span>(<span class=\"hljs-number\">6</span>,<span class=\"hljs-number\">1</span>)\tglobal index <span class=\"hljs-number\">14</span> ival <span class=\"hljs-number\">14</span><br></code></pre></div></td></tr></table></figure>\n\n<p>图2-11说明了这三项索引之间的关系。</p>\n<p><img src=\"/2023/03/09/cuda014/image-20230309115229368.png\" alt=\"image-20230309115229368\"></p>\n<p>代码清单2-6 检查块和线程索引（checkT和readIndex.cu）</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;cuda_runtime.h&gt;</span></span><br><span class=\"hljs-meta\">#inclde <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> CHECK(call)</span><br>&#123;<br>    <span class=\"hljs-keyword\">const</span> cudaError_t error = call;<br>    <span class=\"hljs-keyword\">if</span>(error != cudaSuccess)<br>    &#123;<br>        <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Error: %s:%d, &quot;</span>,__FILE__, __LINE__);<br>        <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;code:%d, reason: %s\\n&quot;</span>,error, <span class=\"hljs-built_in\">cudaGetErrorString</span>(error));<br>        <span class=\"hljs-built_in\">exit</span>(<span class=\"hljs-number\">-10</span>*error);<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">initialInt</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> *p, <span class=\"hljs-keyword\">int</span> size)</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i=<span class=\"hljs-number\">0</span>;i&lt;size;i++)&#123;<br>        ip[i] = i;<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">printMateix</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> *C,<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> nx, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> ny)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> *ic = C;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;\\nMatrix:\t(%d.%d)\\n&quot;</span>.nx,ny);<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> iy=<span class=\"hljs-number\">0</span>;iy&lt;ny;iy++)&#123;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> ix=<span class=\"hljs-number\">0</span>; ix&lt;nx;ix++)&#123;<br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%3d&quot;</span>,ic[ix]);<br>        &#125;<br>        ic += nx;<br>        <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;\\n&quot;</span>);<br>    &#125;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;\\n&quot;</span>);<br>&#125;<br><br><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">printThreadIndex</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> *A, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> nx, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> ny)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> ix = threadIdx.x + blockIdx.x * blockDim.x;<br>    <span class=\"hljs-keyword\">int</span> iy = threadIdx.y + blockIdx.y * blockDim.y;<br>    <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span> idx = iy*nx + ix;<br>    <br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;thread_id (%d,%d) block_id (%d,%d) coordinate (%d,%d) global index %2d ival %2d\\n&quot;</span>, threadIdx.x, threadIdx.y, blockIdx.x,blockIdx.y,ix,iy,idx,A[idx]);<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc,<span class=\"hljs-keyword\">char</span> **argv)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%s Starting...\\n&quot;</span>,argv[<span class=\"hljs-number\">0</span>]);<br>    <br>    <span class=\"hljs-comment\">//get device information</span><br>    <span class=\"hljs-keyword\">int</span> dev = <span class=\"hljs-number\">0</span>;<br>    cudaDeviceProp deviceProp;<br>    <span class=\"hljs-built_in\">CHECK</span>(<span class=\"hljs-built_in\">cudaGetDeviceProperties</span>(&amp;deviceProp, dev));<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Using Device %d: %s\\n&quot;</span>, dev, deviceProp.name);<br>    <br>    <span class=\"hljs-comment\">//set matrix dimension</span><br>    <span class=\"hljs-keyword\">int</span> nx = <span class=\"hljs-number\">8</span>;<br>    <span class=\"hljs-keyword\">int</span> ny = <span class=\"hljs-number\">6</span>;<br>    <span class=\"hljs-keyword\">int</span> nxy = nx*ny;<br>    <span class=\"hljs-keyword\">int</span> nBytes = nxy * <span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">float</span>);<br>    <br>    <span class=\"hljs-comment\">//malloc host memory</span><br>    <span class=\"hljs-keyword\">int</span> *h_A;<br>    h_A = (<span class=\"hljs-keyword\">int</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    <br>    <span class=\"hljs-comment\">//initialize host matrix with interger</span><br>    <span class=\"hljs-built_in\">initialInt</span>(h_A, nxy);<br>    <span class=\"hljs-built_in\">printMatrix</span>(h_A, nx, ny);<br>    <br>    <span class=\"hljs-comment\">//malloc device memory</span><br>    <span class=\"hljs-keyword\">int</span> *d_MatA;<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">void</span>**)&amp;d_MatA, nBytes);<br>    <br>    <span class=\"hljs-comment\">//transfer data from host to device</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_MatA, h_A, nBytes, cudaMemcpyHostToDevice);<br>    <br>    <span class=\"hljs-comment\">//set up execution configuration</span><br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">2</span>)</span></span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">((nx+block.x<span class=\"hljs-number\">-1</span>)/block.x,(ny+block.y<span class=\"hljs-number\">-1</span>)/block.y)</span></span>;<br>    <br>    <span class=\"hljs-comment\">//invoke the kernel</span><br>    printThreadIndex&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_MatA,nx,ny);<br>    <span class=\"hljs-built_in\">cudaDeviceSynchronize</span>();<br>    <br>    <span class=\"hljs-comment\">//free host and device memory</span><br>    <span class=\"hljs-built_in\">cudaFree</span>(d_MatA);<br>    <span class=\"hljs-built_in\">free</span>(h_A);<br>    <br>    <span class=\"hljs-comment\">//reset device</span><br>    <span class=\"hljs-built_in\">cudaDeviceReset</span>();<br>    <br>    <span class=\"hljs-keyword\">return</span>(<span class=\"hljs-number\">0</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/08/cuda013/",
            "url": "https://xingyuanjie.top/2023/03/08/cuda013/",
            "title": "CUDA组织并行编程",
            "date_published": "2023-03-08T14:13:01.000Z",
            "content_html": "<h2 id=\"组织并行编程\"><a href=\"#组织并行编程\" class=\"headerlink\" title=\"组织并行编程\"></a>组织并行编程</h2><p>从前面的例子可以看出，如果使用了合适的网格和块大小来正确地组织线程，那么可以对内核性能产生很大的影响。在向量加法的例子中，为了实现最佳性能我们调整了块的大小，并基于块大小和向量数据大小计算出了网格大小。</p>\n<p>现在通过一个矩阵加法的例子说明这一点。对于矩阵运算，传统的方法是在内核中使用一个包含二维网格与二位块的布局来组织线程。但是，这种传统的方法无法获得最佳性能。在矩阵加法中使用以下布局将有助于了解更多关于网格和块的启发性的用法：</p>\n<ol>\n<li>有二维线程块构成的二维网格</li>\n<li>由一维线程块构成的一维网格</li>\n<li>由一维线程块构成的二维网格</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/07/CUDA012/",
            "url": "https://xingyuanjie.top/2023/03/07/CUDA012/",
            "title": "CUDA给核函数计时",
            "date_published": "2023-03-07T01:53:34.000Z",
            "content_html": "<h2 id=\"CUDA给核函数计时\"><a href=\"#CUDA给核函数计时\" class=\"headerlink\" title=\"CUDA给核函数计时\"></a>CUDA给核函数计时</h2><p>在内核的性能转换过程中，了解核函数的执行需要多长时间是很有帮助并且十分关键的。衡量核函数性能的方法有很多。最简单的方法是在主机端使用一个CPU或GPU计时器来计算内核的执行时间。在本节，你需要设置一个CPU计时器，并使用NVIDIA分析工具来计算执行时间。</p>\n<h3 id=\"用CPU计时器计时\"><a href=\"#用CPU计时器计时\" class=\"headerlink\" title=\"用CPU计时器计时\"></a>用CPU计时器计时</h3><p>可以使用gettimeofday系统调用来创建一个CPU计时器，以获取系统的时钟时间，它将返回自1970年1月1日零点以来，到现在的秒数。程序中需要添加sys&#x2F;time.h头文件，如代码清单2-5所示。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">double</span> <span class=\"hljs-title\">cpuSecond</span><span class=\"hljs-params\">()</span></span><br><span class=\"hljs-function\"></span>&#123;<br>    <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">timeval</span> <span class=\"hljs-title\">tp</span>;</span><br>    <span class=\"hljs-built_in\">gettimeofday</span>(&amp;tp,<span class=\"hljs-literal\">NULL</span>);<br>    <br>    <span class=\"hljs-keyword\">return</span> ((<span class=\"hljs-keyword\">double</span>)tp.tv_sec + (<span class=\"hljs-keyword\">double</span>)tp.tv_usec*<span class=\"hljs-number\">1.e-6</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>你可以用cpuSecond函数来测试你的核函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">double</span> iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>kernel_name&lt;&lt;&lt;grid,block&gt;&gt;&gt;(argument list);<br><span class=\"hljs-built_in\">cudaDeviceSynchronize</span>();<br><span class=\"hljs-keyword\">double</span> iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br></code></pre></div></td></tr></table></figure>\n\n<p>由于核函数调用与主机端程序是异步的，你需要用cudaDeviceSynchronize函数来等待所有的GPU线程运行结束。变量iElaps表示程序运行的时间，就像你用手表记录的核函数的执行时间（用秒计算）。</p>\n<p>现在，通过设置数据集大小来对一个有16M个元素的大向量进行测试：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">int</span> nElem = <span class=\"hljs-number\">1</span>&lt;&lt;<span class=\"hljs-number\">24</span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>由于GPU的可扩展性，你需要借助块和线程的索引来计算一个按行优先的数组索引 i ，并对核函数进行修改，添加限定条件（i &lt; N）来检验索引值是否越界，如下所示：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArraysOnGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> N)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class=\"hljs-keyword\">if</span>( n &lt; N) C[i] = A[i] + B[i];<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>有了这些更改，可以使用不同的执行配置来衡量核函数。为了解决创建的线程总数大于向量元素总数的情况，你需要限制内核不能非法访问全局内存，如图2-7所示。</p>\n<p><img src=\"/2023/03/07/CUDA012/image-20230307120643741.png\" alt=\"image-20230307120643741\"></p>\n<p>代码清单2-5展示了如何在主函数中用CPU计时器测试向量加法的核函数。</p>\n<p>代码清单2-5\t测试向量加法的核函数（sumArraysOnGPU-timer.cu）</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;cuda_runtime.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;sys/time.h&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc,<span class=\"hljs-keyword\">char</span> **argv)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%s Starting...\\n&quot;</span>,argv[<span class=\"hljs-number\">0</span>]);<br>    <br>    <span class=\"hljs-comment\">//set up device</span><br>    <span class=\"hljs-keyword\">int</span> dev = <span class=\"hljs-number\">0</span>;<br>    cudaDeviceProp deviceProp;<br>    <span class=\"hljs-built_in\">CHECK</span>(<span class=\"hljs-built_in\">cudaGetDeviceProperties</span>(&amp;deviceProp, dev));<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Using Device %d: %s\\n&quot;</span>, dev, deviceProp.name);<br>    <span class=\"hljs-built_in\">CHECK</span>(<span class=\"hljs-built_in\">cudaSetDevice</span>(dev));<br>    <br>    <span class=\"hljs-comment\">//set up data size of vectors</span><br>    <span class=\"hljs-keyword\">int</span> nElem = <span class=\"hljs-number\">1</span>&lt;&lt;<span class=\"hljs-number\">24</span>;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Vector size %d\\n&quot;</span>,nElem);<br>    <br>    <span class=\"hljs-comment\">//malloc host memory</span><br>    <span class=\"hljs-keyword\">size_t</span> nBytes = nElem * <span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">float</span>);<br>    <br>    <span class=\"hljs-keyword\">float</span> *h_A, *h_B, *hostRef, *gpuRef;<br>    h_A = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    h_B = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    hostRef = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    gpuRef = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    <br>    <span class=\"hljs-keyword\">double</span> iStart,iElaps;<br>    <br>    <span class=\"hljs-comment\">//initialize data at host side</span><br>    iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>    <span class=\"hljs-built_in\">initialData</span>(h_A, nElem);<br>    <span class=\"hljs-built_in\">initialData</span>(h_B, nElem);<br>    iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br>    <br>    <span class=\"hljs-built_in\">memset</span>(hostRef, <span class=\"hljs-number\">0</span> ,nBytes);<br>    <span class=\"hljs-built_in\">memset</span>(gpuRef, <span class=\"hljs-number\">0</span> ,nBytes);<br>    <br>    <span class=\"hljs-comment\">//add vector at host side for result checks</span><br>    iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>    <span class=\"hljs-built_in\">sumArraysOnHost</span>(h_A, h_B, hostRef, nElem);<br>    iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br>    <br>    <span class=\"hljs-comment\">//malloc device global memory</span><br>    <span class=\"hljs-keyword\">float</span> *d_A, *d_B, *d_C;<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_A, nBytes);<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_B, nBytes);<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_C, nBytes);<br>    <br>    <span class=\"hljs-comment\">//transfer data from host to device</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_A, h_A, nBytes, cudaMemcpyHostTodevice);<br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_B, h_B, nBytes, cudaMemcpyHostTodevice);<br>    <br>    <span class=\"hljs-comment\">//invoke kernel at host side</span><br>    <span class=\"hljs-keyword\">int</span> iLen = <span class=\"hljs-number\">1024</span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(iLen)</span></span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">((nElem+block.x<span class=\"hljs-number\">-1</span>))</span>/block.x)</span>;<br>    <br>    iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>    sumArraysOnGPU&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_A, d_B, d_C,nElem);<br>    <span class=\"hljs-built_in\">cudaDeviceSynchronize</span>();<br>    iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;sumArraysOnGPU&lt;&lt;&lt;%d,%d&gt;&gt;&gt; Time elapsed %f sec\\n&quot;</span>,grid.x, block.x, iElaps);<br>    <br>    <span class=\"hljs-comment\">//copy kernel result back to host side</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);<br>    <br>    <span class=\"hljs-comment\">//check device results</span><br>    <span class=\"hljs-built_in\">checkResult</span>(hostRef, gpuRef, nElem);<br>    <br>    <span class=\"hljs-comment\">//free device global memory</span><br>    <span class=\"hljs-built_in\">cudaFree</span>(d_A);<br>    <span class=\"hljs-built_in\">cudaFree</span>(d_B);<br>    <span class=\"hljs-built_in\">cudaFree</span>(d_C);<br>    <br>    <span class=\"hljs-comment\">//free host memory</span><br>    <span class=\"hljs-built_in\">free</span>(h_A);<br>    <span class=\"hljs-built_in\">free</span>(h_B);<br>    <span class=\"hljs-built_in\">free</span>(hostRef);<br>    <span class=\"hljs-built_in\">free</span>(gpuRef);<br>    <br>    <span class=\"hljs-keyword\">return</span>(<span class=\"hljs-number\">0</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>默认的执行配置被设置为一个包含16384个块的一维网格，每个块包含1024个线程。用以下命令编译并运行程序：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc sumArraysOnGPU-timer.cu -o sumArraysOnGPU-timer<br>./sumArraysOnGPU-timer<br></code></pre></div></td></tr></table></figure>\n\n<p>在基于英特尔Sandy Bridge架构的系统上进行测试，从代码清单2-5的示例中可以看出，在GPU上进行的向量加法的运算速度是在CPU上运行向量加法的3.86倍。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">./sumArraysOnGPU-timer Starting...<br>Using Device 0:Tesia M2070<br>Vector size 16777216<br>sumArraysOnGPU&lt;&lt;&lt;16384, 1024&gt;&gt;&gt;\t\tTime elapsed 0.002456 sec<br>Arrays match.<br></code></pre></div></td></tr></table></figure>\n\n<p>把块的维度减少到512可以创建32768个块。在这个新的配置下，内核的性能提升了1.19倍。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">sumArraysOnGPU&lt;&lt;&lt;32768, 512&gt;&gt;&gt;\tTime elapsed 0.002058 sec<br></code></pre></div></td></tr></table></figure>\n\n<p>如果进一步将块的维度降低到256，系统将提示以下错误信息，信息表示块的总数超过一维网格的限制。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">./sumArraysOnGPU-timer Starting...<br>Using Device 0:\tTesla M2070<br>Vector size 16777216<br>sumArraysOnGPU&lt;&lt;&lt;65536, 256&gt;&gt;&gt;  Time elapsed 0.000183 sec<br>Error: sumArraysOnGPU-timer.cu:153, code:9, reason: invalid configuration argument<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"了解自身局限性\"><a href=\"#了解自身局限性\" class=\"headerlink\" title=\"了解自身局限性\"></a>了解自身局限性</h3><p>在调整执行配置时需要了解的一个关键点是对网格和块维度的限制。线程层次结构中每个层次的最大尺寸取决于设备。</p>\n<p>CUDA提供了通过查询GPU来了解这些限制的能力。</p>\n<p>对于Fermi设备，每个块的最大线程数是1024，且网格的x,y,z三个方向上的维度最大值是65535</p>\n<h3 id=\"用nvprof工具计时\"><a href=\"#用nvprof工具计时\" class=\"headerlink\" title=\"用nvprof工具计时\"></a>用nvprof工具计时</h3><p>自CUDA 5.0以来，NVIDIA提供了一个名为nvprof的命令行分析工具，可以帮助从应用程序的CPU和GPU活动情况中获取时间线信息，其包括内核执行，内存传输以及CUDA API的调用。其用法如下。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvprof [nvprof_args] &lt;application&gt;  [application_args]<br></code></pre></div></td></tr></table></figure>\n\n<p>可以使用以下命令获取更多关于nvprof的帮助信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvprof --help<br></code></pre></div></td></tr></table></figure>\n\n<p>你可以用如下命令去测试内核：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvprof  ./sumArraysOnGPU-timer<br></code></pre></div></td></tr></table></figure>\n\n<p>nvprof的输出结果会因为你使用的GPU类型不同而有所差异。以下结果是从Tesla GPU中得到的：</p>\n<p><img src=\"/2023/03/07/CUDA012/image-20230307142027522.png\" alt=\"image-20230307142027522\"></p>\n<p>以上结果的前半部分来自于程序的输出，后半部分来自于nvprof的输出。可以注意到，CPU计时器显示消耗的内核时间为3.26ms，而nvprof显示消耗的内核时间为2.90ms。在这个例子中，nvprof的结果更为精确，因为CPU计时器测量的时间中包含了来自nvprof附加的时间。</p>\n<p>nvprof是一个能帮助你理解在执行应用程序时所花费的时间主要用在何处的强大工具。可以注意到，在这个例子中，主机和设备之间的数据传输需要的时间比内核执行的时间要多。图2-8所描绘的时间线（未按比例绘制），显示了在CPU上消耗的时间，数据传输所用的时间以及在GPU上计算所用的时间。</p>\n<p><img src=\"/2023/03/07/CUDA012/image-20230307145539161.png\" alt=\"image-20230307145539161\"></p>\n<p>对于HPC工作负载，理解程序中通信比的计算是非常重要的。如果你的应用程序用于计算的时间大于数据传输所用的时间，那么或许可以压缩这些操作，并完全隐藏与传输数据有关的延迟。如果你的应用程序用于计算的时间少于数据传输所用的时间，那么需要尽量减少主机和设备之间的传输。</p>\n<h3 id=\"比较应用程序的性能将理论界限最大化\"><a href=\"#比较应用程序的性能将理论界限最大化\" class=\"headerlink\" title=\"比较应用程序的性能将理论界限最大化\"></a>比较应用程序的性能将理论界限最大化</h3><p>在进行程序优化时，如何将应用程序和理论界限进行比较是很重要的。由nvprof得到的计数器可以帮助你获取应用程序的指令和内存吞吐量。如果将应用程序的测量值与理论峰值进行比较，可以判定你的应用程序的性能是受限于算法还是受限于内存带宽的。以Tesla K10为例，可以得到理论上的比率：</p>\n<p>Tesla K10单精度峰值浮点运算次数</p>\n<p>745 MHz核心频率*2 GPU&#x2F;芯片*  （8个多处理器<em>192个浮点单元</em>32核心&#x2F;多处理器）*2OPS&#x2F;周期 &#x3D; 4.58 TFLOPS （FLOPS表示每秒浮点运算次数）</p>\n<p>Tesla K10内存带宽峰值</p>\n<p>2 GPU&#x2F;芯片<em>256位</em>2500 MHz内存时钟*2 DDR&#x2F;8位&#x2F;字节 &#x3D; 320 GB&#x2F;s</p>\n<p>指令比：字节</p>\n<p>4.58 TFLOPS&#x2F;320 GB&#x2F;s,\t也就是13.6个指令：1个字节</p>\n<p>对于Tesla K10而言，如果你的应用程序每访问一个字节所产生的指令数多于13.6，那么你的应用程序受算法性能限制。大多数HPC工作负载受内存带宽的限制。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/06/ML001/",
            "url": "https://xingyuanjie.top/2023/03/06/ML001/",
            "title": "线性回归模型",
            "date_published": "2023-03-06T11:00:34.000Z",
            "content_html": "<h2 id=\"线性回归模型\"><a href=\"#线性回归模型\" class=\"headerlink\" title=\"线性回归模型\"></a>线性回归模型</h2><h3 id=\"MOdel-Representation\"><a href=\"#MOdel-Representation\" class=\"headerlink\" title=\"MOdel Representation\"></a>MOdel Representation</h3><p><img src=\"/2023/03/06/ML001/image-20230306195956356.png\" alt=\"image-20230306195956356\"></p>\n<h3 id=\"Goals\"><a href=\"#Goals\" class=\"headerlink\" title=\"Goals\"></a>Goals</h3><p>In this lab you will:</p>\n<ul>\n<li>learn to implement the model f_{w,b} for linear regression with one variable</li>\n</ul>\n<h3 id=\"Notation\"><a href=\"#Notation\" class=\"headerlink\" title=\"Notation\"></a>Notation</h3><p>Here is a summary of some of the notation you will encounter.</p>\n<p><img src=\"/2023/03/06/ML001/image-20230306200250050.png\" alt=\"image-20230306200250050\"></p>\n<h3 id=\"Tools\"><a href=\"#Tools\" class=\"headerlink\" title=\"Tools\"></a>Tools</h3><p>In this lab you will make use of:</p>\n<ul>\n<li><p>NumPy,a popular library for scientific computing</p>\n</li>\n<li><p>Matplotlib,a popular library for plotting data</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br>plt.style.use(<span class=\"hljs-string\">&#x27;./deeplearning.mpstyle&#x27;</span>)<br></code></pre></div></td></tr></table></figure></li>\n</ul>\n<h3 id=\"Problem-Statement\"><a href=\"#Problem-Statement\" class=\"headerlink\" title=\"Problem Statement\"></a>Problem Statement</h3><p><img src=\"/2023/03/06/ML001/image-20230306200642937.png\" alt=\"image-20230306200642937\"></p>\n<p>As in the lecture,you will use the motivating example of housing price prediction. This lab will use a simple data set with only two data points - a house with 1000 square feet(sqft) sold for $300,000 and a house with 2000 square feet sold for $500,000.These two points will constitute our data or training set. In this lab, the units of size are 1000 sqft and the units of price are 1000s of dollars.</p>\n<table>\n<thead>\n<tr>\n<th>Size (1000 sqft)</th>\n<th>Price (1000s of dollars)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1.0</td>\n<td>300</td>\n</tr>\n<tr>\n<td>2.0</td>\n<td>500</td>\n</tr>\n</tbody></table>\n<p>You would like to fit a linear regression model(shown above as the blue straight line)through these two points, so you can then predict price for other houses - say, a house with 1200 sqft.</p>\n<p>Please run the following code cell to create your x_train and y_train variables. The data is stored in one-dimensional NumPy arrays.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\">#x_train is the input variable (size in 1000 square feet)</span><br><span class=\"hljs-comment\">#y_train is the target (price in 1000s of dollars)</span><br>x_train = np.array([<span class=\"hljs-number\">1.0</span>,<span class=\"hljs-number\">2.0</span>])<br>y_train = np.array([<span class=\"hljs-number\">300.0</span>,<span class=\"hljs-number\">500.0</span>])<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;x_train = <span class=\"hljs-subst\">&#123;x_train&#125;</span>&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;y_train = <span class=\"hljs-subst\">&#123;y_train&#125;</span>&quot;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"Number-of-training-examples-m\"><a href=\"#Number-of-training-examples-m\" class=\"headerlink\" title=\"Number of training examples m\"></a>Number of training examples m</h3><p>you will use m to denote the number of training examples. Numpy arrays have a .shape parameter. x_train.shape return a python tuple with an entry for each dimension. x_train.shape[0] is the length of the array and number of examples as shown below.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># m is the number of training examples</span><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;x_train.shape: <span class=\"hljs-subst\">&#123;x_train.shape&#125;</span>&quot;</span>)<br>m = x_train.shape[<span class=\"hljs-number\">0</span>]<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;Number of training example is: <span class=\"hljs-subst\">&#123;m&#125;</span>&quot;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<p>x.train.shape: (2,)</p>\n<p>Number of training examples is: 2</p>\n<p><strong>One can also use the Python len() function as shown below.</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># m is the number of training examples</span><br>m = <span class=\"hljs-built_in\">len</span>(x_train)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;Number of training example is: <span class=\"hljs-subst\">&#123;m&#125;</span>&quot;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<p>Number of training examples  is:\t2</p>\n<h3 id=\"Training-example-x-i-y-i\"><a href=\"#Training-example-x-i-y-i\" class=\"headerlink\" title=\"Training example x_i, y_i\"></a>Training example x_i, y_i</h3><p>You will use (x(𝑖), y(𝑖)) to denote the 𝑖(th) training example. Since Python is zero indexed, (x(0), y(0) is (1.0, 300.0) and (x(1), y(1) is (2.0, 500.0).</p>\n<p>To access a value in a Numpy array, one indexes the array with the desired offset. For example the syntax to access location zero of x_train is x_train[0]. Run the next code block below to get the i(th) training example.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">i = <span class=\"hljs-number\">0</span> <span class=\"hljs-comment\">#Change this to 1 to see (x^1,y^1)</span><br><br>x_i = x_train[i]<br>y_i = y_train[i]<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;(x^(<span class=\"hljs-subst\">&#123;i&#125;</span>), y^(<span class=\"hljs-subst\">&#123;i&#125;</span>)) = (<span class=\"hljs-subst\">&#123;x_i&#125;</span>, <span class=\"hljs-subst\">&#123;y_i&#125;</span>)&quot;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">(x^(<span class=\"hljs-number\">0</span>), y^(<span class=\"hljs-number\">0</span>)) = (<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">300.0</span>)<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"Plotting-the-data\"><a href=\"#Plotting-the-data\" class=\"headerlink\" title=\"Plotting the data\"></a>Plotting the data</h3><p>You can plot these two points using the scatter() function is the matplotlib library,as shown in the cell below.</p>\n<ul>\n<li>The function arguments marker and c show the points as red crosses(the default is blue dots.)</li>\n</ul>\n<p>You can use other functions in the matplotlib library to set title and labels to display.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\">#Plot the data points</span><br>plt.scatter(x_train, y_train, marker=<span class=\"hljs-string\">&#x27;x&#x27;</span> c=<span class=\"hljs-string\">&#x27;r&#x27;</span>)<br><span class=\"hljs-comment\">#Set the title</span><br>plt.title(<span class=\"hljs-string\">&quot;Housing Prices&quot;</span>)<br><span class=\"hljs-comment\">#Set the y-axis label</span><br>plt.ylabel(<span class=\"hljs-string\">&#x27;Price (in 1000s of dollars)&#x27;</span>)<br><span class=\"hljs-comment\">#Set the x-axis lbel</span><br>plt.xlabel(<span class=\"hljs-string\">&#x27;Size (1000 sqft)&#x27;</span>)<br>plt.show()<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/06/ML001/image-20230306204822102.png\" alt=\"image-20230306204822102\"></p>\n<h3 id=\"Model-function\"><a href=\"#Model-function\" class=\"headerlink\" title=\"Model function\"></a>Model function</h3><p><img src=\"/2023/03/06/ML001/image-20230306204918585.png\" alt=\"image-20230306204918585\"></p>\n<p>As described in lecture, the model function for linear regression (which is a function that maps from x to y)is represented as</p>\n<p><img src=\"/2023/03/06/ML001/image-20230306205107527.png\" alt=\"image-20230306205107527\"></p>\n<p>The formula above is how you can represent straight lines - different values of w and b give you different straight lines on the plot.</p>\n<p>Let’s try to get a better intuition for this through the code blocks below. Let’s start with w &#x3D; 100 and b &#x3D;100.</p>\n<p>Note: You can come back to this cell to adjust the model’s w and b parameters.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">w = <span class=\"hljs-number\">100</span><br>b = <span class=\"hljs-number\">100</span><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;w: <span class=\"hljs-subst\">&#123;w&#125;</span>&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;b: <span class=\"hljs-subst\">&#123;b&#125;</span>&quot;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">w:\t<span class=\"hljs-number\">100</span><br>b:\t<span class=\"hljs-number\">100</span><br></code></pre></div></td></tr></table></figure>\n\n<p>Now,let’s compute the value of f_{w,b}(x^i) for your two data points. You can explicitly write this out for each data poins as -</p>\n<p>for x(0),f_wb &#x3D; w * x[0] + b</p>\n<p>for x(1),f_wb &#x3D; w * x[1] + b</p>\n<p>For a large number of data points, this can get unwieldy and repetitive. So instead, you can calculate the function output in a for loop as shown in the compute_model_output function below.</p>\n<p>Note:The argument description (ndarray (m,)) describes a Numpy n-dimensional array of shape (m,). (scalar) describes an argument without dimensions, just a magnitude.</p>\n<p>Note: np.zero(n) will return a one-dimensional numpy array with n entries</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">compute_model_output</span>(<span class=\"hljs-params\">x, w, b</span>):</span><br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    Computes the prediction of a linear model</span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">    \tx (ndarray (m,)):Data, m examples</span><br><span class=\"hljs-string\">    \tw,b (scalar)\t:model parameters</span><br><span class=\"hljs-string\">    Returns</span><br><span class=\"hljs-string\">    \ty (ndarray (m,)):target values</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <br>    m = x.shape[<span class=\"hljs-number\">0</span>]<br>    f_wb = np.zeros(m)<br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(m)<br>    \tf_wb[i] = w * x[i] + b<br>    <br>    <span class=\"hljs-keyword\">return</span> f_wb<br></code></pre></div></td></tr></table></figure>\n\n<p>Now let’s call the compute_model_output function and plot the output.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">tmp_f_wb = compute_model_output(x_train, w, b,)<br><br><span class=\"hljs-comment\">#Plot our model prediction</span><br>plt.plot(x_train, tmp_f_wb, c=<span class=\"hljs-string\">&#x27;b&#x27;</span>,label=<span class=\"hljs-string\">&#x27;Our Prediction&#x27;</span>)<br><br><span class=\"hljs-comment\">#Plot the data points</span><br>plt.scatter(x_train, y_train, marker=<span class=\"hljs-string\">&#x27;x&#x27;</span>, c=<span class=\"hljs-string\">&#x27;r&#x27;</span>,label=<span class=\"hljs-string\">&#x27;Actual Values&#x27;</span>)<br><br><span class=\"hljs-comment\">#Set the title</span><br>plt.title(<span class=\"hljs-string\">&quot;Housing Prices&quot;</span>)<br><span class=\"hljs-comment\">#Set the y-axis label</span><br>plt.ylabel(<span class=\"hljs-string\">&#x27;Price (in 1000s of dollars)&#x27;</span>)<br><span class=\"hljs-comment\">#Set the x-axis label</span><br>plt.xlabel(<span class=\"hljs-string\">&#x27;Size (1000 sqft)&#x27;</span>)<br>plt.legend()<br>plt.show()<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/06/ML001/image-20230306211337338.png\" alt=\"image-20230306211337338\"></p>\n<p>As you can see, setting w &#x3D; 100 and b &#x3D; 100 does not result in a line that fits our data.</p>\n<h3 id=\"Challenge\"><a href=\"#Challenge\" class=\"headerlink\" title=\"Challenge\"></a>Challenge</h3><p>Try experimenting with different values of w and b. What should the values be for a line that fits our data?</p>\n<p><strong>Tips:</strong></p>\n<p>You can use  your mouse to click on the triangle to the left of the green “Hints” below to reveal some hints for choosing b and w.</p>\n<p><strong>Hints</strong></p>\n<h3 id=\"Prediction\"><a href=\"#Prediction\" class=\"headerlink\" title=\"Prediction\"></a>Prediction</h3><p>Now that we have a model, we can use it to make our original prediction. Let’s predict the price of a house with 1200 sqft. Since the units of x are in 1000’s of sqft, x is 1.2.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">w = <span class=\"hljs-number\">200</span><br>b = <span class=\"hljs-number\">100</span><br>x_i = <span class=\"hljs-number\">1.2</span><br>cost_1200sqft = w * x_i + b<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;$<span class=\"hljs-subst\">&#123;cost_1200sqft:<span class=\"hljs-number\">.0</span>f&#125;</span> thousand dollars&quot;</span> )<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">$<span class=\"hljs-number\">340</span> thousand dollars<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"Congratulations\"><a href=\"#Congratulations\" class=\"headerlink\" title=\"Congratulations!\"></a>Congratulations!</h3><p>In this lab you have learned:</p>\n<ul>\n<li>Linear regression bulids a model which establishes a relationship between features and targets</li>\n<li>In the example above, the feature was house size and the target was house price</li>\n<li>for simple linear regression, the model has two parameters w and b whose calue are ‘fit’ using training data.</li>\n<li>once a model’s parameters have been determined, the model can be used to make predictions on novel data.</li>\n</ul>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://www.bilibili.com/video/BV1Pa411X76s?p=5&amp;vd_source=3ae32e36058f58c5b85935fca9b77797\">https://www.bilibili.com/video/BV1Pa411X76s?p=5&amp;vd_source=3ae32e36058f58c5b85935fca9b77797</a></p>\n<p><a href=\"https://github.com/kaieye/2022-Machine-Learning-Specialization\">kaieye&#x2F;2022-Machine-Learning-Specialization (github.com)</a></p>\n",
            "tags": [
                "Tensorflow",
                "Machine Learning"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/06/cuda011/",
            "url": "https://xingyuanjie.top/2023/03/06/cuda011/",
            "title": "CUDA编译与执行",
            "date_published": "2023-03-06T08:18:09.000Z",
            "content_html": "<h2 id=\"CUDA编译与执行\"><a href=\"#CUDA编译与执行\" class=\"headerlink\" title=\"CUDA编译与执行\"></a>CUDA编译与执行</h2><p>现在把所有的代码放在一个文件名为sumArraysOnGPU-small-case.cu的文件中，如代码清单2-4所示。</p>\n<p><strong>代码清单2-4\t\t基于GPU的向量加法（sumArraysOnGPU-small-case.cu）</strong></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;cuda_runtime.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-comment\">/*</span><br><span class=\"hljs-comment\">#define CHECK(call)</span><br><span class=\"hljs-comment\">&#123;</span><br><span class=\"hljs-comment\">    const cudaError_t error = call;</span><br><span class=\"hljs-comment\">    if(error != cudaSuccess)</span><br><span class=\"hljs-comment\">    &#123;</span><br><span class=\"hljs-comment\">        printf(&quot;Error:%s:%d, &quot;, __FILE__, __LINE__);</span><br><span class=\"hljs-comment\">        printf(&quot;code:%d, reason: %s\\n&quot;, error, cudaGetErrorString(error));</span><br><span class=\"hljs-comment\">    &#125;</span><br><span class=\"hljs-comment\">&#125;</span><br><span class=\"hljs-comment\">*/</span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">checkResult</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *hostRef, <span class=\"hljs-keyword\">float</span> *gpuRef, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> N)</span></span>&#123;<br>    <span class=\"hljs-keyword\">double</span> epsilon = <span class=\"hljs-number\">1.0E-8</span>;<br>    <span class=\"hljs-keyword\">int</span> match = <span class=\"hljs-number\">1</span>;<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span> ;i &lt; N; i++)&#123;<br>        <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">abs</span>(hostRef[i] - gpuRef[i]) &gt; epsilon)&#123;<br>            match = <span class=\"hljs-number\">0</span>;<br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Arrays do not match!\\n&quot;</span>);<br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;host %5.2f gpu %5.2f at current %d\\n&quot;</span>,hostRef[i],gpuRef[i],i);<br>            <span class=\"hljs-keyword\">break</span>;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-keyword\">if</span>(match) <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Arrays match.\\n\\n&quot;</span>);<br>    <span class=\"hljs-keyword\">return</span>;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">initialData</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *ip,<span class=\"hljs-keyword\">int</span> size)</span></span>&#123;<br>    <span class=\"hljs-comment\">//generate different seed for random number</span><br>    <span class=\"hljs-keyword\">time_t</span> t;<br>    <span class=\"hljs-built_in\">srand</span>((<span class=\"hljs-keyword\">unsigned</span>) <span class=\"hljs-built_in\">time</span>(&amp;t));<br>    <br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i&lt;size;i++)&#123;<br>        ip[i] = (<span class=\"hljs-keyword\">float</span>)(<span class=\"hljs-built_in\">rand</span>() &amp; <span class=\"hljs-number\">0xFF</span>) /<span class=\"hljs-number\">10.0f</span>;<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArraysOnHost</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A,<span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> i = threadIdx.x;<br>    C[i] = A[i] + B[i];<br>&#125;<br><br><span class=\"hljs-function\">__gloal__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArraysOnGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> i = threadIdx.x;<br>    C[i] = A[i] + B[i];<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc,<span class=\"hljs-keyword\">char</span> **argv)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%s Starting...\\n&quot;</span>,argv[<span class=\"hljs-number\">0</span>]);<br>    <br>    <span class=\"hljs-comment\">//set up device</span><br>    <span class=\"hljs-keyword\">int</span> dev = <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-built_in\">cudaSetDevice</span>(dev);<br>    <br>    <span class=\"hljs-comment\">//set up data size of vectors</span><br>    <span class=\"hljs-keyword\">int</span> nElem = <span class=\"hljs-number\">32</span>;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Vector size %d\\n&quot;</span>,nElem);<br>    <br>    <span class=\"hljs-comment\">//malloc host memory</span><br>    <span class=\"hljs-keyword\">size_t</span> nBytes = nElem * <span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">float</span>);<br>    <br>    <span class=\"hljs-keyword\">float</span> *h_A, *h_B, *hostRef, *gpuRef;<br>    h_A = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    h_B = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    hostRef = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    gpuRef = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    <br>    <span class=\"hljs-comment\">//initialize data at host side</span><br>    <span class=\"hljs-built_in\">initialData</span>(h_A, nElem);<br>    <span class=\"hljs-built_in\">initialData</span>(h_B, nElem);<br>    <br>    <span class=\"hljs-built_in\">memset</span>(hostRef, <span class=\"hljs-number\">0</span> ,nBytes);<br>    <span class=\"hljs-built_in\">memset</span>(gpuRef, <span class=\"hljs-number\">0</span> ,nBytes);<br>    <br>    <span class=\"hljs-comment\">//malloc device global memory</span><br>    <span class=\"hljs-keyword\">float</span> *d_A, *d_B, *d_C;<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_A, nBytes);<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_B, nBytes);<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_C, nBytes);<br>    <br>    <span class=\"hljs-comment\">//transfer data from host to device</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_A, h_A, nBytes, cudaMemcpyHostTodevice);<br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_B, h_B, nBytes, cudaMemcpyHostTodevice);<br>    <br>    <span class=\"hljs-comment\">//invoke kernel at host side</span><br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(nElem)</span></span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">(nElem/block.x)</span></span>;<br>    <br>    sumArraysOnGPU&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_A, d_B, d_C);<br>    <span class=\"hljs-built_in\">pritnf</span>(<span class=\"hljs-string\">&quot;Execution configuration &lt;&lt;&lt;%d, %d&gt;&gt;&gt;\\n&quot;</span>,grid.x,block.x);<br>    <br>    <span class=\"hljs-comment\">//copy kernel result back to host side</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);<br>    <br>    <span class=\"hljs-comment\">//add vector at host side for result checks</span><br>    <span class=\"hljs-built_in\">sumArraysOnHost</span>(h_A, h_B, hostRef, nElem);<br>    <br>    <span class=\"hljs-comment\">//check device results</span><br>    <span class=\"hljs-built_in\">checkResult</span>(hostRef, gpuRef, nElem);<br>    <br>    <span class=\"hljs-comment\">//free device global memory</span><br>    <span class=\"hljs-built_in\">cudaFree</span>(d_A);<br>    <span class=\"hljs-built_in\">cudaFree</span>(d_B);<br>    <span class=\"hljs-built_in\">cudaFree</span>(d_C);<br>    <br>    <span class=\"hljs-comment\">//free host memory</span><br>    <span class=\"hljs-built_in\">free</span>(h_A);<br>    <span class=\"hljs-built_in\">free</span>(h_B);<br>    <span class=\"hljs-built_in\">free</span>(hostRef);<br>    <span class=\"hljs-built_in\">free</span>(gpuRef);<br>    <br>    <span class=\"hljs-keyword\">return</span>(<span class=\"hljs-number\">0</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>在这段代码中，向量大小被设置为32，如下所示：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">int</span> nElem = <span class=\"hljs-number\">32</span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>执行配置被放入一个块内，其中包含32个元素：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(nElem)</span></span>;<br><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">(nElem/block.x)</span></span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>使用以下命令编译和执行该带啊吗：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc sumArraysOnGPU-small-case.cu -o addvector<br>./addvector<br></code></pre></div></td></tr></table></figure>\n\n<p>系统报告如下：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">./addvector Starting...<br>Vector size 32<br>Execution configuration &lt;&lt;&lt;1,32&gt;&gt;&gt;<br>Arrays match.<br></code></pre></div></td></tr></table></figure>\n\n<p>如果你将执行配置重新定义为32个块，每个块只有一个元素，如下所示；</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(<span class=\"hljs-number\">1</span>)</span></span>;<br><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">(nElem)</span></span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>那么就需要在代码清单2-4中对核函数sumArraysOnGPU进行修改：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">用<span class=\"hljs-keyword\">int</span> i = threadIdx.x;    替换<span class=\"hljs-keyword\">int</span> i = blockIdx.x;<br></code></pre></div></td></tr></table></figure>\n\n<p>一般情况下，可以基于给定的一维网格和块的信息来计算全局数据访问的唯一索引：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__gloal__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArraysOnGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> i = blockIdx.x * blockDim.x * threadIdx.x;<br>    C[i] = A[i] + B[i];<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>你需要确保一般情况下进行更改所产生结果的正确性。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/06/cuda010/",
            "url": "https://xingyuanjie.top/2023/03/06/cuda010/",
            "title": "CUDA处理错误",
            "date_published": "2023-03-06T08:17:59.000Z",
            "content_html": "<h2 id=\"CUDA处理错误\"><a href=\"#CUDA处理错误\" class=\"headerlink\" title=\"CUDA处理错误\"></a>CUDA处理错误</h2><p>由于许多CUDA调用是异步的，所以有时可能很难确定某个错误是由哪一步程序引起的。定义一个错误处理宏封装所有的CUDA API调用，这简化了错误检查过程：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> CHECK(call)</span><br>&#123;<br>    <span class=\"hljs-keyword\">const</span> cudaError_t error = call;<br>    <span class=\"hljs-keyword\">if</span>(error != cudaSuccess)<br>    &#123;<br>        <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Error:%s:%d, &quot;</span>, __FILE__, __LINE__);<br>        <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;code:%d, reason: %s\\n&quot;</span>, error, <span class=\"hljs-built_in\">cudaGetErrorString</span>(error));<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>例如，你可以在以下代码中使用宏：</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs reasonml\"><span class=\"hljs-constructor\">CHECK(<span class=\"hljs-params\">cudaMemcpy</span>(<span class=\"hljs-params\">d_C</span>, <span class=\"hljs-params\">gpuRef</span>, <span class=\"hljs-params\">nBytes</span>, <span class=\"hljs-params\">cudaMemcpyHostToDevice</span>)</span>);<br></code></pre></div></td></tr></table></figure>\n\n<p>如果内存拷贝或之前的异步操作产生了错误，这个宏会报告错误代码，并输出一个可读信息，然后停止程序。也可以用下述方法，在核函数调用后检查核函数错误：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">kernel_function&lt;&lt;&lt;grid,block&gt;&gt;&gt;(argument list);<br><span class=\"hljs-built_in\">CHECK</span>(<span class=\"hljs-built_in\">cudaDeviceSynchronize</span>());<br></code></pre></div></td></tr></table></figure>\n\n<p>CHECK(cudaDeviceSynchronize())会阻塞主机端线程的运行直到设备端所有的请求任务都结束，并确保最后的核函数启动部分不会出错。以上仅是以调试为目的的，因为在核函数启动后添加这个检查点会阻塞主机端线程，使该检查点成为全局屏障。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/06/cuda009/",
            "url": "https://xingyuanjie.top/2023/03/06/cuda009/",
            "title": "CUDA验证核函数",
            "date_published": "2023-03-06T08:06:35.000Z",
            "content_html": "<h2 id=\"CUDA验证核函数\"><a href=\"#CUDA验证核函数\" class=\"headerlink\" title=\"CUDA验证核函数\"></a>CUDA验证核函数</h2><p>既然你已经编写了核函数，你如何能知道它是否正确运行？你需要一个主机函数来验证核函数的结果。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">checkResult</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *hostRef, <span class=\"hljs-keyword\">float</span> *gpuRef, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> N)</span></span>&#123;<br>    <span class=\"hljs-keyword\">double</span> epsilon = <span class=\"hljs-number\">1.0E-8</span>;<br>    <span class=\"hljs-keyword\">int</span> match = <span class=\"hljs-number\">1</span>;<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span> ;i &lt; N; i++)&#123;<br>        <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">abs</span>(hostRef[i] - gpuRef[i]) &gt; epsilon)&#123;<br>            match = <span class=\"hljs-number\">0</span>;<br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Arrays do not match!\\n&quot;</span>);<br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;host %5.2f gpu %5.2f at current %d\\n&quot;</span>,hostRef[i],gpuRef[i],i);<br>            <span class=\"hljs-keyword\">break</span>;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-keyword\">if</span>(match) <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Arrays match.\\n\\n&quot;</span>);<br>    <span class=\"hljs-keyword\">return</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"验证核函数代码\"><a href=\"#验证核函数代码\" class=\"headerlink\" title=\"验证核函数代码\"></a>验证核函数代码</h3><p>除了许多可用的调试工具外，还有两个非常简单实用的方法可以验证核函数。</p>\n<p>首先，你可以在Fermi及更高版本的设备端的核函数中使用printf函数。</p>\n<p>其次，可以将执行参数设置为&lt;&lt;&lt;1,1&gt;&gt;&gt;，因此强制用一个块和一个线程执行核函数，这模拟了串行执行程序。这对于调试和验证结果是否正确是非常有用的，而且，如果你遇到了运算次序的问题，这有助于你对比验证数值结果是否是按位精确的。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/06/cuda008/",
            "url": "https://xingyuanjie.top/2023/03/06/cuda008/",
            "title": "CUDA编写核函数",
            "date_published": "2023-03-06T07:46:00.000Z",
            "content_html": "<h2 id=\"编写核函数\"><a href=\"#编写核函数\" class=\"headerlink\" title=\"编写核函数\"></a>编写核函数</h2><p>核函数是在设备端执行的代码。在核函数中，需要为一个线程规定要进行的计算以及要进行的数据访问。当核函数被调用时，许多不同的CUDA线程并行执行同一个计算任务。以下是用_<em>global</em>_</p>\n<p>声明定义核函数：</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs reasonml\">__global__  void kernel<span class=\"hljs-constructor\">_name(<span class=\"hljs-params\">argument</span> <span class=\"hljs-params\">list</span>)</span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>核函数必须有一个void返回类型。</p>\n<p>表2-2总结了CUDA C程序中的函数类型限定符。函数类型限定符指定一个函数在主机上执行还是在设备上执行，以及可被主机调用还是被设备调用。</p>\n<p><img src=\"/2023/03/06/cuda008/image-20230306155126122.png\" alt=\"image-20230306155126122\"></p>\n<p>_<em>device</em>_   和 __host__限定符可以一齐使用，这样函数可以同时在主机和设备端进行编译。</p>\n<h3 id=\"CUDA核函数的限制\"><a href=\"#CUDA核函数的限制\" class=\"headerlink\" title=\"CUDA核函数的限制\"></a>CUDA核函数的限制</h3><p>以下限制适用于所有核函数：</p>\n<ul>\n<li>只能访问设备内存</li>\n<li>必须具有void返回类型</li>\n<li>不支持可变数量的参数</li>\n<li>不支持静态变量</li>\n<li>显示异步行为</li>\n</ul>\n<p>考虑一个简单的例子：将两个大小为N的向量A和B相加，主机端的向量加法C代码如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArrayOnHost</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> N)</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>;i &lt; N; i++)<br>        C[i] = A[i] + B[i];<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>这是一个迭代N次的串行程序，循环结束后将产生以下核函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArrayOnHost</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C)</span></span>&#123;<br>    \t<span class=\"hljs-keyword\">int</span> i = threadIdx.x;<br>        C[i] = A[i] + B[i];<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>C函数和核函数之间有什么不同？你可能已经注意到循环体消失了，内置的线程坐标变量替换了数组索引，由于N是被隐式定义用来启动N个线程的，所以N没有什么参考价值。</p>\n<p>假设有一个长度为32个元素的向量，你可以按以下方法用32个线程来调用核函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">sumArraysOnGPU&lt;&lt;&lt;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">32</span>&gt;&gt;&gt;(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C);<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/06/cuda007/",
            "url": "https://xingyuanjie.top/2023/03/06/cuda007/",
            "title": "启动一个CUDA核函数",
            "date_published": "2023-03-06T05:59:18.000Z",
            "content_html": "<h2 id=\"启动一个CUDA核函数\"><a href=\"#启动一个CUDA核函数\" class=\"headerlink\" title=\"启动一个CUDA核函数\"></a>启动一个CUDA核函数</h2><p>你应该对下列C语言函数调用语句很熟悉：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">function_name</span> (argument list);<br></code></pre></div></td></tr></table></figure>\n\n<p>CUDA内核调用是对C语言函数调用语句的延申，&lt;&lt;&lt;&gt;&gt;&gt;运算符内是核函数的执行配置。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">kerbel_name&lt;&lt;&lt;grid,block&gt;&gt;&gt;(srgument list);<br></code></pre></div></td></tr></table></figure>\n\n<p>正如上一节所述，CUDA编程模型揭示了线程层次结构。利用执行配置可以指定线程在GPU上调度运行的方式。执行配置的第一个值是网格维度，也就是启动块的数目。第二个值是块维度，也就是每个块中线程的数目。通过指定网格和块的维度，你可以进行一下配置：</p>\n<ul>\n<li>内核中线程的数目</li>\n<li>内核中使用的线程布局</li>\n</ul>\n<p>同一个块中的线程之间可以相互协作，不同块内的线程不能协作。对于一个给定的问题，可以使用不同的网格和块布局来组织你的线程。例如，假设你有32个数据元素用于计算，每8个元素一个块，需要启动4个块：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">kernel_name&lt;&lt;&lt;<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">8</span>&gt;&gt;&gt;(argument list);<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/06/cuda007/image-20230306140924311.png\" alt=\"image-20230306140924311\"></p>\n<p>由于数据在全局内存中是线性存储的，因此可以用变量blockIdx.x和threadIdx.x来进行以下操作。</p>\n<ul>\n<li>在网格中标识一个唯一的线程</li>\n<li>建立线程和数据元素之间的映射关系</li>\n</ul>\n<p>如果把32个元素放到一个块里，那么只会得到一个块：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">kernel_name&lt;&lt;&lt;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">32</span>&gt;&gt;&gt;(argument list);<br></code></pre></div></td></tr></table></figure>\n\n<p>如果每个块只含一个元素，那么会有32个块：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">kernel_name&lt;&lt;&lt;<span class=\"hljs-number\">32</span>,<span class=\"hljs-number\">1</span>&gt;&gt;&gt;(argument list);<br></code></pre></div></td></tr></table></figure>\n\n<p>核函数的调用与主机线程是异步的。核函数调用结束后，控制权立刻返回给主机端。你可以调用以下函数来强制主机端程序等待所有的核函数执行结束：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">cudaError_t <span class=\"hljs-title\">cudaDeviceSynchronize</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>一些CUDA运行时API在主机和设备之间是隐式同步的。当使用cudaMemcpy函数在主机和设备之间拷贝数据时，主机端隐式同步，即主机端程序必须等待数据拷贝完成后才能继续执行程序。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">cudaError_t <span class=\"hljs-title\">cudaMemcpy</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>* dst, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">void</span>* src, <span class=\"hljs-keyword\">size_t</span> count, cudaMemcpyKind kind)</span></span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>之前所有的核函数调用完成后开始拷贝数据。当拷贝完成后，控制权立刻返回给主机端。</p>\n<h3 id=\"异步行为\"><a href=\"#异步行为\" class=\"headerlink\" title=\"异步行为\"></a>异步行为</h3><p>不同于C语言的函数调用，所有的CUDA核函数的启动都是异步的。CUDA内核调用完成后，控制权立刻返回给CPU。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/02/leetcode205/",
            "url": "https://xingyuanjie.top/2023/03/02/leetcode205/",
            "title": "205.同构字符串",
            "date_published": "2023-03-02T12:44:27.000Z",
            "content_html": "<h2 id=\"205-同构字符串\"><a href=\"#205-同构字符串\" class=\"headerlink\" title=\"205.同构字符串\"></a>205.同构字符串</h2><h2 id=\"题目链接\"><a href=\"#题目链接\" class=\"headerlink\" title=\"题目链接\"></a>题目链接</h2><p><a href=\"https://leetcode.cn/problems/isomorphic-strings/\">205. 同构字符串 - 力扣（LeetCode）</a></p>\n<h2 id=\"完整代码\"><a href=\"#完整代码\" class=\"headerlink\" title=\"完整代码\"></a>完整代码</h2><figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span> &#123;</span><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">bool</span> <span class=\"hljs-title\">isIsomorphic</span><span class=\"hljs-params\">(string s, string t)</span> </span>&#123;<br>        string ss;<br>        string st;<br>        <span class=\"hljs-keyword\">int</span> hash[<span class=\"hljs-number\">255</span>];<br>        <span class=\"hljs-keyword\">int</span> index=<span class=\"hljs-number\">0</span>;<br>        <span class=\"hljs-built_in\">memset</span>(hash, <span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(hash));<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i=<span class=\"hljs-number\">0</span>;i&lt;s.<span class=\"hljs-built_in\">size</span>();i++)&#123;<br>            <span class=\"hljs-keyword\">if</span>(hash[<span class=\"hljs-built_in\"><span class=\"hljs-keyword\">int</span></span>(s[i])]==<span class=\"hljs-number\">0</span>)<br>            &#123;<br>                index++;<br>                hash[<span class=\"hljs-built_in\"><span class=\"hljs-keyword\">int</span></span>(s[i])]=index;<br>                ss.<span class=\"hljs-built_in\">push_back</span>(index+<span class=\"hljs-string\">&#x27;0&#x27;</span>);<br>            &#125;<span class=\"hljs-keyword\">else</span>&#123;<br>                ss.<span class=\"hljs-built_in\">push_back</span>(hash[<span class=\"hljs-built_in\"><span class=\"hljs-keyword\">int</span></span>(s[i])]+<span class=\"hljs-string\">&#x27;0&#x27;</span>);<br>            &#125;<br>        &#125;<br>        index=<span class=\"hljs-number\">0</span>;<br>        <span class=\"hljs-built_in\">memset</span>(hash, <span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(hash));<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i=<span class=\"hljs-number\">0</span>;i&lt;t.<span class=\"hljs-built_in\">size</span>();i++)&#123;<br>            <span class=\"hljs-keyword\">if</span>(hash[<span class=\"hljs-built_in\"><span class=\"hljs-keyword\">int</span></span>(t[i])]==<span class=\"hljs-number\">0</span>)<br>            &#123;<br>                index++;<br>                hash[<span class=\"hljs-built_in\"><span class=\"hljs-keyword\">int</span></span>(t[i])]=index;<br>                st.<span class=\"hljs-built_in\">push_back</span>(index+<span class=\"hljs-string\">&#x27;0&#x27;</span>);<br>            &#125;<span class=\"hljs-keyword\">else</span>&#123;<br>                st.<span class=\"hljs-built_in\">push_back</span>(hash[<span class=\"hljs-built_in\"><span class=\"hljs-keyword\">int</span></span>(t[i])]+<span class=\"hljs-string\">&#x27;0&#x27;</span>);<br>            &#125;<br>        &#125;<br>        <span class=\"hljs-keyword\">int</span> ans = ss.<span class=\"hljs-built_in\">compare</span>(st);<br>        <span class=\"hljs-keyword\">if</span>(ans==<span class=\"hljs-number\">0</span>)&#123;<br>            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>        &#125;<span class=\"hljs-keyword\">else</span>&#123;<br>            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>    &#125;<br>&#125;;<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"参考代码\"><a href=\"#参考代码\" class=\"headerlink\" title=\"参考代码\"></a>参考代码</h2><p><img src=\"/2023/03/02/leetcode205/image-20230302204605581.png\" alt=\"image-20230302204605581\"></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span> &#123;</span><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">bool</span> <span class=\"hljs-title\">isIsomorphic</span><span class=\"hljs-params\">(string s, string t)</span> </span>&#123;<br>        unordered_map&lt;<span class=\"hljs-keyword\">char</span>, <span class=\"hljs-keyword\">char</span>&gt; s2t;<br>        unordered_map&lt;<span class=\"hljs-keyword\">char</span>, <span class=\"hljs-keyword\">char</span>&gt; t2s;<br>        <span class=\"hljs-keyword\">int</span> len = s.<span class=\"hljs-built_in\">length</span>();<br>        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; len; ++i) &#123;<br>            <span class=\"hljs-keyword\">char</span> x = s[i], y = t[i];<br>            <span class=\"hljs-keyword\">if</span> ((s2t.<span class=\"hljs-built_in\">count</span>(x) &amp;&amp; s2t[x] != y) || (t2s.<span class=\"hljs-built_in\">count</span>(y) &amp;&amp; t2s[y] != x)) &#123;<br>                <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">false</span>;<br>            &#125;<br>            s2t[x] = y;<br>            t2s[y] = x;<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">true</span>;<br>    &#125;<br>&#125;;<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><a href=\"https://leetcode.cn/problems/isomorphic-strings/solution/tong-gou-zi-fu-chuan-by-leetcode-solutio-s6fd/\">同构字符串 - 同构字符串 - 力扣（LeetCode）</a></p>\n",
            "tags": [
                "C++",
                "LeetCode",
                "哈希表"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/02/leetcode189/",
            "url": "https://xingyuanjie.top/2023/03/02/leetcode189/",
            "title": "189.轮转数组",
            "date_published": "2023-03-02T12:03:32.000Z",
            "content_html": "<h2 id=\"189-轮转数组\"><a href=\"#189-轮转数组\" class=\"headerlink\" title=\"189.轮转数组\"></a>189.轮转数组</h2><h2 id=\"题目链接\"><a href=\"#题目链接\" class=\"headerlink\" title=\"题目链接\"></a>题目链接</h2><p><a href=\"https://leetcode.cn/problems/rotate-array/\">189. 轮转数组 - 力扣（LeetCode）</a></p>\n<h2 id=\"完整代码\"><a href=\"#完整代码\" class=\"headerlink\" title=\"完整代码\"></a>完整代码</h2><p><img src=\"/2023/03/02/leetcode189/image-20230302200538871.png\" alt=\"image-20230302200538871\"></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span> &#123;</span><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">reverse</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-keyword\">int</span>&gt;&amp; nums,<span class=\"hljs-keyword\">int</span> begin,<span class=\"hljs-keyword\">int</span> end)</span></span><br><span class=\"hljs-function\">    </span>&#123;<br>        <span class=\"hljs-keyword\">while</span>(begin&lt;end)&#123;<br>            <span class=\"hljs-built_in\">swap</span>(nums[begin], nums[end]);<br>            begin++;<br>            end--;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">rotate</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-keyword\">int</span>&gt;&amp; nums, <span class=\"hljs-keyword\">int</span> k)</span> </span>&#123;<br>        <span class=\"hljs-comment\">//数组翻转</span><br>        <span class=\"hljs-keyword\">int</span> p = k%nums.<span class=\"hljs-built_in\">size</span>();<br>        <span class=\"hljs-built_in\">reverse</span>(nums,<span class=\"hljs-number\">0</span>,nums.<span class=\"hljs-built_in\">size</span>()<span class=\"hljs-number\">-1</span>);<br>        <span class=\"hljs-built_in\">reverse</span>(nums,<span class=\"hljs-number\">0</span>,p<span class=\"hljs-number\">-1</span>);<br>        <span class=\"hljs-built_in\">reverse</span>(nums,p,nums.<span class=\"hljs-built_in\">size</span>()<span class=\"hljs-number\">-1</span>);<br>    &#125;<br>&#125;;<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://leetcode.cn/problems/rotate-array/solution/xuan-zhuan-shu-zu-by-leetcode-solution-nipk/\">旋转数组 - 轮转数组 - 力扣（LeetCode）</a></p>\n",
            "tags": [
                "C++",
                "LeetCode",
                "数组翻转"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/01/leetcode724/",
            "url": "https://xingyuanjie.top/2023/03/01/leetcode724/",
            "title": "724.寻找数组的中心下标",
            "date_published": "2023-03-01T09:35:03.000Z",
            "content_html": "<h1 id=\"724-寻找数组的中心下标\"><a href=\"#724-寻找数组的中心下标\" class=\"headerlink\" title=\"724.寻找数组的中心下标\"></a>724.寻找数组的中心下标</h1><h2 id=\"题目链接\"><a href=\"#题目链接\" class=\"headerlink\" title=\"题目链接\"></a>题目链接</h2><p><a href=\"https://leetcode.cn/problems/find-pivot-index/\">724. 寻找数组的中心下标 - 力扣（LeetCode）</a></p>\n<h2 id=\"完整代码\"><a href=\"#完整代码\" class=\"headerlink\" title=\"完整代码\"></a>完整代码</h2><p><img src=\"/2023/03/01/leetcode724/image-20230301173931031.png\" alt=\"image-20230301173931031\"></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span> &#123;</span><br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">pivotIndex</span><span class=\"hljs-params\">(vector&lt;<span class=\"hljs-keyword\">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">int</span> total=<span class=\"hljs-built_in\">accumulate</span>(nums.<span class=\"hljs-built_in\">begin</span>(), nums.<span class=\"hljs-built_in\">end</span>(),<span class=\"hljs-number\">0</span>);\t<span class=\"hljs-comment\">//第三个形参是累加的初始值</span><br>        <span class=\"hljs-keyword\">int</span> sum=<span class=\"hljs-number\">0</span>;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i=<span class=\"hljs-number\">0</span>;i&lt;nums.<span class=\"hljs-built_in\">size</span>();i++)<br>        &#123;<br>            <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-number\">2</span>*sum+nums[i] == total)&#123;<br>                <span class=\"hljs-keyword\">return</span> i;<br>            &#125;<br>            sum+=nums[i];<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">-1</span>;<br>    &#125;<br>&#125;;<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://leetcode.cn/problems/find-pivot-index/solution/xun-zhao-shu-zu-de-zhong-xin-suo-yin-by-gzjle/\">寻找数组的中心索引 - 寻找数组的中心下标 - 力扣（LeetCode）</a></p>\n",
            "tags": [
                "C++",
                "LeetCode",
                "前缀和"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/02/28/vectorbool/",
            "url": "https://xingyuanjie.top/2023/02/28/vectorbool/",
            "title": "vector<bool>与vector<T>",
            "date_published": "2023-02-28T12:59:01.000Z",
            "content_html": "<h1 id=\"vector-lt-bool-gt-与vector-lt-T-gt\"><a href=\"#vector-lt-bool-gt-与vector-lt-T-gt\" class=\"headerlink\" title=\"vector&lt;bool&gt;与vector&lt;T&gt;\"></a>vector&lt;bool&gt;与vector&lt;T&gt;</h1><p>vector&lt;bool&gt; 不像其他容器一样按Byte存储的，它是按bit存储的，也就是说一个正常的bool类型的空间可以存放vector&lt;bool&gt;中的8个，空间上确实优化了很多，然而，c++是不能直接取对bit操作的（因为C++的最小可寻址值通常以byte为单位），对其使用operator[]其实返回的不是bool的引用而是一个”proxy reference”是”std::vector&lt; bool&gt;:reference”类型的对象。</p>\n<p>正因为如此，vector&lt;bool&gt;通过代理对象进行存取访问时需要执行逐位处理，访问通常比int之类的普通类型操作要慢很多。</p>\n<p>因此，对vecotr&lt;bool&gt;的使用需慎重考虑以下几点：<br>(1)是否需要牺牲速度来获取空间上的优化<br>(2)算法中会否有对vecotr地址进行解引用操作的可能。</p>\n<p>如果不满足以上条件，建议使用deque&lt;bool&gt;来取代vector&lt;bool&gt;，功能基本相同，但deque&lt;bool&gt;未对其进行特殊处理。</p>\n<p>下面是vector&lt;bool&gt;与vector&lt;T&gt;简单的对比例子：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>\tvector&lt;<span class=\"hljs-keyword\">char</span>&gt; ch;<br>\tvector&lt;<span class=\"hljs-keyword\">int</span>&gt; in;<br>\tvector&lt;<span class=\"hljs-keyword\">bool</span>&gt; bo;<br> <br>\t<span class=\"hljs-keyword\">int</span> m = <span class=\"hljs-number\">1e6</span>;<br>\t<span class=\"hljs-keyword\">clock_t</span> t1, t2, t3;<br> <br>\tt1 = <span class=\"hljs-built_in\">clock</span>();<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; m; i++)&#123;<br>\t\tch.<span class=\"hljs-built_in\">push_back</span>(<span class=\"hljs-string\">&#x27;0&#x27;</span>);<br>\t&#125;<br>\tt1 = <span class=\"hljs-built_in\">clock</span>() - t1;<br> <br>\tt2 = <span class=\"hljs-built_in\">clock</span>();<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; m; i++)&#123;<br>\t\tin.<span class=\"hljs-built_in\">push_back</span>(<span class=\"hljs-number\">0</span>);<br>\t&#125;<br>\tt2 = <span class=\"hljs-built_in\">clock</span>() - t2;<br> <br>\tt3 = <span class=\"hljs-built_in\">clock</span>();<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; m; i++)&#123;<br>\t\tbo.<span class=\"hljs-built_in\">push_back</span>(<span class=\"hljs-literal\">true</span>);<br>\t&#125;<br>\tt3 = <span class=\"hljs-built_in\">clock</span>() - t3;<br> <br>\tcout &lt;&lt;<span class=\"hljs-string\">&quot;vector&lt;char&gt; &quot;</span>&lt;&lt; t1 &lt;&lt; <span class=\"hljs-string\">&quot;\\n vector&lt;int&gt; &quot;</span> &lt;&lt; t2 &lt;&lt; <span class=\"hljs-string\">&quot;\\nvector&lt;bool&gt; &quot;</span> &lt;&lt; t3 &lt;&lt; endl;<br>\tcout &lt;&lt; endl;<br> <br>\t<span class=\"hljs-built_in\">system</span>(<span class=\"hljs-string\">&quot;pause&quot;</span>);<br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>运行结果：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs cpp\">vector&lt;<span class=\"hljs-keyword\">char</span>&gt; <span class=\"hljs-number\">216</span><br>vextor&lt;<span class=\"hljs-keyword\">int</span>&gt; <span class=\"hljs-number\">229</span><br>vector&lt;<span class=\"hljs-keyword\">bool</span>&gt; <span class=\"hljs-number\">16535</span><br></code></pre></div></td></tr></table></figure>\n\n<p>这里发现vector&lt;bool&gt;相较于其他vector&lt;T&gt;速度要慢的多！</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://blog.csdn.net/qq_52134928/article/details/121066304?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-121066304-blog-86603050.pc_relevant_3mothn_strategy_and_data_recovery&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-121066304-blog-86603050.pc_relevant_3mothn_strategy_and_data_recovery&utm_relevant_index=1\">(65条消息) 【C++】vector＜bool＞的特别之处_小陶同学_的博客-CSDN博客</a></p>\n<p><a href=\"https://blog.csdn.net/u013249689/article/details/25297657\">(65条消息) 不使用vector的原因和替代方法_jackycmu的博客-CSDN博客</a></p>\n",
            "tags": [
                "STL",
                "Vector",
                "C/C++",
                "bool"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/02/28/Linux004/",
            "url": "https://xingyuanjie.top/2023/02/28/Linux004/",
            "title": "C/C++关键字之restrict",
            "date_published": "2023-02-28T11:45:09.000Z",
            "content_html": "<h1 id=\"C-x2F-C-关键字之restrict\"><a href=\"#C-x2F-C-关键字之restrict\" class=\"headerlink\" title=\"C&#x2F;C++关键字之restrict\"></a>C&#x2F;C++关键字之restrict</h1><p>在C语言中，restrict关键字用于修饰指针（C99标准）。通过加上restrict关键字，程序员可提示编译器：在该指针的生命周期内，其指向的对象不会被别的指针所引用。</p>\n<p>需要注意的是，在C++中，并无明确统一的标准支持restrict关键字。但是很多编译器实现了功能相同的关键字，例如gcc和clang中的__restrict关键字。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">add1</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span>*a, <span class=\"hljs-keyword\">int</span>* b)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>    *a = <span class=\"hljs-number\">10</span>;<br>    *b = <span class=\"hljs-number\">12</span>;<br>    <span class=\"hljs-keyword\">return</span> *a + *b;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>add1函数的返回值会永远是10 + 12 &#x3D; 22吗？</p>\n<p>答案是不一定。在指针a和b的地址不同时，返回22没有问题。但是当指针a与b指向的是同一个int对象时，该对象先被赋值为10，后被赋值为12，因此a和b都返回12，因此add1函数最终返回24。</p>\n<p>下面是一个简单的例子：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;bits/stdc++.h&gt;</span></span><br><span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> std;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">add1</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span>* a, <span class=\"hljs-keyword\">int</span>* b)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>    *a = <span class=\"hljs-number\">10</span>;<br>    *b = <span class=\"hljs-number\">12</span>;<br>    <span class=\"hljs-keyword\">return</span> *a + *b;<br>&#125;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span>* c;<br>    <span class=\"hljs-keyword\">int</span>* d;<br>    d=(<span class=\"hljs-keyword\">int</span>*)<span class=\"hljs-built_in\">malloc</span>(<span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">int</span>)*<span class=\"hljs-number\">1</span>);<br>    c=(<span class=\"hljs-keyword\">int</span>*)<span class=\"hljs-built_in\">malloc</span>(<span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">int</span>)*<span class=\"hljs-number\">1</span>);<br>    *c=<span class=\"hljs-number\">10</span>;<br>    *d=<span class=\"hljs-number\">12</span>;<br>    *d=<span class=\"hljs-number\">12</span>;<br>    cout&lt;&lt;<span class=\"hljs-string\">&quot;c:&quot;</span>&lt;&lt;*c&lt;&lt;endl;<br>    cout&lt;&lt;<span class=\"hljs-string\">&quot;d:&quot;</span>&lt;&lt;*d&lt;&lt;endl;<br>    cout&lt;&lt;<span class=\"hljs-string\">&quot;When Pointers a and b have different addresses&quot;</span>&lt;&lt;endl;<br>    cout&lt;&lt;<span class=\"hljs-built_in\">add1</span>(c,d)&lt;&lt;endl;<br>    cout&lt;&lt;<span class=\"hljs-string\">&quot;When Pointers a and b have the same address&quot;</span>&lt;&lt;endl;<br>    cout&lt;&lt;<span class=\"hljs-built_in\">add1</span>(c,c)&lt;&lt;endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>程序输出：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">c:<span class=\"hljs-number\">10</span><br>d:<span class=\"hljs-number\">12</span><br>When Pointers a <span class=\"hljs-keyword\">and</span> b have different addresses<br><span class=\"hljs-number\">22</span><br>When Pointers a <span class=\"hljs-keyword\">and</span> b have the same address<br><span class=\"hljs-number\">24</span><br></code></pre></div></td></tr></table></figure>\n\n<p>开启-O3优化，add1对应的汇编代码如下:</p>\n<p>为了得到<code>*a</code>的值访问了1次内存，而不管在何种条件下(<code>a == b</code> or <code>a != b</code>)，<code>*b</code>的值都是12。因此编译器将<code>*a</code>的值载入<code>eax</code>寄存器后，直接加上立即数12，而无需再访问内存获取<code>*b</code>的值。在无法确定指针a和b是否相同的情况下，编译器只能帮你优化到这里了。</p>\n<figure class=\"highlight fortran\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs fortran\"><span class=\"hljs-number\">0000000000400</span>a10 &lt;_Z4add1PiS_&gt;:<br>  <span class=\"hljs-number\">400</span>a10:   c7 <span class=\"hljs-number\">07</span> <span class=\"hljs-number\">0</span>a <span class=\"hljs-number\">00</span> <span class=\"hljs-number\">00</span> <span class=\"hljs-number\">00</span>       movl   $<span class=\"hljs-number\">0</span>xa,(%rdi) ; *a = <span class=\"hljs-number\">10</span><br>  <span class=\"hljs-number\">400</span>a16:   c7 <span class=\"hljs-number\">06</span> <span class=\"hljs-number\">0</span>c <span class=\"hljs-number\">00</span> <span class=\"hljs-number\">00</span> <span class=\"hljs-number\">00</span>       movl   $<span class=\"hljs-number\">0</span>xc,(%rsi) ; *b = <span class=\"hljs-number\">10</span><br>  <span class=\"hljs-number\">400</span>a1c:   <span class=\"hljs-number\">8</span>b <span class=\"hljs-number\">07</span>                   mov    (%rdi),%eax ; 结果 = *a<br>  <span class=\"hljs-number\">400</span>a1e:   <span class=\"hljs-number\">83</span> c0 <span class=\"hljs-number\">0</span>c                add    $<span class=\"hljs-number\">0</span>xc,%eax   ; 结果 += <span class=\"hljs-number\">12</span> <br>  <span class=\"hljs-number\">400</span>a21:   c3                      retq<br></code></pre></div></td></tr></table></figure>\n\n<p>加上了restrict关键字过后，同样开启-O3优化，add1对应的汇编代码如下：</p>\n<p>加上关键字restrict后，编译器能够确认指针a和b不可能指向同一个内存地址，因此在求*a + *b时，无虚访问内存，因为*a必然等于立即数10，*b必然等于立即数12。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">add2</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span>* __restrict  a, <span class=\"hljs-keyword\">int</span>* __restrict b)</span> </span><br><span class=\"hljs-function\"></span>&#123;<br>    *a = <span class=\"hljs-number\">10</span>;<br>    *b = <span class=\"hljs-number\">12</span>;<br>    <span class=\"hljs-keyword\">return</span> *a + *b ;<br>&#125;<br><span class=\"hljs-number\">0000000000400</span>a30 &lt;_Z4add2PiS_&gt;:<br>  <span class=\"hljs-number\">400</span>a30:   c7 <span class=\"hljs-number\">07</span> <span class=\"hljs-number\">0</span>a <span class=\"hljs-number\">00</span> <span class=\"hljs-number\">00</span> <span class=\"hljs-number\">00</span>       movl   $<span class=\"hljs-number\">0xa</span>,(%rdi) ; *a = <span class=\"hljs-number\">10</span><br>  <span class=\"hljs-number\">400</span>a36:   b8 <span class=\"hljs-number\">16</span> <span class=\"hljs-number\">00</span> <span class=\"hljs-number\">00</span> <span class=\"hljs-number\">00</span>          mov    $<span class=\"hljs-number\">0x16</span>,%eax  ; 结果 = <span class=\"hljs-number\">22</span><br>  <span class=\"hljs-number\">400</span>a3b:   c7 <span class=\"hljs-number\">06</span> <span class=\"hljs-number\">0</span>c <span class=\"hljs-number\">00</span> <span class=\"hljs-number\">00</span> <span class=\"hljs-number\">00</span>       movl   $<span class=\"hljs-number\">0xc</span>,(%rsi) ; *b = <span class=\"hljs-number\">12</span><br>  <span class=\"hljs-number\">400</span>a41:   c3  <br></code></pre></div></td></tr></table></figure>\n\n<p>有无restrict关键字的两种情况下的汇编指令可看到，后者比前者少访问一次内存，且少执行一条指令。就是因为没加restruct关键字时，编译器不能确定别的地方是不是会修改此值，所以会去相应的地址查看。</p>\n<p><strong>这样当我们明确知道两个指针不可能指向同一个地址时，我们就可以通过使用restrict关键字来进行性能优化。</strong></p>\n<p>注意使用restrict的时候，程序员必须确保不会出现<strong>pointer aliasing</strong>，即同一块内存无法通过两个或以上的指针变量名访问。不满足这个条件强行指定restrict，将会出现<strong>underfined behavior</strong>。</p>\n<p>通常编写代码时会忽略pointer aliasing的问题。更常见是在性能分析时，通过反汇编看到很多冗余的读取指令，才会想到加入restrict关键字来提升性能。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://zhuanlan.zhihu.com/p/349726808\">C&#x2F;C++关键字之restrict - 知乎 (zhihu.com)</a></p>\n<p><a href=\"https://github.com/ClickHouse/ClickHouse/pull/19946\">Improve performance of aggregate functions by alexey-milovidov · Pull Request #19946 · ClickHouse&#x2F;ClickHouse (github.com)</a></p>\n<p><a href=\"https://en.cppreference.com/w/c/language/restrict\">restrict type qualifier - cppreference.com</a></p>\n<p><a href=\"https://www.zhihu.com/question/41653775/answer/2535730128\">如何理解C语言关键字restrict？ - 知乎 (zhihu.com)</a></p>\n<p><a href=\"https://blog.csdn.net/qq_41822235/article/details/83479562\">(65条消息) 关键字_restrict___restrict_楚楚可薇的博客-CSDN博客</a></p>\n<p><a href=\"https://blog.csdn.net/qq_41950508/article/details/126619881?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-126619881-blog-102577325.pc_relevant_3mothn_strategy_recovery&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-126619881-blog-102577325.pc_relevant_3mothn_strategy_recovery&utm_relevant_index=1\">(65条消息) 【C++】关键字restrict的作用_restrict关键字的作用_不知所措的渣渣辉的博客-CSDN博客</a></p>\n",
            "tags": [
                "Linux"
            ]
        }
    ]
}