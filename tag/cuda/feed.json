{
    "version": "https://jsonfeed.org/version/1",
    "title": "Amicoyuan • All posts by \"cuda\" tag",
    "description": "",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2023/01/17/cuda005/",
            "url": "http://example.com/2023/01/17/cuda005/",
            "title": "CUDA内存管理",
            "date_published": "2023-01-17T14:03:10.000Z",
            "content_html": "<h3 id=\"1-内存管理\"><a href=\"#1-内存管理\" class=\"headerlink\" title=\"1.内存管理\"></a>1.内存管理</h3><p>CUDA编程模型假设系统是由一个主机和一个设备组成的，而且各自拥有独立的内存。核函数是在设备上运行的。为使你拥有充分的控制权并使系统达到最佳性能，CUDA运行时负责分配与释放设备内存，并且在主机内存和设备内存之间传输数据。表2-1列出了标准的C函数以及相应地针对内存操作的CUDA C函数。</p>\n<p>用于执行GPU内存分配的是cudaMalloc函数，其函数原型为：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">cudaError_t <span class=\"hljs-title\">cudaMalloc</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>** devPtr, <span class=\"hljs-keyword\">size_t</span> size)</span></span><br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/01/17/cuda005/image-20230117223254853.png\" alt=\"image-20230117223254853\"></p>\n<p>该函数负责向设备分配一定字节的线性内存，并以devPtr的形式返回指向所分配内存的指针。cudaMalloc与标准C语言中的malloc函数几乎一样，只是此函数在GPU的内存里分配内存。通过充分保持与标准C语言运行库中的接口一致性，可以实现CUDA应用程序的轻松接入。</p>\n<p>cudaMemcpy函数负责主机和设备之间的数据传输，其函数原型为：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">cudaError_t <span class=\"hljs-title\">cudaMencpy</span><span class=\"hljs-params\">( <span class=\"hljs-keyword\">void</span>* dst, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">void</span>* src, <span class=\"hljs-keyword\">size_t</span> count, cudaMemcpyKind kind)</span></span><br></code></pre></div></td></tr></table></figure>\n\n<p>此函数从src指向的源存储区复制一定数量的字节到dst指向的目标存储区。复制方向由kind指定，其中的kind有以下几种。</p>\n<ol>\n<li>cudaMemcpyHostToHost</li>\n<li>cudaMemcpyHostToDevice</li>\n<li>cudaMemcpyDeviceToHost</li>\n<li>cudaMemcpyDeviceToDevice</li>\n</ol>\n<p>这个函数以同步方式执行，因为在cudaMemcpy函数返回以及传输操作完成之前主机应用程序是阻塞的。除了内核启动之外的CUDA调用都会返回一个错误的枚举类型cudaError_t。如果GPU内存分配成功，函数返回：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">cudaSuccess<br></code></pre></div></td></tr></table></figure>\n\n<p>否则返回：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">cudaErrorMemoryAllocation<br></code></pre></div></td></tr></table></figure>\n\n<p>可以使用以下CUDA运行时函数将错误代码转化为可读的错误消息：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">char</span>* <span class=\"hljs-title\">cudaGetErroeString</span><span class=\"hljs-params\">(cudaError_t error)</span></span><br></code></pre></div></td></tr></table></figure>\n\n<p>cudaGetErrorString函数和C语言中的strerror函数类似。</p>\n<p>CUDA编程模型从GPU架构中抽象出一个内存层次结构，图2-3所示的是一个简化的GPU内存结构，它主要包含两部分：全局内存和共享内存。</p>\n<h3 id=\"2-内存层次结构\"><a href=\"#2-内存层次结构\" class=\"headerlink\" title=\"2.内存层次结构\"></a>2.内存层次结构</h3><p>CUDA编程模型最显著的一个特点就是揭示了内存层次结构。每一个GPU设备都有用于不同用途的存储类型。</p>\n<p>在GPU内存层次结构中，最主要的两种内存是全局内存和共享内存。全局类似于CPU的系统内存，而共享内存类似于CPU的缓存。然而GPU的共享内存可以由CUDA C的内核直接控制。</p>\n<p><img src=\"/2023/01/17/cuda005/image-20230128140743600.png\" alt=\"image-20230128140743600\"></p>\n<p>下面，我们将通过一个简单的两个数组相加的例子来学习如何在主机和设备之间进行数据传输，以及如何使用CUDA C编程。如图2-4所示，数组a的第一个元素与数组b的第一个元素相加，得到的结果作为数组c的第一个元素，重复这个过程直到数组中的所有元素都进行了一次运算。‘</p>\n<p><img src=\"/2023/01/17/cuda005/image-20230128141008674.png\" alt=\"image-20230128141008674\"></p>\n<p>首先，执行主机端代码使两个数组相加（如代码清单2-1所示）。</p>\n<h4 id=\"代码清单2-1-sumArraysOnHost-c\"><a href=\"#代码清单2-1-sumArraysOnHost-c\" class=\"headerlink\" title=\"代码清单2-1 sumArraysOnHost.c\"></a>代码清单2-1 sumArraysOnHost.c</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdlib.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;string.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;time.h&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArraysOnHost</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> N)</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> idx=<span class=\"hljs-number\">0</span>;idx&lt;n;idx++)<br>        C[idx]=A[idx]+B[idx];<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">initialData</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *ip,<span class=\"hljs-keyword\">int</span> size)</span></span>&#123;<br>    <span class=\"hljs-comment\">//generate different seed for random number time_t t;</span><br>    <span class=\"hljs-built_in\">srand</span>((<span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span>) <span class=\"hljs-built_in\">time</span> (&amp;t));<br>    <br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i=<span class=\"hljs-number\">0</span>;i&lt;size;i++)&#123;<br>        ip[i]=(<span class=\"hljs-keyword\">float</span>)(<span class=\"hljs-built_in\">rand</span>() &amp; OxFF)/<span class=\"hljs-number\">10.0f</span>;<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc, <span class=\"hljs-keyword\">char</span> **argv)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> nElem =<span class=\"hljs-number\">1024</span>;<br>    <span class=\"hljs-keyword\">size_t</span> nBytes = nElem *<span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">float</span>);<br>    <br>    <span class=\"hljs-keyword\">float</span> *h_A, *h_B, *h_C;<br>    h_A = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    h_B = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    h_C = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    <br>    <span class=\"hljs-built_in\">initialData</span>(h_A, nElem);<br>    <span class=\"hljs-built_in\">initialData</span>(h_B, nElem);<br>    <br>    <span class=\"hljs-built_in\">sumArraysOnHost</span>(h_A, h_B, h_C, nElem);<br>    <br>    <span class=\"hljs-built_in\">free</span>(h_A);<br>    <span class=\"hljs-built_in\">free</span>(h_B);<br>    <span class=\"hljs-built_in\">free</span>(h_C);<br>    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br><br></code></pre></div></td></tr></table></figure>\n\n<p>这是一个纯C语言编写的程序，你可以用C语言编译器进行编译，也可以像下面这样用nvcc进行编译。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc -Xcompiler -std=c99 sumArraysOnHost.c -o sum<br>./sum<br></code></pre></div></td></tr></table></figure>\n\n<p>nvcc封装了几种内部编译工具，CUDA编译器允许通过命令行选项在不同阶段启动不同的工具完成编译工作。-Xcompiler用于指定命令行选项是指向C编译器还是预处理器。在前面的例子中，将-std&#x3D;c99传递给编译器，因为这里的C程序是按照C99标准编写的。</p>\n<p>现在，你可以在GPU上修改代码来进行数组加法运算，用cudaMalloc在GPU上申请内存。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">float</span> *h_A, *h_B, *h_C;<br><span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_A, nBytes);<br><span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_B, nBytes);<br><span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_C, nBytes);<br></code></pre></div></td></tr></table></figure>\n\n<p>使用cudaMemcpy函数把数据从主机内存拷贝到GPU的全局内存中，参考cudaMemcpyHostToDevice指定数据拷贝方向。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">cudaMemcpy</span>(d_A, h_A, nBytes, cudaMemcpyHostToDevice);<br><span class=\"hljs-built_in\">cudaMemcpy</span>(d_B, h_B, nBytes, cudaMemcpyHostToDevice);<br></code></pre></div></td></tr></table></figure>\n\n<p>当数据被转移到GPU的全局内存后，主机端调用核函数在GPU上进行数组求和。一旦内核被调用，控制权立刻被传回主机，这样的话，当核函数在GPU上运行时，主机可以执行其他函数。因此，内核与主机是异步的。</p>\n<p>当内核在GPU上完成了对所有数组元素的处理后，其结果将以数组d_C的形式存储在GPU的全局内存中，然后用cudaMemcpy函数把结果从GPU复制回到主机的数组gpuRef中。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">cudaMemcpy</span>(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);<br></code></pre></div></td></tr></table></figure>\n\n<p>cudaMemcpy的调用会导致主机运行阻塞。cudaMemcpyDeviceToHost的作用就是将存储在GPU上的数组d_C中的结果复制到gpuRef中。最后，调用cudaFree释放GPU的内存。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">cudaFree</span>(d_A);<br><span class=\"hljs-built_in\">cudaFree</span>(d_B);<br><span class=\"hljs-built_in\">cudaFree</span>(d_C);<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"3-不同的存储空间\"><a href=\"#3-不同的存储空间\" class=\"headerlink\" title=\"3.不同的存储空间\"></a>3.不同的存储空间</h3><p>使用CUDA C进行编程的人最常犯的错误就是对不同内存空间的不恰当引用。对于在GPU上被分配的内存来说，设备指针在主机代码中可能并没有被引用。如果你执行了错误的内存分配，如：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">gpuRef = d_C<br></code></pre></div></td></tr></table></figure>\n\n<p>而不是用：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">cudaMemcpy</span>(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);<br></code></pre></div></td></tr></table></figure>\n\n<p>应用程序在运行时将会崩溃。</p>\n<p>为了避免这类错误，CUDA6.0提出了统一寻址，使用一个指针来访问CPU和GPU的内存</p>\n<h3 id=\"4-参考资料\"><a href=\"#4-参考资料\" class=\"headerlink\" title=\"4.参考资料\"></a>4.参考资料</h3><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "http://example.com/2023/01/17/cuda004/",
            "url": "http://example.com/2023/01/17/cuda004/",
            "title": "CUDA编程结构",
            "date_published": "2023-01-17T13:36:04.000Z",
            "content_html": "<h2 id=\"CUDA编程结构\"><a href=\"#CUDA编程结构\" class=\"headerlink\" title=\"CUDA编程结构\"></a>CUDA编程结构</h2><p>CUDA编程模型使用由C语言扩展生成的注释代码在异构计算系统中执行应用程序。</p>\n<p>在一个异构环境中包含多个CPU和GPU，每个GPU和CPU的内存都由一条PCI-Express总线分隔开。因此，需要注意区别以下内容。</p>\n<ol>\n<li>主机：CPU及其内存（主机内存）</li>\n<li>设备：GPU及其内存（设备内存）</li>\n</ol>\n<p>为了清楚地指明不同的内存空间，在本书的示例代码中，主机内存中的变量名以h__为前缀，设备内存中的变量名以d__为前缀。</p>\n<p>从CUDA6.0开始，NVDIA提出了名为“统一寻址”（Unified Memory）的编程模型的改进，它连接了主机内存和设备内存空间，可使用单个指针访问CPU和GPU内存，无须彼此之间手动拷贝数据。现在，重要的是应学会如何为主机和设备分配内存空间以及如何在CPU和GPU之间拷贝共享数据。这种程序员管理模式控制下的内存和数据可以优化应用程序并实现硬件系统利用率的最大化。</p>\n<p>内核（kernel）是CUDA编程模型的一个重要组成部分，其代码在GPU上运行。作为一个开发人员，你可以串行的执行核函数。在此背景下，CUDA的调度管理程序员在GPU线程上编写核函数。在主机上，基于应用程序数据以及GPU的性能定义如何让设备实现算法功能。这样做的目的是使你专注于算法的逻辑（通过编写串行代码），且在创建和管理大量的GPU线程时不必拘泥于细节。</p>\n<p>多数情况下，主机可以独立地对设备进行操作。内核一旦被启动，端粒权立刻返回给主机，释放CPU来执行由设备上运行的并行代码实现的额外的任务。CUDA编程模型主要是异步的，因此在GPU上进行的运算可以与主机-设备通信重叠。一个典型的CUDA程序包括由并行代码互补的串行代码。如图2-2所示，串行代码（及任务并行代码）在主机CPU上执行，而并行代码在GPU上执行。主机代码按照ANSI C标准进行编写，而设备代码使用CUDA C进行编写。你可以将所有的代码统一放在一个源文件中，也可以使用多个源文件来构建应用程序和库。NVIDIA的C编译器(nvcc)为主机和设备生成可执行代码。</p>\n<p>一个典型的CUDA程序实现流程遵循以下模式</p>\n<ol>\n<li>把数据从CPU内存拷贝到GPU内存</li>\n<li>调用核函数对存储在GPU内存中的数据进行操作</li>\n<li>将数据从GPU内存传送回到CPU内存</li>\n</ol>\n<p>首先，你要学习的是内存管理及主机和设备之间的数据传输。</p>\n<p><img src=\"/2023/01/17/cuda004/image-20230117220146068.png\" alt=\"image-20230117220146068\"></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "http://example.com/2023/01/17/cuda003/",
            "url": "http://example.com/2023/01/17/cuda003/",
            "title": "CUDA编程模型概述",
            "date_published": "2023-01-17T12:29:01.000Z",
            "content_html": "<h2 id=\"CUDA编程模型概述\"><a href=\"#CUDA编程模型概述\" class=\"headerlink\" title=\"CUDA编程模型概述\"></a>CUDA编程模型概述</h2><p>CUDA编程模型提供了一个计算机架构抽象作为应用程序和其可用硬件之间的桥梁。图2-1说明了程序和编程模型实现之间的抽象结构的重要。通信抽象是程序与编程模型实现之间的分界线，它通过专业的硬件原语和操作系统的编译器或库来实现。利用编程模型所编写的程序指定了程序的各组成部分是如何共享信息及相互协作的。编程模型从逻辑上提供了一个特定的计算机架构，通常它体现在编程语言或编程环境中。</p>\n<p><img src=\"/2023/01/17/cuda003/image-20230117203406633.png\" alt=\"image-20230117203406633\"></p>\n<p>除了与其他并行编程模型共有的抽象外，CUDA编程模型还利用GPU架构的计算能力提供了以下几个特有功能。</p>\n<ol>\n<li>一种通过层次结构在GPU中组织线程的方法</li>\n<li>一种通过层次结构在GPU中访问内存的方法</li>\n</ol>\n<p>以程序员的角度可以从以下几个不同的层面来看待并行计算。</p>\n<ol>\n<li>领域层</li>\n<li>逻辑层</li>\n<li>硬件层</li>\n</ol>\n<p>在编程与算法设计的过程中，你最关心的应是在领域层如何解析数据和函数，以便在并行环境中能正确，高效地解决问题。当进入编程阶段，你的关注点应转向如何组织并发线程。在这个阶段，你需要从逻辑层面来思考，以确保你的线程和计算能正确地解决问题。在C语言并行编程中，需要使用pthreads或OpenMP技术来显式地管理线程。CUDA提出了一个线程层次结构抽象的概念，以允许控制线程行为。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "http://example.com/2023/01/16/cuda002/",
            "url": "http://example.com/2023/01/16/cuda002/",
            "title": "CUDA:一种异构计算平台",
            "date_published": "2023-01-16T09:46:48.000Z",
            "content_html": "<h2 id=\"CUDA-一种异构计算平台\"><a href=\"#CUDA-一种异构计算平台\" class=\"headerlink\" title=\"CUDA:一种异构计算平台\"></a>CUDA:一种异构计算平台</h2><h3 id=\"1-CUDA的简单介绍\"><a href=\"#1-CUDA的简单介绍\" class=\"headerlink\" title=\"1.CUDA的简单介绍\"></a>1.CUDA的简单介绍</h3><p>CUDA是一种通用的并行计算平台和编程模型，它利用NVIDIA GPU中的并行计算引擎能够有效地解决复杂的计算问题。通过使用CUDA，你可以像在CPU上，通过GPU来进行计算。</p>\n<p>CUDA平台可以通过CUDA加速库，编译器指令，应用编程接口以及行业标准程序语言的扩展（包括C,C++,Fortran，Python，如图1-12所示）来使用。</p>\n<p>CUDA C是标准ANSI C语言的一个扩展，它带有的少数语言扩展功能使异构编程成为可能，同时也能通过API来管理设备，内存和其他任务。CUDA还是一个可扩展的编程模型，它使程序能对有不同数量核的GPU明显地扩展其并行性，同时对熟悉C编程语言的程序员来说也比较容易上手。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116175503342.png\" alt=\"image-20230116175503342\"></p>\n<p>CUDA提供了两层API来管理GPU设备和组织线程，如图1-13所示。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116175610403.png\" alt=\"image-20230116175610403\"></p>\n<p>-CUDA驱动API</p>\n<p>-CUDA运行时API</p>\n<p>驱动API是一种低级API，它相对来说较难编程，但是它对于在GPU设备使用上提供了更多的控制。运行时API是一个高级API，他在驱动API的上层实现。每个运行时API函数都被分解为更多传给驱动API的基本运算。</p>\n<h3 id=\"2-运行时API与驱动API\"><a href=\"#2-运行时API与驱动API\" class=\"headerlink\" title=\"2.运行时API与驱动API\"></a>2.运行时API与驱动API</h3><p>运行时API和驱动API之间没有明显的性能差异。在设备端，内核是如何使用内存以及你是如何组织线程的，对性能有更显著的影响。</p>\n<p>这两种API是相互排斥的，你必须使用两者之一，从两者中混合函数调用是不可能的。本书中所有例子都使用运行时API。</p>\n<p>一个CUDA程序包含了以下两个部分的混合。</p>\n<p>-在CPU上运行的主机代码</p>\n<p>-在GPU上运行的设备代码</p>\n<p>NVIDIA的CUDA nvcc编译器在编译过程中将设备代码从主机代码中分离出来。如图1-14所示，主机代码是标准的C代码，使用C编译器进行编译。设备代码，也就是核函数，是用扩展的带有标记数据并行函数关键字的CUDA C语言编写的。设备代码通过nvcc进行编译。在链接阶段，在内核程序调用和显示GPU设备操作中添加CUDA运行时库。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116180725596.png\" alt=\"image-20230116180725596\"></p>\n<p>CUDA nvcc编译器是以广泛使用LLVM开源编译系统为基础的。在GPU加速器的支持下，通过使用CUDA编译器SDK，你可以创建或扩展编程语言，如图1-15所示。</p>\n<p>CUDA平台也是支持多样化并行计算生态系统的基础，如图1-26所示。现在，随着越来越多的公司可以提供全球性的工具，服务和解决方案，CUDA生态系统迅速成长。如果你想在GPU上建立你的应用程序，强化GPU性能最简单方式是使用CUDA工具包（cuda-toolkit），它为C和C++开发人员提供了一个综合的开发环境。CUDA工具包包括编译器，数学库，以及调式和优化应用程序性能的工具。同时提供了代码样例，编程指南，用户手册，API参考文档和其他帮助你入门的文档。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116181439404.png\" alt=\"image-20230116181439404\"></p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116181447616.png\" alt=\"image-20230116181447616\"></p>\n<h3 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h3><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "http://example.com/2023/01/16/cuda001/",
            "url": "http://example.com/2023/01/16/cuda001/",
            "title": "CUDA用GPU输出Hello World",
            "date_published": "2023-01-16T08:58:39.000Z",
            "content_html": "<h2 id=\"用GPU输出Hello-World\"><a href=\"#用GPU输出Hello-World\" class=\"headerlink\" title=\"用GPU输出Hello World\"></a>用GPU输出Hello World</h2><h3 id=\"1-检查环境\"><a href=\"#1-检查环境\" class=\"headerlink\" title=\"1.检查环境\"></a>1.检查环境</h3><p>学习一个新编程语言的最好方式就是使用这种语言来编写程序。在本节，你将开始编写在GPU上运行的第一个内核代码。像其他任何编程语言一样编写GPU上的第一个程序是输出字符串“Hello World”。</p>\n<p>如果这是你第一次使用CUDA,在Linux系统中，你可以想使用以下命令来检查CUDA编译器是否正确安装：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">which nvcc<br></code></pre></div></td></tr></table></figure>\n\n<p>通常的结果可能是</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">/usr/local/cuda/bin/nvcc<br></code></pre></div></td></tr></table></figure>\n\n<p>你还需要检查你的机器上是否安装了GPU加速卡。对吃你可以在Linux系统上使用以下命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">ls -l /dev/nv*<br></code></pre></div></td></tr></table></figure>\n\n<p>通常的结果是：</p>\n<p><img src=\"/2023/01/16/cuda001/image-20230116170920773.png\" alt=\"image-20230116170920773\"></p>\n<p>在这个例子中，你发现了两个GPU卡（不同的用户配置可能有所不同，因此显示结果会有所差异）。</p>\n<h3 id=\"2-第一个CUDA-C程序\"><a href=\"#2-第一个CUDA-C程序\" class=\"headerlink\" title=\"2.第一个CUDA C程序\"></a>2.第一个CUDA C程序</h3><p>现在你要准备好写你的第一个CUDA C程序。写一个CUDA C程序，你需要以下几个步骤：</p>\n<ol>\n<li>用专用扩展名.cu来创建一个源文件。</li>\n<li>使用CUDA nvcc编译器来编译程序。</li>\n<li>从命令行运行可执行文件，这个文件有可在GPU上运行的内核代码。</li>\n</ol>\n<p>首先，我们编写一个C语言程序来输出“Hello World”,如下所示：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from CPU!\\n&quot;</span>);<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>把代码保存到hello.cu中，然后使用nvcc编译器来编译。CUDA nvcc编译器和gcc编译器及其他编译器有相似的语义</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc hello.cu -o hello<br></code></pre></div></td></tr></table></figure>\n\n<p>如果你运行可执行文件hello，将会输出：</p>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs angelscript\">Hello World <span class=\"hljs-keyword\">from</span> CPU!<br></code></pre></div></td></tr></table></figure>\n\n<p>接下来，编写一个内核函数，命名为helloFromGPU，用它来输出字符串“Hello World from GPU!”。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">helloFromGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from GPU!\\n&quot;</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>修饰符__global__告诉编译器这个函数将会从CPU中调用，然后在GPU上执行。用下面代码启用内核函数。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">helloFromGPU&lt;&lt;&lt;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">10</span>&gt;&gt;&gt;();<br></code></pre></div></td></tr></table></figure>\n\n<p>三重尖括号意味着从主线程到设备端代码的调用。一个内核函数通过一组线程来执行，所有线程执行相同的代码。三重尖括号里面的参数是执行配置，用来说明使用多少线程来执行内核函数。在这个例子中，有10个GPU线程被调用。综上所述，得到代码清单1-1所示的程序。</p>\n<h3 id=\"3-代码清单1-1Hello-World-from-GPU-hello-cu\"><a href=\"#3-代码清单1-1Hello-World-from-GPU-hello-cu\" class=\"headerlink\" title=\"3.代码清单1-1Hello World from GPU! (hello.cu)\"></a>3.代码清单1-1Hello World from GPU! (hello.cu)</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">helloFromGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from GPU!\\n&quot;</span>);<br>&#125;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-comment\">//hello from cpu</span><br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from CPU!\\n&quot;</span>);<br>    <br>    <br>    helloFromGPU&lt;&lt;&lt;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">10</span>&gt;&gt;&gt;();<br>    <span class=\"hljs-built_in\">cudaDeviceReset</span>();<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>函数cudaDeviceRest（）用来显式地释放和清空当前进程中与当前设别有关的所有资源。如下所示，在nvcc命令行中使用-arch sm_20进行编译：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc -arch sm_20 hello.cu -o hello<br></code></pre></div></td></tr></table></figure>\n\n<p>开关语句-arch sm_20使编译器为Fermi架构生成设备代码。运行这个可执行文件，它将输出10条字符串“Hello World from CPU!”，每个线程输出一条。</p>\n<p><img src=\"/2023/01/16/cuda001/image-20230116173446169.png\" alt=\"image-20230116173446169\"></p>\n<h3 id=\"4-一个典型的CUDA编程结构包括5个主要步骤\"><a href=\"#4-一个典型的CUDA编程结构包括5个主要步骤\" class=\"headerlink\" title=\"4.一个典型的CUDA编程结构包括5个主要步骤\"></a>4.一个典型的CUDA编程结构包括5个主要步骤</h3><ol>\n<li>分配GPU内存</li>\n<li>从CPU内存中拷贝数据到GPU内存</li>\n<li>调用CUDA内核函数来完成程序指定的运算</li>\n<li>将数据从GPU拷回CPU内存</li>\n<li>释放GPU内存空间</li>\n</ol>\n<p>在hello.cu中，你只看到了第三步：调用内核。</p>\n<h3 id=\"5-参考资料\"><a href=\"#5-参考资料\" class=\"headerlink\" title=\"5.参考资料\"></a>5.参考资料</h3><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        }
    ]
}