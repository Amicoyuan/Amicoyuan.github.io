{
    "version": "https://jsonfeed.org/version/1",
    "title": "Amicoyuan • All posts by \"cuda\" tag",
    "description": "",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2023/01/17/cuda004/",
            "url": "http://example.com/2023/01/17/cuda004/",
            "title": "CUDA编程结构",
            "date_published": "2023-01-17T13:36:04.000Z",
            "content_html": "<h2 id=\"CUDA编程结构\"><a href=\"#CUDA编程结构\" class=\"headerlink\" title=\"CUDA编程结构\"></a>CUDA编程结构</h2><p>CUDA编程模型使用由C语言扩展生成的注释代码在异构计算系统中执行应用程序。</p>\n<p>在一个异构环境中包含多个CPU和GPU，每个GPU和CPU的内存都由一条PCI-Express总线分隔开。因此，需要注意区别以下内容。</p>\n<ol>\n<li>主机：CPU及其内存（主机内存）</li>\n<li>设备：GPU及其内存（设备内存）</li>\n</ol>\n<p>为了清楚地指明不同的内存空间，在本书的示例代码中，主机内存中的变量名以h__为前缀，设备内存中的变量名以d__为前缀。</p>\n<p>从CUDA6.0开始，NVDIA提出了名为“统一寻址”（Unified Memory）的编程模型的改进，它连接了主机内存和设备内存空间，可使用单个指针访问CPU和GPU内存，无须彼此之间手动拷贝数据。现在，重要的是应学会如何为主机和设备分配内存空间以及如何在CPU和GPU之间拷贝共享数据。这种程序员管理模式控制下的内存和数据可以优化应用程序并实现硬件系统利用率的最大化。</p>\n<p>内核（kernel）是CUDA编程模型的一个重要组成部分，其代码在GPU上运行。作为一个开发人员，你可以串行的执行核函数。在此背景下，CUDA的调度管理程序员在GPU线程上编写核函数。在主机上，基于应用程序数据以及GPU的性能定义如何让设备实现算法功能。这样做的目的是使你专注于算法的逻辑（通过编写串行代码），且在创建和管理大量的GPU线程时不必拘泥于细节。</p>\n<p>多数情况下，主机可以独立地对设备进行操作。内核一旦被启动，端粒权立刻返回给主机，释放CPU来执行由设备上运行的并行代码实现的额外的任务。CUDA编程模型主要是异步的，因此在GPU上进行的运算可以与主机-设备通信重叠。一个典型的CUDA程序包括由并行代码互补的串行代码。如图2-2所示，串行代码（及任务并行代码）在主机CPU上执行，而并行代码在GPU上执行。主机代码按照ANSI C标准进行编写，而设备代码使用CUDA C进行编写。你可以将所有的代码统一放在一个源文件中，也可以使用多个源文件来构建应用程序和库。NVIDIA的C编译器(nvcc)为主机和设备生成可执行代码。</p>\n<p>一个典型的CUDA程序实现流程遵循以下模式</p>\n<ol>\n<li>把数据从CPU内存拷贝到GPU内存</li>\n<li>调用核函数对存储在GPU内存中的数据进行操作</li>\n<li>将数据从GPU内存传送回到CPU内存</li>\n</ol>\n<p>首先，你要学习的是内存管理及主机和设备之间的数据传输。</p>\n<p><img src=\"/2023/01/17/cuda004/image-20230117220146068.png\" alt=\"image-20230117220146068\"></p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "http://example.com/2023/01/17/cuda003/",
            "url": "http://example.com/2023/01/17/cuda003/",
            "title": "CUDA编程模型概述",
            "date_published": "2023-01-17T12:29:01.000Z",
            "content_html": "<h2 id=\"CUDA编程模型概述\"><a href=\"#CUDA编程模型概述\" class=\"headerlink\" title=\"CUDA编程模型概述\"></a>CUDA编程模型概述</h2><p>CUDA编程模型提供了一个计算机架构抽象作为应用程序和其可用硬件之间的桥梁。图2-1说明了程序和编程模型实现之间的抽象结构的重要。通信抽象是程序与编程模型实现之间的分界线，它通过专业的硬件原语和操作系统的编译器或库来实现。利用编程模型所编写的程序指定了程序的各组成部分是如何共享信息及相互协作的。编程模型从逻辑上提供了一个特定的计算机架构，通常它体现在编程语言或编程环境中。</p>\n<p><img src=\"/2023/01/17/cuda003/image-20230117203406633.png\" alt=\"image-20230117203406633\"></p>\n<p>除了与其他并行编程模型共有的抽象外，CUDA编程模型还利用GPU架构的计算能力提供了以下几个特有功能。</p>\n<ol>\n<li>一种通过层次结构在GPU中组织线程的方法</li>\n<li>一种通过层次结构在GPU中访问内存的方法</li>\n</ol>\n<p>以程序员的角度可以从以下几个不同的层面来看待并行计算。</p>\n<ol>\n<li>领域层</li>\n<li>逻辑层</li>\n<li>硬件层</li>\n</ol>\n<p>在编程与算法设计的过程中，你最关心的应是在领域层如何解析数据和函数，以便在并行环境中能正确，高效地解决问题。当进入编程阶段，你的关注点应转向如何组织并发线程。在这个阶段，你需要从逻辑层面来思考，以确保你的线程和计算能正确地解决问题。在C语言并行编程中，需要使用pthreads或OpenMP技术来显式地管理线程。CUDA提出了一个线程层次结构抽象的概念，以允许控制线程行为。</p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "http://example.com/2023/01/16/cuda002/",
            "url": "http://example.com/2023/01/16/cuda002/",
            "title": "CUDA:一种异构计算平台",
            "date_published": "2023-01-16T09:46:48.000Z",
            "content_html": "<h2 id=\"CUDA-一种异构计算平台\"><a href=\"#CUDA-一种异构计算平台\" class=\"headerlink\" title=\"CUDA:一种异构计算平台\"></a>CUDA:一种异构计算平台</h2><h3 id=\"1-CUDA的简单介绍\"><a href=\"#1-CUDA的简单介绍\" class=\"headerlink\" title=\"1.CUDA的简单介绍\"></a>1.CUDA的简单介绍</h3><p>CUDA是一种通用的并行计算平台和编程模型，它利用NVIDIA GPU中的并行计算引擎能够有效地解决复杂的计算问题。通过使用CUDA，你可以像在CPU上，通过GPU来进行计算。</p>\n<p>CUDA平台可以通过CUDA加速库，编译器指令，应用编程接口以及行业标准程序语言的扩展（包括C,C++,Fortran，Python，如图1-12所示）来使用。</p>\n<p>CUDA C是标准ANSI C语言的一个扩展，它带有的少数语言扩展功能使异构编程成为可能，同时也能通过API来管理设备，内存和其他任务。CUDA还是一个可扩展的编程模型，它使程序能对有不同数量核的GPU明显地扩展其并行性，同时对熟悉C编程语言的程序员来说也比较容易上手。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116175503342.png\" alt=\"image-20230116175503342\"></p>\n<p>CUDA提供了两层API来管理GPU设备和组织线程，如图1-13所示。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116175610403.png\" alt=\"image-20230116175610403\"></p>\n<p>-CUDA驱动API</p>\n<p>-CUDA运行时API</p>\n<p>驱动API是一种低级API，它相对来说较难编程，但是它对于在GPU设备使用上提供了更多的控制。运行时API是一个高级API，他在驱动API的上层实现。每个运行时API函数都被分解为更多传给驱动API的基本运算。</p>\n<h3 id=\"2-运行时API与驱动API\"><a href=\"#2-运行时API与驱动API\" class=\"headerlink\" title=\"2.运行时API与驱动API\"></a>2.运行时API与驱动API</h3><p>运行时API和驱动API之间没有明显的性能差异。在设备端，内核是如何使用内存以及你是如何组织线程的，对性能有更显著的影响。</p>\n<p>这两种API是相互排斥的，你必须使用两者之一，从两者中混合函数调用是不可能的。本书中所有例子都使用运行时API。</p>\n<p>一个CUDA程序包含了以下两个部分的混合。</p>\n<p>-在CPU上运行的主机代码</p>\n<p>-在GPU上运行的设备代码</p>\n<p>NVIDIA的CUDA nvcc编译器在编译过程中将设备代码从主机代码中分离出来。如图1-14所示，主机代码是标准的C代码，使用C编译器进行编译。设备代码，也就是核函数，是用扩展的带有标记数据并行函数关键字的CUDA C语言编写的。设备代码通过nvcc进行编译。在链接阶段，在内核程序调用和显示GPU设备操作中添加CUDA运行时库。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116180725596.png\" alt=\"image-20230116180725596\"></p>\n<p>CUDA nvcc编译器是以广泛使用LLVM开源编译系统为基础的。在GPU加速器的支持下，通过使用CUDA编译器SDK，你可以创建或扩展编程语言，如图1-15所示。</p>\n<p>CUDA平台也是支持多样化并行计算生态系统的基础，如图1-26所示。现在，随着越来越多的公司可以提供全球性的工具，服务和解决方案，CUDA生态系统迅速成长。如果你想在GPU上建立你的应用程序，强化GPU性能最简单方式是使用CUDA工具包（cuda-toolkit），它为C和C++开发人员提供了一个综合的开发环境。CUDA工具包包括编译器，数学库，以及调式和优化应用程序性能的工具。同时提供了代码样例，编程指南，用户手册，API参考文档和其他帮助你入门的文档。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116181439404.png\" alt=\"image-20230116181439404\"></p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116181447616.png\" alt=\"image-20230116181447616\"></p>\n<h3 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h3><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "http://example.com/2023/01/16/cuda001/",
            "url": "http://example.com/2023/01/16/cuda001/",
            "title": "CUDA用GPU输出Hello World",
            "date_published": "2023-01-16T08:58:39.000Z",
            "content_html": "<h2 id=\"用GPU输出Hello-World\"><a href=\"#用GPU输出Hello-World\" class=\"headerlink\" title=\"用GPU输出Hello World\"></a>用GPU输出Hello World</h2><h3 id=\"1-检查环境\"><a href=\"#1-检查环境\" class=\"headerlink\" title=\"1.检查环境\"></a>1.检查环境</h3><p>学习一个新编程语言的最好方式就是使用这种语言来编写程序。在本节，你将开始编写在GPU上运行的第一个内核代码。像其他任何编程语言一样编写GPU上的第一个程序是输出字符串“Hello World”。</p>\n<p>如果这是你第一次使用CUDA,在Linux系统中，你可以想使用以下命令来检查CUDA编译器是否正确安装：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">which nvcc<br></code></pre></div></td></tr></table></figure>\n\n<p>通常的结果可能是</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">/usr/local/cuda/bin/nvcc<br></code></pre></div></td></tr></table></figure>\n\n<p>你还需要检查你的机器上是否安装了GPU加速卡。对吃你可以在Linux系统上使用以下命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">ls -l /dev/nv*<br></code></pre></div></td></tr></table></figure>\n\n<p>通常的结果是：</p>\n<p><img src=\"/2023/01/16/cuda001/image-20230116170920773.png\" alt=\"image-20230116170920773\"></p>\n<p>在这个例子中，你发现了两个GPU卡（不同的用户配置可能有所不同，因此显示结果会有所差异）。</p>\n<h3 id=\"2-第一个CUDA-C程序\"><a href=\"#2-第一个CUDA-C程序\" class=\"headerlink\" title=\"2.第一个CUDA C程序\"></a>2.第一个CUDA C程序</h3><p>现在你要准备好写你的第一个CUDA C程序。写一个CUDA C程序，你需要以下几个步骤：</p>\n<ol>\n<li>用专用扩展名.cu来创建一个源文件。</li>\n<li>使用CUDA nvcc编译器来编译程序。</li>\n<li>从命令行运行可执行文件，这个文件有可在GPU上运行的内核代码。</li>\n</ol>\n<p>首先，我们编写一个C语言程序来输出“Hello World”,如下所示：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from CPU!\\n&quot;</span>);<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>把代码保存到hello.cu中，然后使用nvcc编译器来编译。CUDA nvcc编译器和gcc编译器及其他编译器有相似的语义</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc hello.cu -o hello<br></code></pre></div></td></tr></table></figure>\n\n<p>如果你运行可执行文件hello，将会输出：</p>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs angelscript\">Hello World <span class=\"hljs-keyword\">from</span> CPU!<br></code></pre></div></td></tr></table></figure>\n\n<p>接下来，编写一个内核函数，命名为helloFromGPU，用它来输出字符串“Hello World from GPU!”。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">helloFromGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from GPU!\\n&quot;</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>修饰符__global__告诉编译器这个函数将会从CPU中调用，然后在GPU上执行。用下面代码启用内核函数。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">helloFromGPU&lt;&lt;&lt;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">10</span>&gt;&gt;&gt;();<br></code></pre></div></td></tr></table></figure>\n\n<p>三重尖括号意味着从主线程到设备端代码的调用。一个内核函数通过一组线程来执行，所有线程执行相同的代码。三重尖括号里面的参数是执行配置，用来说明使用多少线程来执行内核函数。在这个例子中，有10个GPU线程被调用。综上所述，得到代码清单1-1所示的程序。</p>\n<h3 id=\"3-代码清单1-1Hello-World-from-GPU-hello-cu\"><a href=\"#3-代码清单1-1Hello-World-from-GPU-hello-cu\" class=\"headerlink\" title=\"3.代码清单1-1Hello World from GPU! (hello.cu)\"></a>3.代码清单1-1Hello World from GPU! (hello.cu)</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">helloFromGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from GPU!\\n&quot;</span>);<br>&#125;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-comment\">//hello from cpu</span><br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from CPU!\\n&quot;</span>);<br>    <br>    <br>    helloFromGPU&lt;&lt;&lt;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">10</span>&gt;&gt;&gt;();<br>    <span class=\"hljs-built_in\">cudaDeviceReset</span>();<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>函数cudaDeviceRest（）用来显式地释放和清空当前进程中与当前设别有关的所有资源。如下所示，在nvcc命令行中使用-arch sm_20进行编译：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc -arch sm_20 hello.cu -o hello<br></code></pre></div></td></tr></table></figure>\n\n<p>开关语句-arch sm_20使编译器为Fermi架构生成设备代码。运行这个可执行文件，它将输出10条字符串“Hello World from CPU!”，每个线程输出一条。</p>\n<p><img src=\"/2023/01/16/cuda001/image-20230116173446169.png\" alt=\"image-20230116173446169\"></p>\n<h3 id=\"4-一个典型的CUDA编程结构包括5个主要步骤\"><a href=\"#4-一个典型的CUDA编程结构包括5个主要步骤\" class=\"headerlink\" title=\"4.一个典型的CUDA编程结构包括5个主要步骤\"></a>4.一个典型的CUDA编程结构包括5个主要步骤</h3><ol>\n<li>分配GPU内存</li>\n<li>从CPU内存中拷贝数据到GPU内存</li>\n<li>调用CUDA内核函数来完成程序指定的运算</li>\n<li>将数据从GPU拷回CPU内存</li>\n<li>释放GPU内存空间</li>\n</ol>\n<p>在hello.cu中，你只看到了第三步：调用内核。</p>\n<h3 id=\"5-参考资料\"><a href=\"#5-参考资料\" class=\"headerlink\" title=\"5.参考资料\"></a>5.参考资料</h3><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        }
    ]
}