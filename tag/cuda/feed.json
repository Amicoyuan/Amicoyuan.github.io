{
    "version": "https://jsonfeed.org/version/1",
    "title": "Amicoyuan • All posts by \"cuda\" tag",
    "description": "",
    "home_page_url": "https://xingyuanjie.top",
    "items": [
        {
            "id": "https://xingyuanjie.top/2023/03/09/cuda015/",
            "url": "https://xingyuanjie.top/2023/03/09/cuda015/",
            "title": "CUDA使用二维网格和二位块对矩阵求和",
            "date_published": "2023-03-09T04:34:51.000Z",
            "content_html": "<h2 id=\"CUDA使用二维网格和二位块对矩阵求和\"><a href=\"#CUDA使用二维网格和二位块对矩阵求和\" class=\"headerlink\" title=\"CUDA使用二维网格和二位块对矩阵求和\"></a>CUDA使用二维网格和二位块对矩阵求和</h2><p>在本节中，我们将使用一个二维网格和二位块来编写一个矩阵加法核函数。首先，应该编写一个校验主函数以验证矩阵加法核函数是否能得出正确的结果：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumMatrixOnhost</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> nx, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> ny)</span></span>&#123;<br>    <span class=\"hljs-keyword\">float</span> *ia = A;<br>    <span class=\"hljs-keyword\">float</span> *ib = B;<br>    <span class=\"hljs-keyword\">float</span> *ic = C;<br>    <br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> iy=<span class=\"hljs-number\">0</span>;iy&lt;ny;iy++)&#123;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> ix=<span class=\"hljs-number\">0</span>;ix&lt;nx;ix++)&#123;<br>            ic[ix]=ia[ix]+ib[ix];<br>        &#125;<br>        ia += nx;<br>        ib += nx;<br>        ic += nx;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>然后，创建一个新的核函数，目的是采用一个二维线程块来进行矩阵求和：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumMatrixOnGPU2D</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *MatA, <span class=\"hljs-keyword\">float</span> *MatB, <span class=\"hljs-keyword\">float</span> *MatC, <span class=\"hljs-keyword\">int</span> nx, <span class=\"hljs-keyword\">int</span> ny)</span></span>&#123;<br>    <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span> ix = threadIdx.x + blockIdx.x * blockDim.x;<br>    <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span> iy = threadIdx.y + blockIdx.y * blockDim.y;<br>    ubsigned <span class=\"hljs-keyword\">int</span> idx = iy*nx + ix;<br>    <br>    <span class=\"hljs-keyword\">if</span>(ix &lt; nx &amp;&amp; iy &lt;ny)<br>        MatC[idx] = MatA[idx] + MatB[idx];<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>这个核函数的关键步骤是将每个线程从它的线程索引映射到全局线性内存索引中，如图2-12所示。</p>\n<p>接下来，每个维度下的矩阵大小可以按如下方法设置为16384个元素：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">int</span> nx = <span class=\"hljs-number\">1</span>&lt;&lt;<span class=\"hljs-number\">14</span>;<br><span class=\"hljs-keyword\">int</span> ny = <span class=\"hljs-number\">1</span>&lt;&lt;<span class=\"hljs-number\">14</span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>然后，使用一个二维网格和二维块按如下方法设置核函数的执行配置：</p>\n<p><img src=\"/2023/03/09/cuda015/image-20230309125059653.png\" alt=\"image-20230309125059653\"></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">int</span> dimx = <span class=\"hljs-number\">32</span>;<br><span class=\"hljs-keyword\">int</span> dimy = <span class=\"hljs-number\">32</span>;<br><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(dimx, dimy)</span></span>;<br><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">((nx + block.x - <span class=\"hljs-number\">1</span>)/block.x, (ny + block.y - <span class=\"hljs-number\">1</span>)/block.y)</span></span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>把所有的代码整合到名为sumMatrixOnGPU-2D-grid-2D-block.cu的文件中。主函数代码如代码清单2-7所示。</p>\n<p>代码清单2-7 使用一个二维网格和二维块的矩阵加法(sumMatrixOnGPU-2D-grid-2D-block.cu)</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc, <span class=\"hljs-keyword\">char</span> **argv)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%s Starting...\\n&quot;</span>,zrgv[<span class=\"hljs-number\">0</span>]);<br>    <br>    <span class=\"hljs-comment\">//set up device</span><br>    <span class=\"hljs-keyword\">int</span> dev = <span class=\"hljs-number\">0</span>;<br>    cudaDeviceProp deviceProp;<br>    <span class=\"hljs-built_in\">CHECK</span>(<span class=\"hljs-built_in\">cudaGetDeviceProperties</span>(&amp;deviceProp, dev));<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Using Device %d: %s\\n&quot;</span>,dev, deviceProp.name);<br>    <span class=\"hljs-built_in\">CHECK</span>(<span class=\"hljs-built_in\">cudaSetDevice</span>(dev));<br>    <br>    <span class=\"hljs-comment\">//set up data size of matrix</span><br>    <span class=\"hljs-keyword\">int</span> nx = <span class=\"hljs-number\">1</span>&lt;&lt;<span class=\"hljs-number\">14</span>;<br>    <span class=\"hljs-keyword\">int</span> ny = <span class=\"hljs-number\">1</span>&lt;&lt;<span class=\"hljs-number\">14</span>;<br>    <br>    <span class=\"hljs-keyword\">int</span> nxy = nx*ny;<br>    <span class=\"hljs-keyword\">int</span> nBytes = nxy *<span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">float</span>);<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Matrix size: nx %d ny %d\\n&quot;</span>,nx,ny);<br>    <br>    <span class=\"hljs-comment\">//malloc host memory</span><br>    <span class=\"hljs-keyword\">float</span> *h_A, *h_B, *hostRef, *gpuRef;<br>    h_A = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    h_B = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    hostRef = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    gpuRef = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    <br>    <span class=\"hljs-comment\">//initialize data at host side</span><br>    <span class=\"hljs-keyword\">double</span> iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>    <span class=\"hljs-built_in\">initialData</span> (h_A, nxy);<br>    <span class=\"hljs-built_in\">initialData</span> (h_B, nxy);<br>    <span class=\"hljs-keyword\">double</span> iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br>    <br>    <span class=\"hljs-built_in\">memset</span>(hostRef, <span class=\"hljs-number\">0</span>, nBytes);<br>    <span class=\"hljs-built_in\">memset</span>(gpuRef, <span class=\"hljs-number\">0</span>, nBytes);<br>    <br>    <span class=\"hljs-comment\">//add matrix at host side for result checks</span><br>    iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>    <span class=\"hljs-built_in\">sumMatrixOnHost</span> (h_A, h_B, hostRef, nx,ny);<br>    iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br>    <br>    <span class=\"hljs-comment\">//malloc device global memory</span><br>    <span class=\"hljs-keyword\">float</span> *d_MatA, *d_MatB, *d_MatC;<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">void</span> **)&amp;d_MatA,nBytes);<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">void</span> **)&amp;d_MatB,nBytes);<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">void</span> **)&amp;d_MatC,nBytes);<br>    <br>    <span class=\"hljs-comment\">//transfer data from host to device</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_MatA, h_A, nBytes, cudaMemcpyHostToDevice);<br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_MatB, h_B, nBytes, cudaMemcpyHostToDevice);<br>    <br>    <span class=\"hljs-comment\">//invoke kernel at host side</span><br>    <span class=\"hljs-keyword\">int</span> dimx = <span class=\"hljs-number\">32</span>;<br>    <span class=\"hljs-keyword\">int</span> dimy = <span class=\"hljs-number\">32</span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(dimx,dimy)</span></span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">((nx+block.x<span class=\"hljs-number\">-1</span>)/block.x,(ny+block.y<span class=\"hljs-number\">-1</span>)/block.y)</span></span>;<br>    <br>    iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>    sumMatrixOnGPU2D&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_MatA, d_MatB, d_MatC, nx,ny);<br>    <span class=\"hljs-built_in\">cudaDeviceSynchronize</span>();<br>    iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;sumMatrixOnGPU2D&lt;&lt;&lt;(%d,%d),(%d,%d)&gt;&gt;&gt; elapsed %f sec\\n&quot;</span>,grid.x, grid.y, block.x,block.y,iElaps);<br>    <br>    <span class=\"hljs-comment\">//copy kernel result back to host side</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(gpuRef, d_MatC, nBytes, cudaMemcpyDeviceToHost);<br>    <br>    <span class=\"hljs-comment\">//check device results</span><br>    <span class=\"hljs-built_in\">checkResult</span>(hostRef, gpuRef,nxy);<br>    <br>    <span class=\"hljs-comment\">//free device global memory</span><br>    <span class=\"hljs-built_in\">cudaFree</span>(d_MatA);<br>    <span class=\"hljs-built_in\">cudaFree</span>(d_MatB);<br>    <span class=\"hljs-built_in\">cudaFree</span>(d_MatC);<br>    <br>    <span class=\"hljs-comment\">//free host memory</span><br>    <span class=\"hljs-built_in\">free</span>(h_A);<br>    <span class=\"hljs-built_in\">free</span>(h_B);<br>    <span class=\"hljs-built_in\">free</span>(hostRef);<br>    <span class=\"hljs-built_in\">free</span>(gpuRef);<br>    <br>    <span class=\"hljs-comment\">//reset device</span><br>    <span class=\"hljs-built_in\">cudaDeviceReset</span>();<br>    <br>    <span class=\"hljs-keyword\">return</span> (<span class=\"hljs-number\">0</span>);<br>&#125; <br></code></pre></div></td></tr></table></figure>\n\n<p>用以下命令编译并运行该代码：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc -arch=sm_20 sumMatrixOnGPU-2D-grid-2D-block.cu -o matrix2D<br>./matrix2D<br></code></pre></div></td></tr></table></figure>\n\n<p>在Tesla M2070上运行的结果：</p>\n<p><img src=\"/2023/03/09/cuda015/image-20230309224513603.png\" alt=\"image-20230309224513603\"></p>\n<p>接下来，调整块的尺寸为32×16并重新编译和运行该代码。核函数的执行速度几乎快了两倍：</p>\n<p><img src=\"/2023/03/09/cuda015/image-20230309224626772.png\" alt=\"image-20230309224626772\"></p>\n<p>你可能好奇为什么只是改变了执行配置，内核性能就几乎翻了一倍。直观地说，你可能会觉得这是因为第二次配置的线程块数是第一次配置块数的两倍，所以并行性也是两倍。你的直觉是正确的，但是，如果进一步减小块的大小变为16×16，相比第一次配置你已经将块的数量翻了四倍。如下所示，这种配置比第一个结果好但是不如第二个。</p>\n<p><img src=\"/2023/03/09/cuda015/image-20230309224912499.png\" alt=\"image-20230309224912499\"></p>\n<p>表2-3总结了不同执行配置的性能。结果显示，增加块的数量不一定能提升内核性能。</p>\n<p><img src=\"/2023/03/09/cuda015/image-20230309225004531.png\" alt=\"image-20230309225004531\"></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/09/cuda014/",
            "url": "https://xingyuanjie.top/2023/03/09/cuda014/",
            "title": "CUDA使用块和线程建立矩阵索引",
            "date_published": "2023-03-09T03:32:36.000Z",
            "content_html": "<h2 id=\"CUDA使用块和线程建立矩阵索引\"><a href=\"#CUDA使用块和线程建立矩阵索引\" class=\"headerlink\" title=\"CUDA使用块和线程建立矩阵索引\"></a>CUDA使用块和线程建立矩阵索引</h2><p>通常情况下，一个矩阵用行优先的方法在全局内存中进行线性存储。图2-9所示的是一个8×6矩阵的小例子。</p>\n<p>在一个矩阵加法核函数中，一个线程通常被分配一个数据元素来处理。首先要完成的任务是使用块和线程索引从全局内存中访问指定的数据。通常情况下，对一个二维示例来说，需要管理3种索引。</p>\n<p><img src=\"/2023/03/09/cuda014/image-20230309113733674.png\" alt=\"image-20230309113733674\"></p>\n<ul>\n<li>线程和块索引</li>\n<li>矩阵中给定点的坐标</li>\n<li>全局线性内存中的偏移量</li>\n</ul>\n<p>对于一个给定的线程，首先可以通过把线程和块索引映射到矩阵坐标上来获取线程块和线程索引的全局内存偏移量，然后将这些矩阵坐标映射到全局内存的存储单元中。</p>\n<p>第一步，可以用以下公式把线程和块索引映射到矩阵坐标上：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">ix = threadIdx.x + blockIdx.x * blockDim.x;<br>iy = threadIdx.y + blockIdx.y * blockDim.y;<br></code></pre></div></td></tr></table></figure>\n\n<p>第二步，可以用以下公式把矩阵坐标映射到全局内存中的索引&#x2F;存储单元上:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">idx = iy * nx + ix<br></code></pre></div></td></tr></table></figure>\n\n<p>图2-10说明了块和线程索引，矩阵坐标以及线性全局内存索引之间的对应关系。</p>\n<p><img src=\"/2023/03/09/cuda014/image-20230309114815497.png\" alt=\"image-20230309114815497\"></p>\n<p>printThreadInfo函数被用于输出关于每个线程的以下信息：</p>\n<ul>\n<li>线程索引</li>\n<li>块索引</li>\n<li>矩阵坐标</li>\n<li>线性全局内存偏移量</li>\n<li>相应元素的值</li>\n</ul>\n<p>用以下命令编译并运行该程序：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc -arch=sm_20 checkThreadIndex.cu -o checkIndex<br>./checkIndex<br></code></pre></div></td></tr></table></figure>\n\n<p>对于每个线程，你可以获取以下信息：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">thread_id</span>(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">1</span>)\t<span class=\"hljs-built_in\">block_id</span>(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">0</span>)\t<span class=\"hljs-built_in\">coordinate</span>(<span class=\"hljs-number\">6</span>,<span class=\"hljs-number\">1</span>)\tglobal index <span class=\"hljs-number\">14</span> ival <span class=\"hljs-number\">14</span><br></code></pre></div></td></tr></table></figure>\n\n<p>图2-11说明了这三项索引之间的关系。</p>\n<p><img src=\"/2023/03/09/cuda014/image-20230309115229368.png\" alt=\"image-20230309115229368\"></p>\n<p>代码清单2-6 检查块和线程索引（checkT和readIndex.cu）</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;cuda_runtime.h&gt;</span></span><br><span class=\"hljs-meta\">#inclde <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> CHECK(call)</span><br>&#123;<br>    <span class=\"hljs-keyword\">const</span> cudaError_t error = call;<br>    <span class=\"hljs-keyword\">if</span>(error != cudaSuccess)<br>    &#123;<br>        <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Error: %s:%d, &quot;</span>,__FILE__, __LINE__);<br>        <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;code:%d, reason: %s\\n&quot;</span>,error, <span class=\"hljs-built_in\">cudaGetErrorString</span>(error));<br>        <span class=\"hljs-built_in\">exit</span>(<span class=\"hljs-number\">-10</span>*error);<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">initialInt</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> *p, <span class=\"hljs-keyword\">int</span> size)</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i=<span class=\"hljs-number\">0</span>;i&lt;size;i++)&#123;<br>        ip[i] = i;<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">printMateix</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> *C,<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> nx, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> ny)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> *ic = C;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;\\nMatrix:\t(%d.%d)\\n&quot;</span>.nx,ny);<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> iy=<span class=\"hljs-number\">0</span>;iy&lt;ny;iy++)&#123;<br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> ix=<span class=\"hljs-number\">0</span>; ix&lt;nx;ix++)&#123;<br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%3d&quot;</span>,ic[ix]);<br>        &#125;<br>        ic += nx;<br>        <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;\\n&quot;</span>);<br>    &#125;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;\\n&quot;</span>);<br>&#125;<br><br><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">printThreadIndex</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> *A, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> nx, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> ny)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> ix = threadIdx.x + blockIdx.x * blockDim.x;<br>    <span class=\"hljs-keyword\">int</span> iy = threadIdx.y + blockIdx.y * blockDim.y;<br>    <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span> idx = iy*nx + ix;<br>    <br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;thread_id (%d,%d) block_id (%d,%d) coordinate (%d,%d) global index %2d ival %2d\\n&quot;</span>, threadIdx.x, threadIdx.y, blockIdx.x,blockIdx.y,ix,iy,idx,A[idx]);<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc,<span class=\"hljs-keyword\">char</span> **argv)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%s Starting...\\n&quot;</span>,argv[<span class=\"hljs-number\">0</span>]);<br>    <br>    <span class=\"hljs-comment\">//get device information</span><br>    <span class=\"hljs-keyword\">int</span> dev = <span class=\"hljs-number\">0</span>;<br>    cudaDeviceProp deviceProp;<br>    <span class=\"hljs-built_in\">CHECK</span>(<span class=\"hljs-built_in\">cudaGetDeviceProperties</span>(&amp;deviceProp, dev));<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Using Device %d: %s\\n&quot;</span>, dev, deviceProp.name);<br>    <br>    <span class=\"hljs-comment\">//set matrix dimension</span><br>    <span class=\"hljs-keyword\">int</span> nx = <span class=\"hljs-number\">8</span>;<br>    <span class=\"hljs-keyword\">int</span> ny = <span class=\"hljs-number\">6</span>;<br>    <span class=\"hljs-keyword\">int</span> nxy = nx*ny;<br>    <span class=\"hljs-keyword\">int</span> nBytes = nxy * <span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">float</span>);<br>    <br>    <span class=\"hljs-comment\">//malloc host memory</span><br>    <span class=\"hljs-keyword\">int</span> *h_A;<br>    h_A = (<span class=\"hljs-keyword\">int</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    <br>    <span class=\"hljs-comment\">//initialize host matrix with interger</span><br>    <span class=\"hljs-built_in\">initialInt</span>(h_A, nxy);<br>    <span class=\"hljs-built_in\">printMatrix</span>(h_A, nx, ny);<br>    <br>    <span class=\"hljs-comment\">//malloc device memory</span><br>    <span class=\"hljs-keyword\">int</span> *d_MatA;<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">void</span>**)&amp;d_MatA, nBytes);<br>    <br>    <span class=\"hljs-comment\">//transfer data from host to device</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_MatA, h_A, nBytes, cudaMemcpyHostToDevice);<br>    <br>    <span class=\"hljs-comment\">//set up execution configuration</span><br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">2</span>)</span></span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">((nx+block.x<span class=\"hljs-number\">-1</span>)/block.x,(ny+block.y<span class=\"hljs-number\">-1</span>)/block.y)</span></span>;<br>    <br>    <span class=\"hljs-comment\">//invoke the kernel</span><br>    printThreadIndex&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_MatA,nx,ny);<br>    <span class=\"hljs-built_in\">cudaDeviceSynchronize</span>();<br>    <br>    <span class=\"hljs-comment\">//free host and device memory</span><br>    <span class=\"hljs-built_in\">cudaFree</span>(d_MatA);<br>    <span class=\"hljs-built_in\">free</span>(h_A);<br>    <br>    <span class=\"hljs-comment\">//reset device</span><br>    <span class=\"hljs-built_in\">cudaDeviceReset</span>();<br>    <br>    <span class=\"hljs-keyword\">return</span>(<span class=\"hljs-number\">0</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/08/cuda013/",
            "url": "https://xingyuanjie.top/2023/03/08/cuda013/",
            "title": "CUDA组织并行编程",
            "date_published": "2023-03-08T14:13:01.000Z",
            "content_html": "<h2 id=\"组织并行编程\"><a href=\"#组织并行编程\" class=\"headerlink\" title=\"组织并行编程\"></a>组织并行编程</h2><p>从前面的例子可以看出，如果使用了合适的网格和块大小来正确地组织线程，那么可以对内核性能产生很大的影响。在向量加法的例子中，为了实现最佳性能我们调整了块的大小，并基于块大小和向量数据大小计算出了网格大小。</p>\n<p>现在通过一个矩阵加法的例子说明这一点。对于矩阵运算，传统的方法是在内核中使用一个包含二维网格与二位块的布局来组织线程。但是，这种传统的方法无法获得最佳性能。在矩阵加法中使用以下布局将有助于了解更多关于网格和块的启发性的用法：</p>\n<ol>\n<li>有二维线程块构成的二维网格</li>\n<li>由一维线程块构成的一维网格</li>\n<li>由一维线程块构成的二维网格</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/07/CUDA012/",
            "url": "https://xingyuanjie.top/2023/03/07/CUDA012/",
            "title": "CUDA给核函数计时",
            "date_published": "2023-03-07T01:53:34.000Z",
            "content_html": "<h2 id=\"CUDA给核函数计时\"><a href=\"#CUDA给核函数计时\" class=\"headerlink\" title=\"CUDA给核函数计时\"></a>CUDA给核函数计时</h2><p>在内核的性能转换过程中，了解核函数的执行需要多长时间是很有帮助并且十分关键的。衡量核函数性能的方法有很多。最简单的方法是在主机端使用一个CPU或GPU计时器来计算内核的执行时间。在本节，你需要设置一个CPU计时器，并使用NVIDIA分析工具来计算执行时间。</p>\n<h3 id=\"用CPU计时器计时\"><a href=\"#用CPU计时器计时\" class=\"headerlink\" title=\"用CPU计时器计时\"></a>用CPU计时器计时</h3><p>可以使用gettimeofday系统调用来创建一个CPU计时器，以获取系统的时钟时间，它将返回自1970年1月1日零点以来，到现在的秒数。程序中需要添加sys&#x2F;time.h头文件，如代码清单2-5所示。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">double</span> <span class=\"hljs-title\">cpuSecond</span><span class=\"hljs-params\">()</span></span><br><span class=\"hljs-function\"></span>&#123;<br>    <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">timeval</span> <span class=\"hljs-title\">tp</span>;</span><br>    <span class=\"hljs-built_in\">gettimeofday</span>(&amp;tp,<span class=\"hljs-literal\">NULL</span>);<br>    <br>    <span class=\"hljs-keyword\">return</span> ((<span class=\"hljs-keyword\">double</span>)tp.tv_sec + (<span class=\"hljs-keyword\">double</span>)tp.tv_usec*<span class=\"hljs-number\">1.e-6</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>你可以用cpuSecond函数来测试你的核函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">double</span> iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>kernel_name&lt;&lt;&lt;grid,block&gt;&gt;&gt;(argument list);<br><span class=\"hljs-built_in\">cudaDeviceSynchronize</span>();<br><span class=\"hljs-keyword\">double</span> iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br></code></pre></div></td></tr></table></figure>\n\n<p>由于核函数调用与主机端程序是异步的，你需要用cudaDeviceSynchronize函数来等待所有的GPU线程运行结束。变量iElaps表示程序运行的时间，就像你用手表记录的核函数的执行时间（用秒计算）。</p>\n<p>现在，通过设置数据集大小来对一个有16M个元素的大向量进行测试：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">int</span> nElem = <span class=\"hljs-number\">1</span>&lt;&lt;<span class=\"hljs-number\">24</span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>由于GPU的可扩展性，你需要借助块和线程的索引来计算一个按行优先的数组索引 i ，并对核函数进行修改，添加限定条件（i &lt; N）来检验索引值是否越界，如下所示：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArraysOnGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> N)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class=\"hljs-keyword\">if</span>( n &lt; N) C[i] = A[i] + B[i];<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>有了这些更改，可以使用不同的执行配置来衡量核函数。为了解决创建的线程总数大于向量元素总数的情况，你需要限制内核不能非法访问全局内存，如图2-7所示。</p>\n<p><img src=\"/2023/03/07/CUDA012/image-20230307120643741.png\" alt=\"image-20230307120643741\"></p>\n<p>代码清单2-5展示了如何在主函数中用CPU计时器测试向量加法的核函数。</p>\n<p>代码清单2-5\t测试向量加法的核函数（sumArraysOnGPU-timer.cu）</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;cuda_runtime.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;sys/time.h&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc,<span class=\"hljs-keyword\">char</span> **argv)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%s Starting...\\n&quot;</span>,argv[<span class=\"hljs-number\">0</span>]);<br>    <br>    <span class=\"hljs-comment\">//set up device</span><br>    <span class=\"hljs-keyword\">int</span> dev = <span class=\"hljs-number\">0</span>;<br>    cudaDeviceProp deviceProp;<br>    <span class=\"hljs-built_in\">CHECK</span>(<span class=\"hljs-built_in\">cudaGetDeviceProperties</span>(&amp;deviceProp, dev));<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Using Device %d: %s\\n&quot;</span>, dev, deviceProp.name);<br>    <span class=\"hljs-built_in\">CHECK</span>(<span class=\"hljs-built_in\">cudaSetDevice</span>(dev));<br>    <br>    <span class=\"hljs-comment\">//set up data size of vectors</span><br>    <span class=\"hljs-keyword\">int</span> nElem = <span class=\"hljs-number\">1</span>&lt;&lt;<span class=\"hljs-number\">24</span>;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Vector size %d\\n&quot;</span>,nElem);<br>    <br>    <span class=\"hljs-comment\">//malloc host memory</span><br>    <span class=\"hljs-keyword\">size_t</span> nBytes = nElem * <span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">float</span>);<br>    <br>    <span class=\"hljs-keyword\">float</span> *h_A, *h_B, *hostRef, *gpuRef;<br>    h_A = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    h_B = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    hostRef = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    gpuRef = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    <br>    <span class=\"hljs-keyword\">double</span> iStart,iElaps;<br>    <br>    <span class=\"hljs-comment\">//initialize data at host side</span><br>    iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>    <span class=\"hljs-built_in\">initialData</span>(h_A, nElem);<br>    <span class=\"hljs-built_in\">initialData</span>(h_B, nElem);<br>    iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br>    <br>    <span class=\"hljs-built_in\">memset</span>(hostRef, <span class=\"hljs-number\">0</span> ,nBytes);<br>    <span class=\"hljs-built_in\">memset</span>(gpuRef, <span class=\"hljs-number\">0</span> ,nBytes);<br>    <br>    <span class=\"hljs-comment\">//add vector at host side for result checks</span><br>    iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>    <span class=\"hljs-built_in\">sumArraysOnHost</span>(h_A, h_B, hostRef, nElem);<br>    iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br>    <br>    <span class=\"hljs-comment\">//malloc device global memory</span><br>    <span class=\"hljs-keyword\">float</span> *d_A, *d_B, *d_C;<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_A, nBytes);<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_B, nBytes);<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_C, nBytes);<br>    <br>    <span class=\"hljs-comment\">//transfer data from host to device</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_A, h_A, nBytes, cudaMemcpyHostTodevice);<br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_B, h_B, nBytes, cudaMemcpyHostTodevice);<br>    <br>    <span class=\"hljs-comment\">//invoke kernel at host side</span><br>    <span class=\"hljs-keyword\">int</span> iLen = <span class=\"hljs-number\">1024</span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(iLen)</span></span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">((nElem+block.x<span class=\"hljs-number\">-1</span>))</span>/block.x)</span>;<br>    <br>    iStart = <span class=\"hljs-built_in\">cpuSecond</span>();<br>    sumArraysOnGPU&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_A, d_B, d_C,nElem);<br>    <span class=\"hljs-built_in\">cudaDeviceSynchronize</span>();<br>    iElaps = <span class=\"hljs-built_in\">cpuSecond</span>() - iStart;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;sumArraysOnGPU&lt;&lt;&lt;%d,%d&gt;&gt;&gt; Time elapsed %f sec\\n&quot;</span>,grid.x, block.x, iElaps);<br>    <br>    <span class=\"hljs-comment\">//copy kernel result back to host side</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);<br>    <br>    <span class=\"hljs-comment\">//check device results</span><br>    <span class=\"hljs-built_in\">checkResult</span>(hostRef, gpuRef, nElem);<br>    <br>    <span class=\"hljs-comment\">//free device global memory</span><br>    <span class=\"hljs-built_in\">cudaFree</span>(d_A);<br>    <span class=\"hljs-built_in\">cudaFree</span>(d_B);<br>    <span class=\"hljs-built_in\">cudaFree</span>(d_C);<br>    <br>    <span class=\"hljs-comment\">//free host memory</span><br>    <span class=\"hljs-built_in\">free</span>(h_A);<br>    <span class=\"hljs-built_in\">free</span>(h_B);<br>    <span class=\"hljs-built_in\">free</span>(hostRef);<br>    <span class=\"hljs-built_in\">free</span>(gpuRef);<br>    <br>    <span class=\"hljs-keyword\">return</span>(<span class=\"hljs-number\">0</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>默认的执行配置被设置为一个包含16384个块的一维网格，每个块包含1024个线程。用以下命令编译并运行程序：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc sumArraysOnGPU-timer.cu -o sumArraysOnGPU-timer<br>./sumArraysOnGPU-timer<br></code></pre></div></td></tr></table></figure>\n\n<p>在基于英特尔Sandy Bridge架构的系统上进行测试，从代码清单2-5的示例中可以看出，在GPU上进行的向量加法的运算速度是在CPU上运行向量加法的3.86倍。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">./sumArraysOnGPU-timer Starting...<br>Using Device 0:Tesia M2070<br>Vector size 16777216<br>sumArraysOnGPU&lt;&lt;&lt;16384, 1024&gt;&gt;&gt;\t\tTime elapsed 0.002456 sec<br>Arrays match.<br></code></pre></div></td></tr></table></figure>\n\n<p>把块的维度减少到512可以创建32768个块。在这个新的配置下，内核的性能提升了1.19倍。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">sumArraysOnGPU&lt;&lt;&lt;32768, 512&gt;&gt;&gt;\tTime elapsed 0.002058 sec<br></code></pre></div></td></tr></table></figure>\n\n<p>如果进一步将块的维度降低到256，系统将提示以下错误信息，信息表示块的总数超过一维网格的限制。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">./sumArraysOnGPU-timer Starting...<br>Using Device 0:\tTesla M2070<br>Vector size 16777216<br>sumArraysOnGPU&lt;&lt;&lt;65536, 256&gt;&gt;&gt;  Time elapsed 0.000183 sec<br>Error: sumArraysOnGPU-timer.cu:153, code:9, reason: invalid configuration argument<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"了解自身局限性\"><a href=\"#了解自身局限性\" class=\"headerlink\" title=\"了解自身局限性\"></a>了解自身局限性</h3><p>在调整执行配置时需要了解的一个关键点是对网格和块维度的限制。线程层次结构中每个层次的最大尺寸取决于设备。</p>\n<p>CUDA提供了通过查询GPU来了解这些限制的能力。</p>\n<p>对于Fermi设备，每个块的最大线程数是1024，且网格的x,y,z三个方向上的维度最大值是65535</p>\n<h3 id=\"用nvprof工具计时\"><a href=\"#用nvprof工具计时\" class=\"headerlink\" title=\"用nvprof工具计时\"></a>用nvprof工具计时</h3><p>自CUDA 5.0以来，NVIDIA提供了一个名为nvprof的命令行分析工具，可以帮助从应用程序的CPU和GPU活动情况中获取时间线信息，其包括内核执行，内存传输以及CUDA API的调用。其用法如下。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvprof [nvprof_args] &lt;application&gt;  [application_args]<br></code></pre></div></td></tr></table></figure>\n\n<p>可以使用以下命令获取更多关于nvprof的帮助信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvprof --help<br></code></pre></div></td></tr></table></figure>\n\n<p>你可以用如下命令去测试内核：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvprof  ./sumArraysOnGPU-timer<br></code></pre></div></td></tr></table></figure>\n\n<p>nvprof的输出结果会因为你使用的GPU类型不同而有所差异。以下结果是从Tesla GPU中得到的：</p>\n<p><img src=\"/2023/03/07/CUDA012/image-20230307142027522.png\" alt=\"image-20230307142027522\"></p>\n<p>以上结果的前半部分来自于程序的输出，后半部分来自于nvprof的输出。可以注意到，CPU计时器显示消耗的内核时间为3.26ms，而nvprof显示消耗的内核时间为2.90ms。在这个例子中，nvprof的结果更为精确，因为CPU计时器测量的时间中包含了来自nvprof附加的时间。</p>\n<p>nvprof是一个能帮助你理解在执行应用程序时所花费的时间主要用在何处的强大工具。可以注意到，在这个例子中，主机和设备之间的数据传输需要的时间比内核执行的时间要多。图2-8所描绘的时间线（未按比例绘制），显示了在CPU上消耗的时间，数据传输所用的时间以及在GPU上计算所用的时间。</p>\n<p><img src=\"/2023/03/07/CUDA012/image-20230307145539161.png\" alt=\"image-20230307145539161\"></p>\n<p>对于HPC工作负载，理解程序中通信比的计算是非常重要的。如果你的应用程序用于计算的时间大于数据传输所用的时间，那么或许可以压缩这些操作，并完全隐藏与传输数据有关的延迟。如果你的应用程序用于计算的时间少于数据传输所用的时间，那么需要尽量减少主机和设备之间的传输。</p>\n<h3 id=\"比较应用程序的性能将理论界限最大化\"><a href=\"#比较应用程序的性能将理论界限最大化\" class=\"headerlink\" title=\"比较应用程序的性能将理论界限最大化\"></a>比较应用程序的性能将理论界限最大化</h3><p>在进行程序优化时，如何将应用程序和理论界限进行比较是很重要的。由nvprof得到的计数器可以帮助你获取应用程序的指令和内存吞吐量。如果将应用程序的测量值与理论峰值进行比较，可以判定你的应用程序的性能是受限于算法还是受限于内存带宽的。以Tesla K10为例，可以得到理论上的比率：</p>\n<p>Tesla K10单精度峰值浮点运算次数</p>\n<p>745 MHz核心频率*2 GPU&#x2F;芯片*  （8个多处理器<em>192个浮点单元</em>32核心&#x2F;多处理器）*2OPS&#x2F;周期 &#x3D; 4.58 TFLOPS （FLOPS表示每秒浮点运算次数）</p>\n<p>Tesla K10内存带宽峰值</p>\n<p>2 GPU&#x2F;芯片<em>256位</em>2500 MHz内存时钟*2 DDR&#x2F;8位&#x2F;字节 &#x3D; 320 GB&#x2F;s</p>\n<p>指令比：字节</p>\n<p>4.58 TFLOPS&#x2F;320 GB&#x2F;s,\t也就是13.6个指令：1个字节</p>\n<p>对于Tesla K10而言，如果你的应用程序每访问一个字节所产生的指令数多于13.6，那么你的应用程序受算法性能限制。大多数HPC工作负载受内存带宽的限制。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/06/cuda011/",
            "url": "https://xingyuanjie.top/2023/03/06/cuda011/",
            "title": "CUDA编译与执行",
            "date_published": "2023-03-06T08:18:09.000Z",
            "content_html": "<h2 id=\"CUDA编译与执行\"><a href=\"#CUDA编译与执行\" class=\"headerlink\" title=\"CUDA编译与执行\"></a>CUDA编译与执行</h2><p>现在把所有的代码放在一个文件名为sumArraysOnGPU-small-case.cu的文件中，如代码清单2-4所示。</p>\n<p><strong>代码清单2-4\t\t基于GPU的向量加法（sumArraysOnGPU-small-case.cu）</strong></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;cuda_runtime.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-comment\">/*</span><br><span class=\"hljs-comment\">#define CHECK(call)</span><br><span class=\"hljs-comment\">&#123;</span><br><span class=\"hljs-comment\">    const cudaError_t error = call;</span><br><span class=\"hljs-comment\">    if(error != cudaSuccess)</span><br><span class=\"hljs-comment\">    &#123;</span><br><span class=\"hljs-comment\">        printf(&quot;Error:%s:%d, &quot;, __FILE__, __LINE__);</span><br><span class=\"hljs-comment\">        printf(&quot;code:%d, reason: %s\\n&quot;, error, cudaGetErrorString(error));</span><br><span class=\"hljs-comment\">    &#125;</span><br><span class=\"hljs-comment\">&#125;</span><br><span class=\"hljs-comment\">*/</span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">checkResult</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *hostRef, <span class=\"hljs-keyword\">float</span> *gpuRef, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> N)</span></span>&#123;<br>    <span class=\"hljs-keyword\">double</span> epsilon = <span class=\"hljs-number\">1.0E-8</span>;<br>    <span class=\"hljs-keyword\">int</span> match = <span class=\"hljs-number\">1</span>;<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span> ;i &lt; N; i++)&#123;<br>        <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">abs</span>(hostRef[i] - gpuRef[i]) &gt; epsilon)&#123;<br>            match = <span class=\"hljs-number\">0</span>;<br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Arrays do not match!\\n&quot;</span>);<br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;host %5.2f gpu %5.2f at current %d\\n&quot;</span>,hostRef[i],gpuRef[i],i);<br>            <span class=\"hljs-keyword\">break</span>;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-keyword\">if</span>(match) <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Arrays match.\\n\\n&quot;</span>);<br>    <span class=\"hljs-keyword\">return</span>;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">initialData</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *ip,<span class=\"hljs-keyword\">int</span> size)</span></span>&#123;<br>    <span class=\"hljs-comment\">//generate different seed for random number</span><br>    <span class=\"hljs-keyword\">time_t</span> t;<br>    <span class=\"hljs-built_in\">srand</span>((<span class=\"hljs-keyword\">unsigned</span>) <span class=\"hljs-built_in\">time</span>(&amp;t));<br>    <br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i&lt;size;i++)&#123;<br>        ip[i] = (<span class=\"hljs-keyword\">float</span>)(<span class=\"hljs-built_in\">rand</span>() &amp; <span class=\"hljs-number\">0xFF</span>) /<span class=\"hljs-number\">10.0f</span>;<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArraysOnHost</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A,<span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> i = threadIdx.x;<br>    C[i] = A[i] + B[i];<br>&#125;<br><br><span class=\"hljs-function\">__gloal__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArraysOnGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> i = threadIdx.x;<br>    C[i] = A[i] + B[i];<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc,<span class=\"hljs-keyword\">char</span> **argv)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%s Starting...\\n&quot;</span>,argv[<span class=\"hljs-number\">0</span>]);<br>    <br>    <span class=\"hljs-comment\">//set up device</span><br>    <span class=\"hljs-keyword\">int</span> dev = <span class=\"hljs-number\">0</span>;<br>    <span class=\"hljs-built_in\">cudaSetDevice</span>(dev);<br>    <br>    <span class=\"hljs-comment\">//set up data size of vectors</span><br>    <span class=\"hljs-keyword\">int</span> nElem = <span class=\"hljs-number\">32</span>;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Vector size %d\\n&quot;</span>,nElem);<br>    <br>    <span class=\"hljs-comment\">//malloc host memory</span><br>    <span class=\"hljs-keyword\">size_t</span> nBytes = nElem * <span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">float</span>);<br>    <br>    <span class=\"hljs-keyword\">float</span> *h_A, *h_B, *hostRef, *gpuRef;<br>    h_A = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    h_B = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    hostRef = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    gpuRef = (<span class=\"hljs-keyword\">float</span>*)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    <br>    <span class=\"hljs-comment\">//initialize data at host side</span><br>    <span class=\"hljs-built_in\">initialData</span>(h_A, nElem);<br>    <span class=\"hljs-built_in\">initialData</span>(h_B, nElem);<br>    <br>    <span class=\"hljs-built_in\">memset</span>(hostRef, <span class=\"hljs-number\">0</span> ,nBytes);<br>    <span class=\"hljs-built_in\">memset</span>(gpuRef, <span class=\"hljs-number\">0</span> ,nBytes);<br>    <br>    <span class=\"hljs-comment\">//malloc device global memory</span><br>    <span class=\"hljs-keyword\">float</span> *d_A, *d_B, *d_C;<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_A, nBytes);<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_B, nBytes);<br>    <span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_C, nBytes);<br>    <br>    <span class=\"hljs-comment\">//transfer data from host to device</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_A, h_A, nBytes, cudaMemcpyHostTodevice);<br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(d_B, h_B, nBytes, cudaMemcpyHostTodevice);<br>    <br>    <span class=\"hljs-comment\">//invoke kernel at host side</span><br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(nElem)</span></span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">(nElem/block.x)</span></span>;<br>    <br>    sumArraysOnGPU&lt;&lt;&lt;grid,block&gt;&gt;&gt;(d_A, d_B, d_C);<br>    <span class=\"hljs-built_in\">pritnf</span>(<span class=\"hljs-string\">&quot;Execution configuration &lt;&lt;&lt;%d, %d&gt;&gt;&gt;\\n&quot;</span>,grid.x,block.x);<br>    <br>    <span class=\"hljs-comment\">//copy kernel result back to host side</span><br>    <span class=\"hljs-built_in\">cudaMemcpy</span>(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);<br>    <br>    <span class=\"hljs-comment\">//add vector at host side for result checks</span><br>    <span class=\"hljs-built_in\">sumArraysOnHost</span>(h_A, h_B, hostRef, nElem);<br>    <br>    <span class=\"hljs-comment\">//check device results</span><br>    <span class=\"hljs-built_in\">checkResult</span>(hostRef, gpuRef, nElem);<br>    <br>    <span class=\"hljs-comment\">//free device global memory</span><br>    <span class=\"hljs-built_in\">cudaFree</span>(d_A);<br>    <span class=\"hljs-built_in\">cudaFree</span>(d_B);<br>    <span class=\"hljs-built_in\">cudaFree</span>(d_C);<br>    <br>    <span class=\"hljs-comment\">//free host memory</span><br>    <span class=\"hljs-built_in\">free</span>(h_A);<br>    <span class=\"hljs-built_in\">free</span>(h_B);<br>    <span class=\"hljs-built_in\">free</span>(hostRef);<br>    <span class=\"hljs-built_in\">free</span>(gpuRef);<br>    <br>    <span class=\"hljs-keyword\">return</span>(<span class=\"hljs-number\">0</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>在这段代码中，向量大小被设置为32，如下所示：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">int</span> nElem = <span class=\"hljs-number\">32</span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>执行配置被放入一个块内，其中包含32个元素：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(nElem)</span></span>;<br><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">(nElem/block.x)</span></span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>使用以下命令编译和执行该带啊吗：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc sumArraysOnGPU-small-case.cu -o addvector<br>./addvector<br></code></pre></div></td></tr></table></figure>\n\n<p>系统报告如下：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">./addvector Starting...<br>Vector size 32<br>Execution configuration &lt;&lt;&lt;1,32&gt;&gt;&gt;<br>Arrays match.<br></code></pre></div></td></tr></table></figure>\n\n<p>如果你将执行配置重新定义为32个块，每个块只有一个元素，如下所示；</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(<span class=\"hljs-number\">1</span>)</span></span>;<br><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">(nElem)</span></span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>那么就需要在代码清单2-4中对核函数sumArraysOnGPU进行修改：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">用<span class=\"hljs-keyword\">int</span> i = threadIdx.x;    替换<span class=\"hljs-keyword\">int</span> i = blockIdx.x;<br></code></pre></div></td></tr></table></figure>\n\n<p>一般情况下，可以基于给定的一维网格和块的信息来计算全局数据访问的唯一索引：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__gloal__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArraysOnGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> i = blockIdx.x * blockDim.x * threadIdx.x;<br>    C[i] = A[i] + B[i];<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>你需要确保一般情况下进行更改所产生结果的正确性。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/06/cuda010/",
            "url": "https://xingyuanjie.top/2023/03/06/cuda010/",
            "title": "CUDA处理错误",
            "date_published": "2023-03-06T08:17:59.000Z",
            "content_html": "<h2 id=\"CUDA处理错误\"><a href=\"#CUDA处理错误\" class=\"headerlink\" title=\"CUDA处理错误\"></a>CUDA处理错误</h2><p>由于许多CUDA调用是异步的，所以有时可能很难确定某个错误是由哪一步程序引起的。定义一个错误处理宏封装所有的CUDA API调用，这简化了错误检查过程：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> CHECK(call)</span><br>&#123;<br>    <span class=\"hljs-keyword\">const</span> cudaError_t error = call;<br>    <span class=\"hljs-keyword\">if</span>(error != cudaSuccess)<br>    &#123;<br>        <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Error:%s:%d, &quot;</span>, __FILE__, __LINE__);<br>        <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;code:%d, reason: %s\\n&quot;</span>, error, <span class=\"hljs-built_in\">cudaGetErrorString</span>(error));<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>例如，你可以在以下代码中使用宏：</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs reasonml\"><span class=\"hljs-constructor\">CHECK(<span class=\"hljs-params\">cudaMemcpy</span>(<span class=\"hljs-params\">d_C</span>, <span class=\"hljs-params\">gpuRef</span>, <span class=\"hljs-params\">nBytes</span>, <span class=\"hljs-params\">cudaMemcpyHostToDevice</span>)</span>);<br></code></pre></div></td></tr></table></figure>\n\n<p>如果内存拷贝或之前的异步操作产生了错误，这个宏会报告错误代码，并输出一个可读信息，然后停止程序。也可以用下述方法，在核函数调用后检查核函数错误：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">kernel_function&lt;&lt;&lt;grid,block&gt;&gt;&gt;(argument list);<br><span class=\"hljs-built_in\">CHECK</span>(<span class=\"hljs-built_in\">cudaDeviceSynchronize</span>());<br></code></pre></div></td></tr></table></figure>\n\n<p>CHECK(cudaDeviceSynchronize())会阻塞主机端线程的运行直到设备端所有的请求任务都结束，并确保最后的核函数启动部分不会出错。以上仅是以调试为目的的，因为在核函数启动后添加这个检查点会阻塞主机端线程，使该检查点成为全局屏障。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/06/cuda009/",
            "url": "https://xingyuanjie.top/2023/03/06/cuda009/",
            "title": "CUDA验证核函数",
            "date_published": "2023-03-06T08:06:35.000Z",
            "content_html": "<h2 id=\"CUDA验证核函数\"><a href=\"#CUDA验证核函数\" class=\"headerlink\" title=\"CUDA验证核函数\"></a>CUDA验证核函数</h2><p>既然你已经编写了核函数，你如何能知道它是否正确运行？你需要一个主机函数来验证核函数的结果。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">checkResult</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *hostRef, <span class=\"hljs-keyword\">float</span> *gpuRef, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> N)</span></span>&#123;<br>    <span class=\"hljs-keyword\">double</span> epsilon = <span class=\"hljs-number\">1.0E-8</span>;<br>    <span class=\"hljs-keyword\">int</span> match = <span class=\"hljs-number\">1</span>;<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span> ;i &lt; N; i++)&#123;<br>        <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">abs</span>(hostRef[i] - gpuRef[i]) &gt; epsilon)&#123;<br>            match = <span class=\"hljs-number\">0</span>;<br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Arrays do not match!\\n&quot;</span>);<br>            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;host %5.2f gpu %5.2f at current %d\\n&quot;</span>,hostRef[i],gpuRef[i],i);<br>            <span class=\"hljs-keyword\">break</span>;<br>        &#125;<br>    &#125;<br>    <span class=\"hljs-keyword\">if</span>(match) <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Arrays match.\\n\\n&quot;</span>);<br>    <span class=\"hljs-keyword\">return</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"验证核函数代码\"><a href=\"#验证核函数代码\" class=\"headerlink\" title=\"验证核函数代码\"></a>验证核函数代码</h3><p>除了许多可用的调试工具外，还有两个非常简单实用的方法可以验证核函数。</p>\n<p>首先，你可以在Fermi及更高版本的设备端的核函数中使用printf函数。</p>\n<p>其次，可以将执行参数设置为&lt;&lt;&lt;1,1&gt;&gt;&gt;，因此强制用一个块和一个线程执行核函数，这模拟了串行执行程序。这对于调试和验证结果是否正确是非常有用的，而且，如果你遇到了运算次序的问题，这有助于你对比验证数值结果是否是按位精确的。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/06/cuda008/",
            "url": "https://xingyuanjie.top/2023/03/06/cuda008/",
            "title": "CUDA编写核函数",
            "date_published": "2023-03-06T07:46:00.000Z",
            "content_html": "<h2 id=\"编写核函数\"><a href=\"#编写核函数\" class=\"headerlink\" title=\"编写核函数\"></a>编写核函数</h2><p>核函数是在设备端执行的代码。在核函数中，需要为一个线程规定要进行的计算以及要进行的数据访问。当核函数被调用时，许多不同的CUDA线程并行执行同一个计算任务。以下是用_<em>global</em>_</p>\n<p>声明定义核函数：</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs reasonml\">__global__  void kernel<span class=\"hljs-constructor\">_name(<span class=\"hljs-params\">argument</span> <span class=\"hljs-params\">list</span>)</span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>核函数必须有一个void返回类型。</p>\n<p>表2-2总结了CUDA C程序中的函数类型限定符。函数类型限定符指定一个函数在主机上执行还是在设备上执行，以及可被主机调用还是被设备调用。</p>\n<p><img src=\"/2023/03/06/cuda008/image-20230306155126122.png\" alt=\"image-20230306155126122\"></p>\n<p>_<em>device</em>_   和 __host__限定符可以一齐使用，这样函数可以同时在主机和设备端进行编译。</p>\n<h3 id=\"CUDA核函数的限制\"><a href=\"#CUDA核函数的限制\" class=\"headerlink\" title=\"CUDA核函数的限制\"></a>CUDA核函数的限制</h3><p>以下限制适用于所有核函数：</p>\n<ul>\n<li>只能访问设备内存</li>\n<li>必须具有void返回类型</li>\n<li>不支持可变数量的参数</li>\n<li>不支持静态变量</li>\n<li>显示异步行为</li>\n</ul>\n<p>考虑一个简单的例子：将两个大小为N的向量A和B相加，主机端的向量加法C代码如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArrayOnHost</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> N)</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>;i &lt; N; i++)<br>        C[i] = A[i] + B[i];<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>这是一个迭代N次的串行程序，循环结束后将产生以下核函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArrayOnHost</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C)</span></span>&#123;<br>    \t<span class=\"hljs-keyword\">int</span> i = threadIdx.x;<br>        C[i] = A[i] + B[i];<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>C函数和核函数之间有什么不同？你可能已经注意到循环体消失了，内置的线程坐标变量替换了数组索引，由于N是被隐式定义用来启动N个线程的，所以N没有什么参考价值。</p>\n<p>假设有一个长度为32个元素的向量，你可以按以下方法用32个线程来调用核函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">sumArraysOnGPU&lt;&lt;&lt;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">32</span>&gt;&gt;&gt;(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C);<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/06/cuda007/",
            "url": "https://xingyuanjie.top/2023/03/06/cuda007/",
            "title": "启动一个CUDA核函数",
            "date_published": "2023-03-06T05:59:18.000Z",
            "content_html": "<h2 id=\"启动一个CUDA核函数\"><a href=\"#启动一个CUDA核函数\" class=\"headerlink\" title=\"启动一个CUDA核函数\"></a>启动一个CUDA核函数</h2><p>你应该对下列C语言函数调用语句很熟悉：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">function_name</span> (argument list);<br></code></pre></div></td></tr></table></figure>\n\n<p>CUDA内核调用是对C语言函数调用语句的延申，&lt;&lt;&lt;&gt;&gt;&gt;运算符内是核函数的执行配置。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">kerbel_name&lt;&lt;&lt;grid,block&gt;&gt;&gt;(srgument list);<br></code></pre></div></td></tr></table></figure>\n\n<p>正如上一节所述，CUDA编程模型揭示了线程层次结构。利用执行配置可以指定线程在GPU上调度运行的方式。执行配置的第一个值是网格维度，也就是启动块的数目。第二个值是块维度，也就是每个块中线程的数目。通过指定网格和块的维度，你可以进行一下配置：</p>\n<ul>\n<li>内核中线程的数目</li>\n<li>内核中使用的线程布局</li>\n</ul>\n<p>同一个块中的线程之间可以相互协作，不同块内的线程不能协作。对于一个给定的问题，可以使用不同的网格和块布局来组织你的线程。例如，假设你有32个数据元素用于计算，每8个元素一个块，需要启动4个块：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">kernel_name&lt;&lt;&lt;<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">8</span>&gt;&gt;&gt;(argument list);<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/06/cuda007/image-20230306140924311.png\" alt=\"image-20230306140924311\"></p>\n<p>由于数据在全局内存中是线性存储的，因此可以用变量blockIdx.x和threadIdx.x来进行以下操作。</p>\n<ul>\n<li>在网格中标识一个唯一的线程</li>\n<li>建立线程和数据元素之间的映射关系</li>\n</ul>\n<p>如果把32个元素放到一个块里，那么只会得到一个块：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">kernel_name&lt;&lt;&lt;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">32</span>&gt;&gt;&gt;(argument list);<br></code></pre></div></td></tr></table></figure>\n\n<p>如果每个块只含一个元素，那么会有32个块：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">kernel_name&lt;&lt;&lt;<span class=\"hljs-number\">32</span>,<span class=\"hljs-number\">1</span>&gt;&gt;&gt;(argument list);<br></code></pre></div></td></tr></table></figure>\n\n<p>核函数的调用与主机线程是异步的。核函数调用结束后，控制权立刻返回给主机端。你可以调用以下函数来强制主机端程序等待所有的核函数执行结束：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">cudaError_t <span class=\"hljs-title\">cudaDeviceSynchronize</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>一些CUDA运行时API在主机和设备之间是隐式同步的。当使用cudaMemcpy函数在主机和设备之间拷贝数据时，主机端隐式同步，即主机端程序必须等待数据拷贝完成后才能继续执行程序。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">cudaError_t <span class=\"hljs-title\">cudaMemcpy</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>* dst, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">void</span>* src, <span class=\"hljs-keyword\">size_t</span> count, cudaMemcpyKind kind)</span></span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>之前所有的核函数调用完成后开始拷贝数据。当拷贝完成后，控制权立刻返回给主机端。</p>\n<h3 id=\"异步行为\"><a href=\"#异步行为\" class=\"headerlink\" title=\"异步行为\"></a>异步行为</h3><p>不同于C语言的函数调用，所有的CUDA核函数的启动都是异步的。CUDA内核调用完成后，控制权立刻返回给CPU。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/01/28/cuda006/",
            "url": "https://xingyuanjie.top/2023/01/28/cuda006/",
            "title": "CUDA线程管理",
            "date_published": "2023-01-28T07:41:55.000Z",
            "content_html": "<h3 id=\"1-线程管理\"><a href=\"#1-线程管理\" class=\"headerlink\" title=\"1.线程管理\"></a>1.线程管理</h3><p>当核函数在主机端启动时，它的执行会移动到设备上，此时设备中会产生大量的线程并且每个线程都执行由核函数指定的语句。了解如何组织线程是CUDA编程的一个关键部分。CUDA明确了线程层次抽象的概念以便于你组织线程。这是一个两层的线程层次结构，由线程块和线程块网格构成，如图2-5所示。</p>\n<p><img src=\"/2023/01/28/cuda006/image-20230128160011560.png\" alt=\"image-20230128160011560\"></p>\n<p>由一个内核启动所产生的所有线程统称为一个网格。同一网格中的所有线程共享相同的全局内存空间。一个网格由多个线程块构成，一个线程块包含一组线程，同一线程块内的线程协作可以通过以下方式来实现。</p>\n<p>​\t-同步</p>\n<p>​\t-共享内存</p>\n<p>不同块内的线程不能协作。</p>\n<p>线程依靠以下两个坐标变量来区分彼此。</p>\n<p>​\t-blockIdx(线程块在线程格内的索引)</p>\n<p>​\t-threadIdx(块内的线程索引)</p>\n<p>这些变量是核函数中需要预初始化的内置变量。当执行一个核函数时，CUDA运行时为每个线程分配坐标变量blockIdx和threadIdx。基于这些坐标，你可以将部分数据分配给不同的线程。</p>\n<p>该坐标变量是基于uint3定义的CUDA内置的向量类型，是一个包含3个无符号整数的结构，可以通过x,y,z三个字段来指定。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">blockIdx.x<br>blockIdx.y<br>blockIdx.z<br>threadIdx.x<br>threadIdx.y<br>threadIdx.z<br></code></pre></div></td></tr></table></figure>\n\n<p>CUDA可以组织三维的网格和块。图2-5展示了一个线程层次结构的示例，其结构是一个包含二维块的二维网格。网格和块的维度由下列两个内置变量指定。</p>\n<p>​\t-blockDim(线程块的维度，用每个线程块中的线程数来表示)</p>\n<p>​\t-gridDim(线程格的维度，用每个线程格中的线程数来表示)</p>\n<p>它们是dim3类型的变量，是基于uint3定义的整数型向量，用来表示维度。当定义一个dim3类型的变量时，所有未指定的元素都被初始化为1。dim3类型变量中的每个组件可以通过它的x,y,z字段获得。如下所示。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">blockDim.x<br>blockDim.y<br>blockDim.z<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"2-网格和线程块的维度\"><a href=\"#2-网格和线程块的维度\" class=\"headerlink\" title=\"2.网格和线程块的维度\"></a>2.网格和线程块的维度</h3><p>通常，一个线程格会被组织成线程块的二维数组形式，一个线程块会被组织成线程的三维数组形式。</p>\n<p>线程格和线程块均使用3个dim3类型的无符号整型字段，而未使用的字段将被初始化为1且忽略不计。</p>\n<p>在CUDA程序中有两组不同的网格和块变量：手动定义的dim3数据类型和预定义的uint3数据类型。在主机端，作为内核调用的一部分，你可以使用dim3数据类型定义一个网格和块的维度。当执行核函数时，CUDA运行时会生成相应的内置预初始化的网格，块和线程变量，它们在核函数内均可被访问到且为unit3类型。手动定义的dim3类型的网络和块变量仅在主机端可见，而unit3类型的内置预初始化的网格和块变量仅在设备端可见。</p>\n<p>你可以通过代码清单2-2来验证这些变量如何使用。首先，定义程序所用的数据大小，为了对此进行说明，我们定义一个较小的数据。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">int</span> nElem = <span class=\"hljs-number\">6</span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>接下来，定义块的尺寸并基于块和数据的大小计算网格尺寸。在下面例子中，定义了一个包含3个线程的一维线程块，以及一个基于块和数据大小定义的一定数量线程块的一维线程网格。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(<span class=\"hljs-number\">3</span>)</span></span>;<br><span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">((nElem+block.x<span class=\"hljs-number\">-1</span>)/block.x)</span></span>;<br></code></pre></div></td></tr></table></figure>\n\n<p>你会发现网格大小是块大小的倍数。以下主机端上的程序段用来检查网格和块维度。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;grid.x %d grid.y %d grid.z %d\\n&quot;</span>,grid.x,grid.y,grid.z);<br><span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;block.x %d block.y %d block.z %d\\n&quot;</span>,block.x,block.y,block.z);<br></code></pre></div></td></tr></table></figure>\n\n<p>在核函数中，每个线程都输出自己的线程索引，块索引，块维度和网格维度。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;threadIdx:(%d, %d, %d) blockIdx:(%d, %d, %d) blockDim:(%d, %d, %d) &quot;</span> <span class=\"hljs-string\">&quot;gridDim:(%d, %d, %d)\\n&quot;</span>, threadIdx.x, threadIdx,y, threadIdz.z,blockIdx.x, blockIdx.y, blockIdx.z, blockDim.x, blockDim.y, blockDim.z, gridDim.x,gridDim.y,gridDim.z);<br></code></pre></div></td></tr></table></figure>\n\n<p>把代码合并保存成名为checkDimension.cu的文件，如代码清单2-2所示。</p>\n<p><strong>代码清单2-2     检查网络和块的索引和维度（checkDimension.cu）</strong></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;cuda_runtime.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><br><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">checkIndex</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;threadIdx:(%d, %d, %d) blockIdx:(%d, %d, %d) blockDim:(%d, %d, %d) &quot;</span> <span class=\"hljs-string\">&quot;gridDim:(%d, %d, %d)\\n&quot;</span>, \t\tthreadIdx.x, threadIdx,y, threadIdz.z, blockIdx.x, blockIdx.y, blockIdx.z, blockDim.x, blockDim.y, \t\t\tblockDim.z, gridDim.x,gridDim.y,gridDim.z);<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc, <span class=\"hljs-keyword\">char</span> **argv)</span></span>&#123;<br>    <span class=\"hljs-comment\">//define total data element</span><br>    <span class=\"hljs-keyword\">int</span> nElem = <span class=\"hljs-number\">6</span>;<br>    <span class=\"hljs-comment\">//define grid and block structure</span><br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span><span class=\"hljs-params\">(<span class=\"hljs-number\">3</span>)</span></span>;<br>\t<span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span><span class=\"hljs-params\">((nElem+block.x<span class=\"hljs-number\">-1</span>)/block.x)</span></span>;<br>    <br>    <span class=\"hljs-comment\">//check grid and block dimension from host side</span><br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;grid.x %d grid.y %d grid.z %d\\n&quot;</span>,grid.x,grid.y,grid.z);<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;block.x %d block.y %d block.z %d\\n&quot;</span>,block.x,block.y,block.z);<br>\t<br>    <span class=\"hljs-comment\">//check grid and block dimension from device side</span><br>    checkIndex&lt;&lt;&lt;grid, block&gt;&gt;&gt;();<br>    <br>    <span class=\"hljs-comment\">//reset device before you leave</span><br>    <span class=\"hljs-built_in\">cudaDeviceReset</span>();<br>    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>现在开始编译和运行这段程序：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc -arch=sm_20 checkDimension.cu -o check<br>./check<br></code></pre></div></td></tr></table></figure>\n\n<p>因为printf函数只支持Fermi及以上版本的GPU架构，所以必须添加-arch&#x3D;sm_20编译器选项。默认情况下，nvcc会产生支持最低版本GPU架构的代码。这个应用程序的运行结果如下。可以看到，每个线程都有自己的坐标，所有的线程都有相同的块维度和网格维度。</p>\n<p><img src=\"/2023/01/28/cuda006/image-20230129172501750.png\" alt=\"image-20230129172501750\"></p>\n<h3 id=\"3-从主机端和设备端访问网格-x2F-块变量\"><a href=\"#3-从主机端和设备端访问网格-x2F-块变量\" class=\"headerlink\" title=\"3.从主机端和设备端访问网格&#x2F;块变量\"></a>3.从主机端和设备端访问网格&#x2F;块变量</h3><p>区别主机端和设备端的网格和块变量的访问是很重要的。例如，声明一个主机端的块变量，你按如下定义它的坐标并对其进行访问：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">block.x,block.y,block.z<br></code></pre></div></td></tr></table></figure>\n\n<p>在设备端，你已经预定义了内置块变量的大小：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">blockDim.x,blockDim.y,blockDim.z<br></code></pre></div></td></tr></table></figure>\n\n<p>总之，在启动内核之前就定义了主机端的网格和块变量，并从主机端通过由x,y,z三个字段决定的矢量结构来访问它们。当内核启动时，可以使用内核中预初始化的内置变量。</p>\n<p>对于一个给定的数据大小，确定网格和块尺寸的一般步骤为：</p>\n<p>​\t-确定块的大小</p>\n<p>​\t-在已知数据大小和块大小的基础上计算网格维度</p>\n<p>要确定块尺寸，通常需要考虑：</p>\n<p>​\t-内核的性能特性</p>\n<p>​\t-GPU资源的限制</p>\n<p>代码清单2-3使用了一个一维网格和一个一维块来说明当块的大小改变时，网格的尺寸也会随之改变。</p>\n<p><strong>代码清单2-3 在主机上定义网格和块的大小（defineGridBlock.cu）</strong></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;cuda_runtime.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc, <span class=\"hljs-keyword\">char</span> **argv)</span></span>&#123;<br>    <span class=\"hljs-comment\">//define total data element</span><br>    <span class=\"hljs-keyword\">int</span> nElem = <span class=\"hljs-number\">1024</span>;<br>    <br>    <span class=\"hljs-comment\">//define grid and block structure</span><br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">block</span>\t<span class=\"hljs-params\">(<span class=\"hljs-number\">1024</span>)</span></span>;<br>    <span class=\"hljs-function\">dim3 <span class=\"hljs-title\">grid</span> <span class=\"hljs-params\">((nElem+block.x<span class=\"hljs-number\">-1</span>)/block.x)</span></span>;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;grid.x %d block.x %d \\n&quot;</span>,grid.x, block.x);<br>    <br>    <span class=\"hljs-comment\">//reset block</span><br>    block.x = <span class=\"hljs-number\">512</span>;<br>    grid.x = (nElem+block.x<span class=\"hljs-number\">-1</span>)/block.x;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;grid.x %d block.x %d \\n&quot;</span>,grid.x, block.x);<br>    <br>    <span class=\"hljs-comment\">//reset block</span><br>    block.x = <span class=\"hljs-number\">256</span>;<br>    grid.x = (nElem+block.x<span class=\"hljs-number\">-1</span>)/block.x;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;grid.x %d block.x %d \\n&quot;</span>,grid.x, block.x);<br>    <br>    <span class=\"hljs-comment\">//reset block</span><br>    block.x = <span class=\"hljs-number\">128</span>;<br>    grid.x = (nElem+block.x<span class=\"hljs-number\">-1</span>)/block.x;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;grid.x %d block.x %d \\n&quot;</span>,grid.x, block.x);<br>    <br>    <span class=\"hljs-comment\">//reset device before you leave</span><br>    <span class=\"hljs-built_in\">cudaDeviceReset</span>();<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>用下列命令编译和运行这段程序：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc defineGridBlock.cu\t-o block<br>./block<br></code></pre></div></td></tr></table></figure>\n\n<p>下面是一个输出示例。由于应用程序中的数据大小是固定的，因此当块的大小发生改变时，相应的网格尺寸也会发生改变。</p>\n<p><img src=\"/2023/01/28/cuda006/image-20230129174300533.png\" alt=\"image-20230129174300533\"></p>\n<h3 id=\"4-线程层次结构\"><a href=\"#4-线程层次结构\" class=\"headerlink\" title=\"4.线程层次结构\"></a>4.线程层次结构</h3><p>CUDA的特点之一就是通过编程模型揭示了一个两层的线程层次结构。由于一个内核启动的网格和块的维数会影响性能，这一结构为程序员优化程序提供了一个额外的途径。</p>\n<p>网格和块的维度存在几个限制因素，对于块大小的一个主要限制因素就是可利用的计算资源，如寄存器，共享内存等。某些限制可以通过查询GPU设备撤回。</p>\n<p>网格和块从逻辑上代表了一个核函数的线程层次结构。</p>\n<h3 id=\"5-参考资料\"><a href=\"#5-参考资料\" class=\"headerlink\" title=\"5.参考资料\"></a>5.参考资料</h3><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/01/17/cuda005/",
            "url": "https://xingyuanjie.top/2023/01/17/cuda005/",
            "title": "CUDA内存管理",
            "date_published": "2023-01-17T14:03:10.000Z",
            "content_html": "<h3 id=\"1-内存管理\"><a href=\"#1-内存管理\" class=\"headerlink\" title=\"1.内存管理\"></a>1.内存管理</h3><p>CUDA编程模型假设系统是由一个主机和一个设备组成的，而且各自拥有独立的内存。核函数是在设备上运行的。为使你拥有充分的控制权并使系统达到最佳性能，CUDA运行时负责分配与释放设备内存，并且在主机内存和设备内存之间传输数据。表2-1列出了标准的C函数以及相应地针对内存操作的CUDA C函数。</p>\n<p>用于执行GPU内存分配的是cudaMalloc函数，其函数原型为：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">cudaError_t <span class=\"hljs-title\">cudaMalloc</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>** devPtr, <span class=\"hljs-keyword\">size_t</span> size)</span></span><br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/01/17/cuda005/image-20230117223254853.png\" alt=\"image-20230117223254853\"></p>\n<p>该函数负责向设备分配一定字节的线性内存，并以devPtr的形式返回指向所分配内存的指针。cudaMalloc与标准C语言中的malloc函数几乎一样，只是此函数在GPU的内存里分配内存。通过充分保持与标准C语言运行库中的接口一致性，可以实现CUDA应用程序的轻松接入。</p>\n<p>cudaMemcpy函数负责主机和设备之间的数据传输，其函数原型为：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">cudaError_t <span class=\"hljs-title\">cudaMencpy</span><span class=\"hljs-params\">( <span class=\"hljs-keyword\">void</span>* dst, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">void</span>* src, <span class=\"hljs-keyword\">size_t</span> count, cudaMemcpyKind kind)</span></span><br></code></pre></div></td></tr></table></figure>\n\n<p>此函数从src指向的源存储区复制一定数量的字节到dst指向的目标存储区。复制方向由kind指定，其中的kind有以下几种。</p>\n<ol>\n<li>cudaMemcpyHostToHost</li>\n<li>cudaMemcpyHostToDevice</li>\n<li>cudaMemcpyDeviceToHost</li>\n<li>cudaMemcpyDeviceToDevice</li>\n</ol>\n<p>这个函数以同步方式执行，因为在cudaMemcpy函数返回以及传输操作完成之前主机应用程序是阻塞的。除了内核启动之外的CUDA调用都会返回一个错误的枚举类型cudaError_t。如果GPU内存分配成功，函数返回：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">cudaSuccess<br></code></pre></div></td></tr></table></figure>\n\n<p>否则返回：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">cudaErrorMemoryAllocation<br></code></pre></div></td></tr></table></figure>\n\n<p>可以使用以下CUDA运行时函数将错误代码转化为可读的错误消息：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">char</span>* <span class=\"hljs-title\">cudaGetErroeString</span><span class=\"hljs-params\">(cudaError_t error)</span></span><br></code></pre></div></td></tr></table></figure>\n\n<p>cudaGetErrorString函数和C语言中的strerror函数类似。</p>\n<p>CUDA编程模型从GPU架构中抽象出一个内存层次结构，图2-3所示的是一个简化的GPU内存结构，它主要包含两部分：全局内存和共享内存。</p>\n<h3 id=\"2-内存层次结构\"><a href=\"#2-内存层次结构\" class=\"headerlink\" title=\"2.内存层次结构\"></a>2.内存层次结构</h3><p>CUDA编程模型最显著的一个特点就是揭示了内存层次结构。每一个GPU设备都有用于不同用途的存储类型。</p>\n<p>在GPU内存层次结构中，最主要的两种内存是全局内存和共享内存。全局类似于CPU的系统内存，而共享内存类似于CPU的缓存。然而GPU的共享内存可以由CUDA C的内核直接控制。</p>\n<p><img src=\"/2023/01/17/cuda005/image-20230128140743600.png\" alt=\"image-20230128140743600\"></p>\n<p>下面，我们将通过一个简单的两个数组相加的例子来学习如何在主机和设备之间进行数据传输，以及如何使用CUDA C编程。如图2-4所示，数组a的第一个元素与数组b的第一个元素相加，得到的结果作为数组c的第一个元素，重复这个过程直到数组中的所有元素都进行了一次运算。‘</p>\n<p><img src=\"/2023/01/17/cuda005/image-20230128141008674.png\" alt=\"image-20230128141008674\"></p>\n<p>首先，执行主机端代码使两个数组相加（如代码清单2-1所示）。</p>\n<h4 id=\"代码清单2-1-sumArraysOnHost-c\"><a href=\"#代码清单2-1-sumArraysOnHost-c\" class=\"headerlink\" title=\"代码清单2-1 sumArraysOnHost.c\"></a>代码清单2-1 sumArraysOnHost.c</h4><figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdlib.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;string.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;time.h&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">sumArraysOnHost</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *A, <span class=\"hljs-keyword\">float</span> *B, <span class=\"hljs-keyword\">float</span> *C, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> N)</span></span>&#123;<br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> idx=<span class=\"hljs-number\">0</span>;idx&lt;n;idx++)<br>        C[idx]=A[idx]+B[idx];<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">initialData</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">float</span> *ip,<span class=\"hljs-keyword\">int</span> size)</span></span>&#123;<br>    <span class=\"hljs-comment\">//generate different seed for random number time_t t;</span><br>    <span class=\"hljs-built_in\">srand</span>((<span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span>) <span class=\"hljs-built_in\">time</span> (&amp;t));<br>    <br>    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i=<span class=\"hljs-number\">0</span>;i&lt;size;i++)&#123;<br>        ip[i]=(<span class=\"hljs-keyword\">float</span>)(<span class=\"hljs-built_in\">rand</span>() &amp; OxFF)/<span class=\"hljs-number\">10.0f</span>;<br>    &#125;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc, <span class=\"hljs-keyword\">char</span> **argv)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> nElem =<span class=\"hljs-number\">1024</span>;<br>    <span class=\"hljs-keyword\">size_t</span> nBytes = nElem *<span class=\"hljs-built_in\"><span class=\"hljs-keyword\">sizeof</span></span>(<span class=\"hljs-keyword\">float</span>);<br>    <br>    <span class=\"hljs-keyword\">float</span> *h_A, *h_B, *h_C;<br>    h_A = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    h_B = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    h_C = (<span class=\"hljs-keyword\">float</span> *)<span class=\"hljs-built_in\">malloc</span>(nBytes);<br>    <br>    <span class=\"hljs-built_in\">initialData</span>(h_A, nElem);<br>    <span class=\"hljs-built_in\">initialData</span>(h_B, nElem);<br>    <br>    <span class=\"hljs-built_in\">sumArraysOnHost</span>(h_A, h_B, h_C, nElem);<br>    <br>    <span class=\"hljs-built_in\">free</span>(h_A);<br>    <span class=\"hljs-built_in\">free</span>(h_B);<br>    <span class=\"hljs-built_in\">free</span>(h_C);<br>    <br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br><br></code></pre></div></td></tr></table></figure>\n\n<p>这是一个纯C语言编写的程序，你可以用C语言编译器进行编译，也可以像下面这样用nvcc进行编译。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc -Xcompiler -std=c99 sumArraysOnHost.c -o sum<br>./sum<br></code></pre></div></td></tr></table></figure>\n\n<p>nvcc封装了几种内部编译工具，CUDA编译器允许通过命令行选项在不同阶段启动不同的工具完成编译工作。-Xcompiler用于指定命令行选项是指向C编译器还是预处理器。在前面的例子中，将-std&#x3D;c99传递给编译器，因为这里的C程序是按照C99标准编写的。</p>\n<p>现在，你可以在GPU上修改代码来进行数组加法运算，用cudaMalloc在GPU上申请内存。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">float</span> *h_A, *h_B, *h_C;<br><span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_A, nBytes);<br><span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_B, nBytes);<br><span class=\"hljs-built_in\">cudaMalloc</span>((<span class=\"hljs-keyword\">float</span>**)&amp;d_C, nBytes);<br></code></pre></div></td></tr></table></figure>\n\n<p>使用cudaMemcpy函数把数据从主机内存拷贝到GPU的全局内存中，参考cudaMemcpyHostToDevice指定数据拷贝方向。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">cudaMemcpy</span>(d_A, h_A, nBytes, cudaMemcpyHostToDevice);<br><span class=\"hljs-built_in\">cudaMemcpy</span>(d_B, h_B, nBytes, cudaMemcpyHostToDevice);<br></code></pre></div></td></tr></table></figure>\n\n<p>当数据被转移到GPU的全局内存后，主机端调用核函数在GPU上进行数组求和。一旦内核被调用，控制权立刻被传回主机，这样的话，当核函数在GPU上运行时，主机可以执行其他函数。因此，内核与主机是异步的。</p>\n<p>当内核在GPU上完成了对所有数组元素的处理后，其结果将以数组d_C的形式存储在GPU的全局内存中，然后用cudaMemcpy函数把结果从GPU复制回到主机的数组gpuRef中。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">cudaMemcpy</span>(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);<br></code></pre></div></td></tr></table></figure>\n\n<p>cudaMemcpy的调用会导致主机运行阻塞。cudaMemcpyDeviceToHost的作用就是将存储在GPU上的数组d_C中的结果复制到gpuRef中。最后，调用cudaFree释放GPU的内存。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">cudaFree</span>(d_A);<br><span class=\"hljs-built_in\">cudaFree</span>(d_B);<br><span class=\"hljs-built_in\">cudaFree</span>(d_C);<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"3-不同的存储空间\"><a href=\"#3-不同的存储空间\" class=\"headerlink\" title=\"3.不同的存储空间\"></a>3.不同的存储空间</h3><p>使用CUDA C进行编程的人最常犯的错误就是对不同内存空间的不恰当引用。对于在GPU上被分配的内存来说，设备指针在主机代码中可能并没有被引用。如果你执行了错误的内存分配，如：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">gpuRef = d_C<br></code></pre></div></td></tr></table></figure>\n\n<p>而不是用：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\">cudaMemcpy</span>(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);<br></code></pre></div></td></tr></table></figure>\n\n<p>应用程序在运行时将会崩溃。</p>\n<p>为了避免这类错误，CUDA6.0提出了统一寻址，使用一个指针来访问CPU和GPU的内存</p>\n<h3 id=\"4-参考资料\"><a href=\"#4-参考资料\" class=\"headerlink\" title=\"4.参考资料\"></a>4.参考资料</h3><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/01/17/cuda004/",
            "url": "https://xingyuanjie.top/2023/01/17/cuda004/",
            "title": "CUDA编程结构",
            "date_published": "2023-01-17T13:36:04.000Z",
            "content_html": "<h2 id=\"CUDA编程结构\"><a href=\"#CUDA编程结构\" class=\"headerlink\" title=\"CUDA编程结构\"></a>CUDA编程结构</h2><p>CUDA编程模型使用由C语言扩展生成的注释代码在异构计算系统中执行应用程序。</p>\n<p>在一个异构环境中包含多个CPU和GPU，每个GPU和CPU的内存都由一条PCI-Express总线分隔开。因此，需要注意区别以下内容。</p>\n<ol>\n<li>主机：CPU及其内存（主机内存）</li>\n<li>设备：GPU及其内存（设备内存）</li>\n</ol>\n<p>为了清楚地指明不同的内存空间，在本书的示例代码中，主机内存中的变量名以h__为前缀，设备内存中的变量名以d__为前缀。</p>\n<p>从CUDA6.0开始，NVDIA提出了名为“统一寻址”（Unified Memory）的编程模型的改进，它连接了主机内存和设备内存空间，可使用单个指针访问CPU和GPU内存，无须彼此之间手动拷贝数据。现在，重要的是应学会如何为主机和设备分配内存空间以及如何在CPU和GPU之间拷贝共享数据。这种程序员管理模式控制下的内存和数据可以优化应用程序并实现硬件系统利用率的最大化。</p>\n<p>内核（kernel）是CUDA编程模型的一个重要组成部分，其代码在GPU上运行。作为一个开发人员，你可以串行的执行核函数。在此背景下，CUDA的调度管理程序员在GPU线程上编写核函数。在主机上，基于应用程序数据以及GPU的性能定义如何让设备实现算法功能。这样做的目的是使你专注于算法的逻辑（通过编写串行代码），且在创建和管理大量的GPU线程时不必拘泥于细节。</p>\n<p>多数情况下，主机可以独立地对设备进行操作。内核一旦被启动，端粒权立刻返回给主机，释放CPU来执行由设备上运行的并行代码实现的额外的任务。CUDA编程模型主要是异步的，因此在GPU上进行的运算可以与主机-设备通信重叠。一个典型的CUDA程序包括由并行代码互补的串行代码。如图2-2所示，串行代码（及任务并行代码）在主机CPU上执行，而并行代码在GPU上执行。主机代码按照ANSI C标准进行编写，而设备代码使用CUDA C进行编写。你可以将所有的代码统一放在一个源文件中，也可以使用多个源文件来构建应用程序和库。NVIDIA的C编译器(nvcc)为主机和设备生成可执行代码。</p>\n<p>一个典型的CUDA程序实现流程遵循以下模式</p>\n<ol>\n<li>把数据从CPU内存拷贝到GPU内存</li>\n<li>调用核函数对存储在GPU内存中的数据进行操作</li>\n<li>将数据从GPU内存传送回到CPU内存</li>\n</ol>\n<p>首先，你要学习的是内存管理及主机和设备之间的数据传输。</p>\n<p><img src=\"/2023/01/17/cuda004/image-20230117220146068.png\" alt=\"image-20230117220146068\"></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/01/17/cuda003/",
            "url": "https://xingyuanjie.top/2023/01/17/cuda003/",
            "title": "CUDA编程模型概述",
            "date_published": "2023-01-17T12:29:01.000Z",
            "content_html": "<h2 id=\"CUDA编程模型概述\"><a href=\"#CUDA编程模型概述\" class=\"headerlink\" title=\"CUDA编程模型概述\"></a>CUDA编程模型概述</h2><p>CUDA编程模型提供了一个计算机架构抽象作为应用程序和其可用硬件之间的桥梁。图2-1说明了程序和编程模型实现之间的抽象结构的重要。通信抽象是程序与编程模型实现之间的分界线，它通过专业的硬件原语和操作系统的编译器或库来实现。利用编程模型所编写的程序指定了程序的各组成部分是如何共享信息及相互协作的。编程模型从逻辑上提供了一个特定的计算机架构，通常它体现在编程语言或编程环境中。</p>\n<p><img src=\"/2023/01/17/cuda003/image-20230117203406633.png\" alt=\"image-20230117203406633\"></p>\n<p>除了与其他并行编程模型共有的抽象外，CUDA编程模型还利用GPU架构的计算能力提供了以下几个特有功能。</p>\n<ol>\n<li>一种通过层次结构在GPU中组织线程的方法</li>\n<li>一种通过层次结构在GPU中访问内存的方法</li>\n</ol>\n<p>以程序员的角度可以从以下几个不同的层面来看待并行计算。</p>\n<ol>\n<li>领域层</li>\n<li>逻辑层</li>\n<li>硬件层</li>\n</ol>\n<p>在编程与算法设计的过程中，你最关心的应是在领域层如何解析数据和函数，以便在并行环境中能正确，高效地解决问题。当进入编程阶段，你的关注点应转向如何组织并发线程。在这个阶段，你需要从逻辑层面来思考，以确保你的线程和计算能正确地解决问题。在C语言并行编程中，需要使用pthreads或OpenMP技术来显式地管理线程。CUDA提出了一个线程层次结构抽象的概念，以允许控制线程行为。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/01/16/cuda002/",
            "url": "https://xingyuanjie.top/2023/01/16/cuda002/",
            "title": "CUDA:一种异构计算平台",
            "date_published": "2023-01-16T09:46:48.000Z",
            "content_html": "<h2 id=\"CUDA-一种异构计算平台\"><a href=\"#CUDA-一种异构计算平台\" class=\"headerlink\" title=\"CUDA:一种异构计算平台\"></a>CUDA:一种异构计算平台</h2><h3 id=\"1-CUDA的简单介绍\"><a href=\"#1-CUDA的简单介绍\" class=\"headerlink\" title=\"1.CUDA的简单介绍\"></a>1.CUDA的简单介绍</h3><p>CUDA是一种通用的并行计算平台和编程模型，它利用NVIDIA GPU中的并行计算引擎能够有效地解决复杂的计算问题。通过使用CUDA，你可以像在CPU上，通过GPU来进行计算。</p>\n<p>CUDA平台可以通过CUDA加速库，编译器指令，应用编程接口以及行业标准程序语言的扩展（包括C,C++,Fortran，Python，如图1-12所示）来使用。</p>\n<p>CUDA C是标准ANSI C语言的一个扩展，它带有的少数语言扩展功能使异构编程成为可能，同时也能通过API来管理设备，内存和其他任务。CUDA还是一个可扩展的编程模型，它使程序能对有不同数量核的GPU明显地扩展其并行性，同时对熟悉C编程语言的程序员来说也比较容易上手。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116175503342.png\" alt=\"image-20230116175503342\"></p>\n<p>CUDA提供了两层API来管理GPU设备和组织线程，如图1-13所示。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116175610403.png\" alt=\"image-20230116175610403\"></p>\n<p>-CUDA驱动API</p>\n<p>-CUDA运行时API</p>\n<p>驱动API是一种低级API，它相对来说较难编程，但是它对于在GPU设备使用上提供了更多的控制。运行时API是一个高级API，他在驱动API的上层实现。每个运行时API函数都被分解为更多传给驱动API的基本运算。</p>\n<h3 id=\"2-运行时API与驱动API\"><a href=\"#2-运行时API与驱动API\" class=\"headerlink\" title=\"2.运行时API与驱动API\"></a>2.运行时API与驱动API</h3><p>运行时API和驱动API之间没有明显的性能差异。在设备端，内核是如何使用内存以及你是如何组织线程的，对性能有更显著的影响。</p>\n<p>这两种API是相互排斥的，你必须使用两者之一，从两者中混合函数调用是不可能的。本书中所有例子都使用运行时API。</p>\n<p>一个CUDA程序包含了以下两个部分的混合。</p>\n<p>-在CPU上运行的主机代码</p>\n<p>-在GPU上运行的设备代码</p>\n<p>NVIDIA的CUDA nvcc编译器在编译过程中将设备代码从主机代码中分离出来。如图1-14所示，主机代码是标准的C代码，使用C编译器进行编译。设备代码，也就是核函数，是用扩展的带有标记数据并行函数关键字的CUDA C语言编写的。设备代码通过nvcc进行编译。在链接阶段，在内核程序调用和显示GPU设备操作中添加CUDA运行时库。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116180725596.png\" alt=\"image-20230116180725596\"></p>\n<p>CUDA nvcc编译器是以广泛使用LLVM开源编译系统为基础的。在GPU加速器的支持下，通过使用CUDA编译器SDK，你可以创建或扩展编程语言，如图1-15所示。</p>\n<p>CUDA平台也是支持多样化并行计算生态系统的基础，如图1-26所示。现在，随着越来越多的公司可以提供全球性的工具，服务和解决方案，CUDA生态系统迅速成长。如果你想在GPU上建立你的应用程序，强化GPU性能最简单方式是使用CUDA工具包（cuda-toolkit），它为C和C++开发人员提供了一个综合的开发环境。CUDA工具包包括编译器，数学库，以及调式和优化应用程序性能的工具。同时提供了代码样例，编程指南，用户手册，API参考文档和其他帮助你入门的文档。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116181439404.png\" alt=\"image-20230116181439404\"></p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116181447616.png\" alt=\"image-20230116181447616\"></p>\n<h3 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h3><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/01/16/cuda001/",
            "url": "https://xingyuanjie.top/2023/01/16/cuda001/",
            "title": "CUDA用GPU输出Hello World",
            "date_published": "2023-01-16T08:58:39.000Z",
            "content_html": "<h2 id=\"用GPU输出Hello-World\"><a href=\"#用GPU输出Hello-World\" class=\"headerlink\" title=\"用GPU输出Hello World\"></a>用GPU输出Hello World</h2><h3 id=\"1-检查环境\"><a href=\"#1-检查环境\" class=\"headerlink\" title=\"1.检查环境\"></a>1.检查环境</h3><p>学习一个新编程语言的最好方式就是使用这种语言来编写程序。在本节，你将开始编写在GPU上运行的第一个内核代码。像其他任何编程语言一样编写GPU上的第一个程序是输出字符串“Hello World”。</p>\n<p>如果这是你第一次使用CUDA,在Linux系统中，你可以想使用以下命令来检查CUDA编译器是否正确安装：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">which nvcc<br></code></pre></div></td></tr></table></figure>\n\n<p>通常的结果可能是</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">/usr/local/cuda/bin/nvcc<br></code></pre></div></td></tr></table></figure>\n\n<p>你还需要检查你的机器上是否安装了GPU加速卡。对吃你可以在Linux系统上使用以下命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">ls -l /dev/nv*<br></code></pre></div></td></tr></table></figure>\n\n<p>通常的结果是：</p>\n<p><img src=\"/2023/01/16/cuda001/image-20230116170920773.png\" alt=\"image-20230116170920773\"></p>\n<p>在这个例子中，你发现了两个GPU卡（不同的用户配置可能有所不同，因此显示结果会有所差异）。</p>\n<h3 id=\"2-第一个CUDA-C程序\"><a href=\"#2-第一个CUDA-C程序\" class=\"headerlink\" title=\"2.第一个CUDA C程序\"></a>2.第一个CUDA C程序</h3><p>现在你要准备好写你的第一个CUDA C程序。写一个CUDA C程序，你需要以下几个步骤：</p>\n<ol>\n<li>用专用扩展名.cu来创建一个源文件。</li>\n<li>使用CUDA nvcc编译器来编译程序。</li>\n<li>从命令行运行可执行文件，这个文件有可在GPU上运行的内核代码。</li>\n</ol>\n<p>首先，我们编写一个C语言程序来输出“Hello World”,如下所示：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from CPU!\\n&quot;</span>);<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>把代码保存到hello.cu中，然后使用nvcc编译器来编译。CUDA nvcc编译器和gcc编译器及其他编译器有相似的语义</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc hello.cu -o hello<br></code></pre></div></td></tr></table></figure>\n\n<p>如果你运行可执行文件hello，将会输出：</p>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs angelscript\">Hello World <span class=\"hljs-keyword\">from</span> CPU!<br></code></pre></div></td></tr></table></figure>\n\n<p>接下来，编写一个内核函数，命名为helloFromGPU，用它来输出字符串“Hello World from GPU!”。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">helloFromGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from GPU!\\n&quot;</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>修饰符__global__告诉编译器这个函数将会从CPU中调用，然后在GPU上执行。用下面代码启用内核函数。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">helloFromGPU&lt;&lt;&lt;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">10</span>&gt;&gt;&gt;();<br></code></pre></div></td></tr></table></figure>\n\n<p>三重尖括号意味着从主线程到设备端代码的调用。一个内核函数通过一组线程来执行，所有线程执行相同的代码。三重尖括号里面的参数是执行配置，用来说明使用多少线程来执行内核函数。在这个例子中，有10个GPU线程被调用。综上所述，得到代码清单1-1所示的程序。</p>\n<h3 id=\"3-代码清单1-1Hello-World-from-GPU-hello-cu\"><a href=\"#3-代码清单1-1Hello-World-from-GPU-hello-cu\" class=\"headerlink\" title=\"3.代码清单1-1Hello World from GPU! (hello.cu)\"></a>3.代码清单1-1Hello World from GPU! (hello.cu)</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">helloFromGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from GPU!\\n&quot;</span>);<br>&#125;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-comment\">//hello from cpu</span><br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from CPU!\\n&quot;</span>);<br>    <br>    <br>    helloFromGPU&lt;&lt;&lt;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">10</span>&gt;&gt;&gt;();<br>    <span class=\"hljs-built_in\">cudaDeviceReset</span>();<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>函数cudaDeviceRest（）用来显式地释放和清空当前进程中与当前设别有关的所有资源。如下所示，在nvcc命令行中使用-arch sm_20进行编译：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc -arch sm_20 hello.cu -o hello<br></code></pre></div></td></tr></table></figure>\n\n<p>开关语句-arch sm_20使编译器为Fermi架构生成设备代码。运行这个可执行文件，它将输出10条字符串“Hello World from CPU!”，每个线程输出一条。</p>\n<p><img src=\"/2023/01/16/cuda001/image-20230116173446169.png\" alt=\"image-20230116173446169\"></p>\n<h3 id=\"4-一个典型的CUDA编程结构包括5个主要步骤\"><a href=\"#4-一个典型的CUDA编程结构包括5个主要步骤\" class=\"headerlink\" title=\"4.一个典型的CUDA编程结构包括5个主要步骤\"></a>4.一个典型的CUDA编程结构包括5个主要步骤</h3><ol>\n<li>分配GPU内存</li>\n<li>从CPU内存中拷贝数据到GPU内存</li>\n<li>调用CUDA内核函数来完成程序指定的运算</li>\n<li>将数据从GPU拷回CPU内存</li>\n<li>释放GPU内存空间</li>\n</ol>\n<p>在hello.cu中，你只看到了第三步：调用内核。</p>\n<h3 id=\"5-参考资料\"><a href=\"#5-参考资料\" class=\"headerlink\" title=\"5.参考资料\"></a>5.参考资料</h3><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        }
    ]
}