{
    "version": "https://jsonfeed.org/version/1",
    "title": "Amicoyuan • All posts by \"cuda\" tag",
    "description": "",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2023/01/16/cuda002/",
            "url": "http://example.com/2023/01/16/cuda002/",
            "title": "CUDA:一种异构计算平台",
            "date_published": "2023-01-16T09:46:48.000Z",
            "content_html": "<h2 id=\"CUDA-一种异构计算平台\"><a href=\"#CUDA-一种异构计算平台\" class=\"headerlink\" title=\"CUDA:一种异构计算平台\"></a>CUDA:一种异构计算平台</h2><h3 id=\"1-CUDA的简单介绍\"><a href=\"#1-CUDA的简单介绍\" class=\"headerlink\" title=\"1.CUDA的简单介绍\"></a>1.CUDA的简单介绍</h3><p>CUDA是一种通用的并行计算平台和编程模型，它利用NVIDIA GPU中的并行计算引擎能够有效地解决复杂的计算问题。通过使用CUDA，你可以像在CPU上，通过GPU来进行计算。</p>\n<p>CUDA平台可以通过CUDA加速库，编译器指令，应用编程接口以及行业标准程序语言的扩展（包括C,C++,Fortran，Python，如图1-12所示）来使用。</p>\n<p>CUDA C是标准ANSI C语言的一个扩展，它带有的少数语言扩展功能使异构编程成为可能，同时也能通过API来管理设备，内存和其他任务。CUDA还是一个可扩展的编程模型，它使程序能对有不同数量核的GPU明显地扩展其并行性，同时对熟悉C编程语言的程序员来说也比较容易上手。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116175503342.png\" alt=\"image-20230116175503342\"></p>\n<p>CUDA提供了两层API来管理GPU设备和组织线程，如图1-13所示。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116175610403.png\" alt=\"image-20230116175610403\"></p>\n<p>-CUDA驱动API</p>\n<p>-CUDA运行时API</p>\n<p>驱动API是一种低级API，它相对来说较难编程，但是它对于在GPU设备使用上提供了更多的控制。运行时API是一个高级API，他在驱动API的上层实现。每个运行时API函数都被分解为更多传给驱动API的基本运算。</p>\n<h3 id=\"2-运行时API与驱动API\"><a href=\"#2-运行时API与驱动API\" class=\"headerlink\" title=\"2.运行时API与驱动API\"></a>2.运行时API与驱动API</h3><p>运行时API和驱动API之间没有明显的性能差异。在设备端，内核是如何使用内存以及你是如何组织线程的，对性能有更显著的影响。</p>\n<p>这两种API是相互排斥的，你必须使用两者之一，从两者中混合函数调用是不可能的。本书中所有例子都使用运行时API。</p>\n<p>一个CUDA程序包含了以下两个部分的混合。</p>\n<p>-在CPU上运行的主机代码</p>\n<p>-在GPU上运行的设备代码</p>\n<p>NVIDIA的CUDA nvcc编译器在编译过程中将设备代码从主机代码中分离出来。如图1-14所示，主机代码是标准的C代码，使用C编译器进行编译。设备代码，也就是核函数，是用扩展的带有标记数据并行函数关键字的CUDA C语言编写的。设备代码通过nvcc进行编译。在链接阶段，在内核程序调用和显示GPU设备操作中添加CUDA运行时库。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116180725596.png\" alt=\"image-20230116180725596\"></p>\n<p>CUDA nvcc编译器是以广泛使用LLVM开源编译系统为基础的。在GPU加速器的支持下，通过使用CUDA编译器SDK，你可以创建或扩展编程语言，如图1-15所示。</p>\n<p>CUDA平台也是支持多样化并行计算生态系统的基础，如图1-26所示。现在，随着越来越多的公司可以提供全球性的工具，服务和解决方案，CUDA生态系统迅速成长。如果你想在GPU上建立你的应用程序，强化GPU性能最简单方式是使用CUDA工具包（cuda-toolkit），它为C和C++开发人员提供了一个综合的开发环境。CUDA工具包包括编译器，数学库，以及调式和优化应用程序性能的工具。同时提供了代码样例，编程指南，用户手册，API参考文档和其他帮助你入门的文档。</p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116181439404.png\" alt=\"image-20230116181439404\"></p>\n<p><img src=\"/2023/01/16/cuda002/image-20230116181447616.png\" alt=\"image-20230116181447616\"></p>\n<h3 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h3><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        },
        {
            "id": "http://example.com/2023/01/16/cuda001/",
            "url": "http://example.com/2023/01/16/cuda001/",
            "title": "CUDA用GPU输出Hello World",
            "date_published": "2023-01-16T08:58:39.000Z",
            "content_html": "<h2 id=\"用GPU输出Hello-World\"><a href=\"#用GPU输出Hello-World\" class=\"headerlink\" title=\"用GPU输出Hello World\"></a>用GPU输出Hello World</h2><h3 id=\"1-检查环境\"><a href=\"#1-检查环境\" class=\"headerlink\" title=\"1.检查环境\"></a>1.检查环境</h3><p>学习一个新编程语言的最好方式就是使用这种语言来编写程序。在本节，你将开始编写在GPU上运行的第一个内核代码。像其他任何编程语言一样编写GPU上的第一个程序是输出字符串“Hello World”。</p>\n<p>如果这是你第一次使用CUDA,在Linux系统中，你可以想使用以下命令来检查CUDA编译器是否正确安装：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">which nvcc<br></code></pre></div></td></tr></table></figure>\n\n<p>通常的结果可能是</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">/usr/local/cuda/bin/nvcc<br></code></pre></div></td></tr></table></figure>\n\n<p>你还需要检查你的机器上是否安装了GPU加速卡。对吃你可以在Linux系统上使用以下命令：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">ls -l /dev/nv*<br></code></pre></div></td></tr></table></figure>\n\n<p>通常的结果是：</p>\n<p><img src=\"/2023/01/16/cuda001/image-20230116170920773.png\" alt=\"image-20230116170920773\"></p>\n<p>在这个例子中，你发现了两个GPU卡（不同的用户配置可能有所不同，因此显示结果会有所差异）。</p>\n<h3 id=\"2-第一个CUDA-C程序\"><a href=\"#2-第一个CUDA-C程序\" class=\"headerlink\" title=\"2.第一个CUDA C程序\"></a>2.第一个CUDA C程序</h3><p>现在你要准备好写你的第一个CUDA C程序。写一个CUDA C程序，你需要以下几个步骤：</p>\n<ol>\n<li>用专用扩展名.cu来创建一个源文件。</li>\n<li>使用CUDA nvcc编译器来编译程序。</li>\n<li>从命令行运行可执行文件，这个文件有可在GPU上运行的内核代码。</li>\n</ol>\n<p>首先，我们编写一个C语言程序来输出“Hello World”,如下所示：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from CPU!\\n&quot;</span>);<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>把代码保存到hello.cu中，然后使用nvcc编译器来编译。CUDA nvcc编译器和gcc编译器及其他编译器有相似的语义</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc hello.cu -o hello<br></code></pre></div></td></tr></table></figure>\n\n<p>如果你运行可执行文件hello，将会输出：</p>\n<figure class=\"highlight angelscript\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs angelscript\">Hello World <span class=\"hljs-keyword\">from</span> CPU!<br></code></pre></div></td></tr></table></figure>\n\n<p>接下来，编写一个内核函数，命名为helloFromGPU，用它来输出字符串“Hello World from GPU!”。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">helloFromGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from GPU!\\n&quot;</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>修饰符__global__告诉编译器这个函数将会从CPU中调用，然后在GPU上执行。用下面代码启用内核函数。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">helloFromGPU&lt;&lt;&lt;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">10</span>&gt;&gt;&gt;();<br></code></pre></div></td></tr></table></figure>\n\n<p>三重尖括号意味着从主线程到设备端代码的调用。一个内核函数通过一组线程来执行，所有线程执行相同的代码。三重尖括号里面的参数是执行配置，用来说明使用多少线程来执行内核函数。在这个例子中，有10个GPU线程被调用。综上所述，得到代码清单1-1所示的程序。</p>\n<h3 id=\"3-代码清单1-1Hello-World-from-GPU-hello-cu\"><a href=\"#3-代码清单1-1Hello-World-from-GPU-hello-cu\" class=\"headerlink\" title=\"3.代码清单1-1Hello World from GPU! (hello.cu)\"></a>3.代码清单1-1Hello World from GPU! (hello.cu)</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-function\">__global__ <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">helloFromGPU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>&#123;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from GPU!\\n&quot;</span>);<br>&#125;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;<br>    <span class=\"hljs-comment\">//hello from cpu</span><br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Hello World from CPU!\\n&quot;</span>);<br>    <br>    <br>    helloFromGPU&lt;&lt;&lt;<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">10</span>&gt;&gt;&gt;();<br>    <span class=\"hljs-built_in\">cudaDeviceReset</span>();<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>函数cudaDeviceRest（）用来显式地释放和清空当前进程中与当前设别有关的所有资源。如下所示，在nvcc命令行中使用-arch sm_20进行编译：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\">nvcc -arch sm_20 hello.cu -o hello<br></code></pre></div></td></tr></table></figure>\n\n<p>开关语句-arch sm_20使编译器为Fermi架构生成设备代码。运行这个可执行文件，它将输出10条字符串“Hello World from CPU!”，每个线程输出一条。</p>\n<p><img src=\"/2023/01/16/cuda001/image-20230116173446169.png\" alt=\"image-20230116173446169\"></p>\n<h3 id=\"4-一个典型的CUDA编程结构包括5个主要步骤\"><a href=\"#4-一个典型的CUDA编程结构包括5个主要步骤\" class=\"headerlink\" title=\"4.一个典型的CUDA编程结构包括5个主要步骤\"></a>4.一个典型的CUDA编程结构包括5个主要步骤</h3><ol>\n<li>分配GPU内存</li>\n<li>从CPU内存中拷贝数据到GPU内存</li>\n<li>调用CUDA内核函数来完成程序指定的运算</li>\n<li>将数据从GPU拷回CPU内存</li>\n<li>释放GPU内存空间</li>\n</ol>\n<p>在hello.cu中，你只看到了第三步：调用内核。</p>\n<h3 id=\"5-参考资料\"><a href=\"#5-参考资料\" class=\"headerlink\" title=\"5.参考资料\"></a>5.参考资料</h3><p>CUDA C编程权威指南 程润伟，Max Grossman(美)，Ty Mckercher </p>\n",
            "tags": [
                "CUDA"
            ]
        }
    ]
}