{
    "version": "https://jsonfeed.org/version/1",
    "title": "Amicoyuan • All posts by \"openmp\" tag",
    "description": "",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2023/01/14/openmp006/",
            "url": "http://example.com/2023/01/14/openmp006/",
            "title": "OpenMP生产者消费者问题(未完结)",
            "date_published": "2023-01-14T14:30:05.000Z",
            "content_html": "<h2 id=\"OpenMP生产者消费者问题\"><a href=\"#OpenMP生产者消费者问题\" class=\"headerlink\" title=\"OpenMP生产者消费者问题\"></a>OpenMP生产者消费者问题</h2><p><strong>本节将讨论一个不适合用parallel for指令或者for指令来并行化的问题。</strong></p>\n<h3 id=\"1-队列\"><a href=\"#1-队列\" class=\"headerlink\" title=\"1.队列\"></a>1.队列</h3><p>队列是一种抽象的数据结构，插入元素时将元素插入到队列“尾部”，而读取元素时，队列“头部”的元素被返回并从队列中被移除。队列可以看做是在超市中等待付款的消费者的抽象，队列中的元素是消费者。新的消费者到达时排在等待队列的尾部，下一个付款离开等待队列的是排在队列头部的消费者。</p>\n<p>当一个新的元素插入到队列的尾部时，通常称这个新的元素“入队”了；当一个元素从队列的头部被移除时，通常称这个元素“出队”了。</p>\n<p>队列在计算机科学中随处可见。例如，如果有多个进程，每个进程都试图向硬盘写入数据，为了确保每次只有一个进程在写硬盘，一种自然而然的方法是将进程组织为队列。换句话说，排在队列第一个的进程在当前进程结束对硬盘的使用后，第一个获得硬盘的访问权限；排在队列第二个的进程在排在队列第一个的进程使用完硬盘后获得硬盘的访问权限，依此类推。</p>\n<p>队列也是在多线程应用程序中经常使用到的数据结构。例如，我们有几个“生产者”线程和几个“消费者”线程。生产者线程“产生”对服务器数据的请求———例如当前股票的价格，而消费者线程通过发现和生成数据（例如，当前股票的价格）来“消费”请求。生产者线程将请求入队，而消费者线程将请求从队列中移除。在这个例子中，只有当消费者线程将请求的数据发送给生产者线程时，进程才会结束。</p>\n<h3 id=\"2-消息传递\"><a href=\"#2-消息传递\" class=\"headerlink\" title=\"2.消息传递\"></a>2.消息传递</h3><p>生产者和消费者问题模型的另外一个应用是在共享内存系统上实现消息传递。每一个线程有一个消息共享队列，当一个线程要向另一个线程“发送消息“时，他将消息放入目标线程的消息队列中。一个线程接受消息时只需从它的消息队列的头部取出消息。</p>\n<p>这里我们将实现一个简单的消息传递程序，在这个程序中，每个线程随机产生整数”消息“和消息的日志目标线程。当创建一条消息后，线程将消息加入到合适的消息队列中。当发送消息之后，该线程查看它自己的消息队列以获知它是否收到了消息，如果它收到了消息，它将从队首的消息出队并打印该消息。每个线程交替发送和接受消息，用户需要指定每个线程发送消息的数目。当一个线程发送完所有消息后，该线程不断接受消息直到所有的线程都已完成，此时所有的线程都结束了。每个线程的伪代码如下。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">for</span>(send_msgs = <span class=\"hljs-number\">0</span>; sent_msgs &lt; send_max ;sent_msgs++)&#123;<br>    <span class=\"hljs-built_in\">Send_msg</span>();<br>    <span class=\"hljs-built_in\">Try_receive</span>();<br>&#125;<br><br><span class=\"hljs-keyword\">while</span>(!<span class=\"hljs-built_in\">Done</span>())<br>    <span class=\"hljs-built_in\">Try_receive</span>();<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"3-发送消息\"><a href=\"#3-发送消息\" class=\"headerlink\" title=\"3.发送消息\"></a>3.发送消息</h3><p>需要注意的是，访问消息队列并将消息入队，可能是一个临界区。尽管我们还没有深入地研究如何实现消息队列，但我们很有可能需要用一个变量来跟踪队列的尾部。例如，使用一个单链表来实现消息队列，链表的尾部对应着队列的尾部。然后，为了有效地进行入队操作，需要存储指向链表尾部的指针，当一条新消息入队时，需要检查和更新这个队尾指针。如果两个线程试图同时进行这些操作，那么可能会丢失一条已经由其中一个线程入队的消息.（画张图能够有助于理解这种情况！）两个操作的结果会发生冲突，因此入队操作形成了临界区。</p>\n<p>Send_msg()函数的伪代码如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">mesg = <span class=\"hljs-built_in\">random</span>();<br>dest = <span class=\"hljs-built_in\">random</span>() % thread_count;<br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp critical</span><br><span class=\"hljs-built_in\">Enqueue</span>(queue,dest,my_rank.mesg);<br></code></pre></div></td></tr></table></figure>\n\n<p>注意在上面的实现中，允许线程向它自己发送消息。</p>\n<h3 id=\"4-接受消息\"><a href=\"#4-接受消息\" class=\"headerlink\" title=\"4.接受消息\"></a>4.接受消息</h3><p>接受消息的同步问题与发送消息有些不同。只有消息队列的拥有者（即目标线程）可以从给定的消息队列中获取消息。如果消息队列中至少有两条消息，那么只要每次只出队一条消息，那么出队操作和入队操作就不可能冲突。因此如果队列中至少有两条消息，通过跟踪队列的大小就可以避免任何同步（例如critical指令）</p>\n<p>现在的问题是如何存储队列大小。如果只使用一个变量来存储队列的大小，那么对该变量的操作会形成临界区。然而可以使用两个变量：enqueued和dequeued，那么队列中消息的个数（队列的大小）就为</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">queue_size = enqueued - dequeued<br></code></pre></div></td></tr></table></figure>\n\n<p>并且，唯一能够更新dequeued的线程是消息队列的拥有者。可以看到在一个线程使用enqueued计算队列大小queue_size的同时，另外一个线程可以更新enqueued。为了解释这种情况，假如进程q正在计算queue_size，那么它将可能得到enqueued新的或者旧的值。当queue_size实际值是1或者2时，线程q可能会得到queue_size是0或者1。但这只会引起程序一定的延迟，而不会引起程序错误。如果queue_size本应该是1，却误计算为0，那么线程q延迟一段时间后会试图重新计算队列的大小；如果queue_size本应该是2，却误计算为1，那么线程q将执行临界区指令，虽然这本来是不必要的。</p>\n<p>因此，可以按照如下的方式实现Try_receive:</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">queue_size = enqueued - dequeued;<br><span class=\"hljs-keyword\">if</span>(queue_size == <span class=\"hljs-number\">0</span>) <span class=\"hljs-keyword\">return</span>;<br>\t<span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(queue_size == <span class=\"hljs-number\">1</span>)<br>    \t<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp critical</span><br>    \t<span class=\"hljs-built_in\">Dequeue</span>(queue,&amp;src,&amp;mesg);<br>\t<span class=\"hljs-keyword\">else</span><br>    \t<span class=\"hljs-built_in\">Dequeue</span>(queue,&amp;src,&amp;mesg);<br>\t<span class=\"hljs-built_in\">Print_message</span>(src,mesg);<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"5-终止检测\"><a href=\"#5-终止检测\" class=\"headerlink\" title=\"5.终止检测\"></a>5.终止检测</h3><p>接下来，我们探讨如何实现Done函数。首先，我们给出一个”直接“的实现，但这个实现隐藏着问题：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">queue_size = enqueued - dequeued;<br><span class=\"hljs-keyword\">if</span>(queue_size == <span class=\"hljs-number\">0</span>)<br>    <span class=\"hljs-keyword\">return</span> True;<br><span class=\"hljs-keyword\">else</span><br>    <span class=\"hljs-keyword\">return</span> False;<br></code></pre></div></td></tr></table></figure>\n\n<p>如果线程u执行这段代码，那么很有可能有些线程，如线程v，在线程u计算出queue_size &#x3D; 0后向线程u发送一条消息。当然，线程u在得出queue_size &#x3D; 0后将终止，那么线程v发送给它的消息就永远不会被接受到。</p>\n<p>然而，在我们程序中，每个线程在执行完for循环后将不再发送任何消息。因此可以增加一个计数器done_sending，每个线程在for循环结束后将该计数器加1，Done的实现如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">queue_size = enqueued - dequeued;<br><span class=\"hljs-keyword\">if</span>(queue_size == <span class=\"hljs-number\">0</span> &amp;&amp; done_sending == thread_count)<br>    <span class=\"hljs-keyword\">return</span> TRUE;<br><span class=\"hljs-keyword\">else</span><br>    rerun FALSE;<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"6-启动\"><a href=\"#6-启动\" class=\"headerlink\" title=\"6.启动\"></a>6.启动</h3><p>当程序开始执行时，主线程将得到命令行参数并且分配一个数组空间给消息队列，每个线程对应着一个消息队列。由于每个线程可以向其他任意的下次线程发送消息，所以这个数组应该被所有线程共享，而且每个线程可以向任何一个消息队列插入一条消息。消息队列（至少）可以存储：</p>\n<ol>\n<li>消息列表</li>\n<li>队尾指针或索引</li>\n<li>队首指针或索引</li>\n<li>入队消息的数目</li>\n<li>出队消息的数目</li>\n</ol>\n<p>最好将队列存在消息队列的结构体中，为了减少参数传递时复制的开销，最好用指向结构体的指针数组来实现消息队列。因此，一旦主线程分配了队列数组，就可以使用parallel指令开始执行线程，每个线程可以为自己的队列分配存储空间。</p>\n<p>这里一个重要的问题是：一个或者多个线程可能在其他线程之前完成它的队列分配。如果这种情况出现了，那么完成分配的线程可能会试图开始向那些还没有完成队列分配的线程发送消息，这将导致程序崩溃。因此，我们必须确保任何一个线程都必须在所有的线程都完成了队列分配后才开始发送消息。回想一下，之前我们见过一些OpenMP指令在结束时提供隐式路障，即任何一个线程都必须等到组中所有的线程完成了某个程序块后才可以接着执行后续代码。然而，在这个例子中，我们处于parallel块的中间，所以我们不能依赖于OpenMP提供的隐式路障——我们应当使用显式路障。幸运的是，OpenMP提供了相应的指令：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp barrier</span><br></code></pre></div></td></tr></table></figure>\n\n<p>当线程遇到路障时，它将被阻塞，直到组中所有的线程都到达了这个路障。当组中所有的线程都到达了这个路障时，这些线程就可以接着往下执行。</p>\n<h3 id=\"7-atomic指令\"><a href=\"#7-atomic指令\" class=\"headerlink\" title=\"7.atomic指令\"></a>7.atomic指令</h3><p>发送完所有的消息后，每个线程在执行最后的循环以便接受消息之前，需要对done_sending加1.显然，对done_sending的增量操作是临界区，可以通过critical指令来保护它。然后，OpenMP提供了另外一种可能更加高效的指令：atomic指令：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp atomic</span><br></code></pre></div></td></tr></table></figure>\n\n<p>与critical指令不同，它只能保护由一条C语言赋值语句所形成的临界区。此外，语句必须是一下几种形式之一：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">x &lt;op&gt; = &lt;expression&gt;<br>x++;<br>++x;<br>x--;<br>--x;<br></code></pre></div></td></tr></table></figure>\n\n<p><op>可以是以下任意的二元操作符：</op></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">+,*,-,/,&amp;,|,^,&lt;&lt;,<span class=\"hljs-keyword\">or</span> &gt;&gt;<br></code></pre></div></td></tr></table></figure>\n\n<p>这里要记住，<expression>不能引用x。</expression></p>\n<p>需要注意的是，只有x的装载和存储可以确保是受保护的，例如在下面的代码中：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp atomic</span><br>x += y++;<br></code></pre></div></td></tr></table></figure>\n\n<p>其他线程对x的更新必须等到该线程对x的更新结束之后。但是对y的更新不受保护，因此程序的结果是不可预测的。</p>\n<p>atomic指令的思想是许多处理器提供专门的装载-修改-存储(load-modify-store)指令。使用这种专门的指令而不使用保护临界区的通用结构，可以更高效地保护临界区。</p>\n<h3 id=\"8-临界区和锁\"><a href=\"#8-临界区和锁\" class=\"headerlink\" title=\"8.临界区和锁\"></a>8.临界区和锁</h3><p>为了完成对消息传递程序的讨论，我们需要进一步仔细研究OpenMP critical指令的规范。在更早的例子中，程序最多只有一个临界区，critical指令强制所有的线程对该区域进行互斥访问。在这个程序中，临界区的使用将更加复杂。我们将在源代码中看到3个在critical或atomic指令后面的代码块：</p>\n<ol>\n<li>done_sending++</li>\n<li>Enqueue(q_p,my_rank,mesg);</li>\n<li>Dequeue(q_p,&amp;src,&amp;mesg);</li>\n</ol>\n<p>然而，我们不需要强制对3个代码块都进行互斥访问，甚至不需要强制对第二个和第三个代码块进行完全的互斥访问。例如，线程0在向线程1的消息队列写消息的同时，线程1可以向线程2的消息队列写消息。但是OpenMP的规定第二个和第三个代码块是被critical指令保护的代码块。在OpenMP看来，我们的程序有两个不同的临界区；被atomic指令保护的done_sending++和“复合”临界区。在“复合”临界区中，程序读取和发送消息。</p>\n<p>强制线程间的互斥会使程序的执行串行化。OpenMP默认的做法是将所有的临界区代码块作为复合临界区的一部分，这可能非常不利于程序的性能。OpenMP提供了向critical指令添加名字的选项：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp critical(name)</span><br></code></pre></div></td></tr></table></figure>\n\n<p>采取这种方式，两个用不同名字的critical指令保护的代码块就可以同时执行。我们想为每一个线程的消息队列的临界区提供不同的名字，但是临界区的名字是在程序编译过程中设置的。因此，我们需要在程序执行的过程中设置临界区的名字。但是按照为我们的设置，当我们想让访问不同队列的线程可以同时访问相同的代码块时，被命名的critical指令就不能满足我们的要求了。</p>\n<p>解决方案是使用锁（lock）。锁由一个数据结构和定义在这个数据结构上的函数组成，这些函数使得程序员可以显式地强制对临界区进行互斥访问。锁的使用可以大概用下面的伪代码描述：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-comment\">/*Executed by one thread*/</span><br>initialize the lock data structure;<br>...<br><span class=\"hljs-comment\">/*Executed by multiple threads*/</span><br>Attempt to lock <span class=\"hljs-keyword\">or</span> set the lock data structure;<br>Critical section;<br>Unlock <span class=\"hljs-keyword\">or</span> unset the lock data structure;<br>...<br><span class=\"hljs-comment\">/*Executed by one thread*/</span><br>Destory the lock data structure;<br></code></pre></div></td></tr></table></figure>\n\n<p>锁的数据结构被执行临界区的线程所共享，这些线程中的某个线程（如主线程）会初始化锁。而当所有的线程都使用完锁后，某个线程应当负责销毁锁。</p>\n<p>在一个线程进入临界区前，它尝试通过调用锁函数来上锁（set）。如果没有其他的线程正在执行临界区代码，那么它将获得锁并进入临界区。当该线程执行完临界区代码后，它调用解锁函数释放（relinquish或者unset）锁，以便其他线程可以获得锁。</p>\n<p>当一个线程拥有锁时，其他线程都不能进入该临界区。其他线程尝试通过调用锁函数进入该临界区时会阻塞。如果有多个线程被锁函数阻塞，则当临界区的线程释放锁时，这些线程中的某个线程会获得锁，而其他线程仍被阻塞。</p>\n<p>OpenMP有两种锁：简单（simple）锁和嵌套（nested）锁。简单锁在被释放前只能获得一次，而一个嵌套锁在被释放前可以被同一个线程获得多次。OpenMP简单锁的类型是omp_lock_t，定义简单锁的函数包括：</p>\n<p><img src=\"/2023/01/14/openmp006/image-20230116165204803.png\" alt=\"image-20230116165204803\"></p>\n<p>相关的类型和函数在头文件omp.h中声明。第一个函数的作为是初始化锁，所以此时锁处于解锁状态，换句话说，此时没有线程拥有这个锁。第二个函数尝试获得锁，如果成功，调用该函数的线程可以继续执行；如果失败，调用该函数的线程将被阻塞，直到锁被其他线程释放。第三个函数释放锁，以便其他线程可以获得该锁。第四个函数销毁锁。</p>\n",
            "tags": [
                "OpenMP"
            ]
        },
        {
            "id": "http://example.com/2023/01/14/openmp005/",
            "url": "http://example.com/2023/01/14/openmp005/",
            "title": "OpenMP循环调度",
            "date_published": "2023-01-14T05:04:25.000Z",
            "content_html": "<h2 id=\"OpenMP循环调度\"><a href=\"#OpenMP循环调度\" class=\"headerlink\" title=\"OpenMP循环调度\"></a>OpenMP循环调度</h2><h3 id=\"1-循环调度\"><a href=\"#1-循环调度\" class=\"headerlink\" title=\"1.循环调度\"></a>1.循环调度</h3><p>当第一次遇到parallel for指令时，我们看到将各次循环分配给线程的操作是由系统完成的。然而，大部分OpenMP实现只是粗略地使用块分割：如果在串行循环中有n次迭代，那么在并行循环中，前n&#x2F;thread_count个迭代分配给线程0，接下来的n&#x2F;thread_count个迭代分配给线程1，依此类推。不难想到，这种分配方式肯定不是最优的。例如，假如我们想要并行化循环：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">sum = <span class=\"hljs-number\">0.0</span>;<br><span class=\"hljs-keyword\">for</span>(i=<span class=\"hljs-number\">0</span>;i&lt;=n;i++)<br>    sum+=<span class=\"hljs-built_in\">f</span>(i);<br></code></pre></div></td></tr></table></figure>\n\n<p>同时，假设对f函数调用所需要的时间与参数i的大小成正比，那么与分配给线程0的工作相比，分配给线程thread_count-1的工作量相对较大。一个更好的分配方案是轮流分配线程的工作（循环划分）。在循环划分中，各次迭代被“轮流”地一次一个地分配给线程。假如 t&#x3D;thread_count。那么一个循环划分将如下分配各次迭代：</p>\n<p><img src=\"/2023/01/14/openmp005/image-20230114132246596.png\" alt=\"image-20230114132246596\"></p>\n<p>为了了解这样分配是如何影响性能的，我们编写了如下程序。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">double</span> <span class=\"hljs-title\">f</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> i)</span></span>&#123;<br>    <span class=\"hljs-keyword\">int</span> j,start=i*(i+<span class=\"hljs-number\">1</span>)/<span class=\"hljs-number\">2</span>,finish=start+i;<br>    <span class=\"hljs-keyword\">double</span> return_val = <span class=\"hljs-number\">0.0</span>;<br>    <br>    <span class=\"hljs-keyword\">for</span>(j = start; j&lt;=finish; j++)&#123;<br>        return_val += <span class=\"hljs-built_in\">sin</span>(j);<br>    &#125;<br>    <span class=\"hljs-keyword\">return</span> return_val;<br>    <span class=\"hljs-comment\">/* f */</span><br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>每当函数f（i）调用i次sin函数。例如，执行f（2i）的时间几乎是执行f（i）的时间的两倍。</p>\n<p>当n&#x3D;10000并且只用一个线程运行程序时，运行时间是3.67秒。当用两个线程和缺省分配方式（第0-5000次迭代分配给线程0，第5001-10000次迭代分配给线程1），运行程序时，运行时间为2.76秒。加速比仅为1.33.然而，当运行两个线程并采用循环划分时，运行时间减少到1.84秒。与单线程运行相比，加速比为1.99；与双线程，块分割相比，加速比为1.5！</p>\n<p>我们看到一个好的迭代分配能够对性能有很大的影响。再OpenMP中，将循环分配给线程称为调度，schedule子句用于在parallel for或者for指令中进行迭代分配。</p>\n<h3 id=\"2-schedule子句\"><a href=\"#2-schedule子句\" class=\"headerlink\" title=\"2.schedule子句\"></a>2.schedule子句</h3><p>在例子中，我们已经知道如何乎获取缺省调度：只需要添加parallel for指令和reduction子句：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">sum=<span class=\"hljs-number\">0.0</span>;<br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp parallel for num_threads(thread_count) reduction(+:sum)</span><br><span class=\"hljs-keyword\">for</span>(i=<span class=\"hljs-number\">0</span>;i&lt;=n;i++)&#123;<br>    sum+=<span class=\"hljs-built_in\">f</span>(i);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>为了对线程进行调度，可以添加一个schedule子句到parallel for指令中：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">sum=<span class=\"hljs-number\">0.0</span>;<br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp parallel for num_threads(thread_count) reduction(+:sum)\tschedule(static,1)</span><br><span class=\"hljs-keyword\">for</span>(i=<span class=\"hljs-number\">0</span>;i&lt;=n;i++)&#123;<br>    sum+=<span class=\"hljs-built_in\">f</span>(i);<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>一般而言，schedule子句有如下形式：</p>\n<p>schedule（<type>[.<chunksize>]）</chunksize></type></p>\n<p>type可以是下列任意一个：</p>\n<ol>\n<li>static：迭代能够在循环执行前分配给线程</li>\n<li>dynamic或guided：迭代在循环执行时被分配给线程，因此在一个线程完成了它的当前迭代集合后，它能从运行时系统中请求更多</li>\n<li>auto：编译器和运行时系统决定调度方式</li>\n<li>runtime：调度在运行时决定</li>\n</ol>\n<p>chunksize是一个正整数。在OpenMP中，迭代块是在顺序循环中连续执行的一块迭代语句，块中的迭代次数是chunksize。只有static，dynamic和guided调度有chunksize。这虽然决定了调度的细节，但准确的解释还是依赖于type。</p>\n<h3 id=\"3-stastic调度类型\"><a href=\"#3-stastic调度类型\" class=\"headerlink\" title=\"3.stastic调度类型\"></a>3.stastic调度类型</h3><p>对于static调度，系统以轮转的方式分配chunksize块个迭代给每个线程。例如，假如有12个迭代，0，1，—，11和3个线程，如果在parallel for或for指令中使用schedule（static，1）迭代将如下分配：</p>\n<p><img src=\"/2023/01/14/openmp005/image-20230114141741424.png\" alt=\"image-20230114141741424\"></p>\n<p>如果使用schedule（static，2），迭代将如下进行分配：</p>\n<p><img src=\"/2023/01/14/openmp005/image-20230114141830866.png\" alt=\"image-20230114141830866\"></p>\n<p>如果使用schedule（static，4），迭代将如下分配：</p>\n<p><img src=\"/2023/01/14/openmp005/image-20230114141909092.png\" alt=\"image-20230114141909092\"></p>\n<p>因此，子句schedule（static,total_iterations&#x2F;thread_count）就相当于被大部分OpenMP实现所使用的缺省调度。</p>\n<p>这里，chunksize可以被忽略。如果他被忽略了，chunksize就近似等于total_iterations&#x2F;thread_count。</p>\n<h3 id=\"4-dynamic和guided调度类型\"><a href=\"#4-dynamic和guided调度类型\" class=\"headerlink\" title=\"4.dynamic和guided调度类型\"></a>4.dynamic和guided调度类型</h3><p>在dynamic调度中，迭代也被分成chunksize个连续迭代的块。每个线程执行一块，并且当一个线程完成一块时，它将从运行时系统请求另一块，直到所有的迭代完成。chunksize可以被忽略。当它被忽略时，chunksize为1。</p>\n<p>在guided调度中，每个线程也执行一块，并且当一个线程完成一块时，将请求另一块。然而，在guided调度中，当块完成后，新块的大小会变小。例如，在我们的系统中，如果用parallel for指令和schedule（guided）子句来运行梯形积分法程序，那么当n&#x3D;10000并且thread_count&#x3D;2时。迭代将如表5-3那样分配。块的大小近似等于剩下的迭代数除以线程数。第一个块的大小9999&#x2F;2≈5000，因为有9999个迭代未被分配的迭代。第二个块的大小为4999&#x2F;2≈2500，一次类推。</p>\n<p><img src=\"/2023/01/14/openmp005/image-20230114143233692.png\" alt=\"image-20230114143233692\"></p>\n<p>在guided调度中，如果没有指定chunksize，那么块的大小为1；如果指定了chunksize，那么块的大小就是chunksize，除了最后一块的大小可以比chunksize小。</p>\n<h3 id=\"5-runtime调度类型\"><a href=\"#5-runtime调度类型\" class=\"headerlink\" title=\"5.runtime调度类型\"></a>5.runtime调度类型</h3><p>为了理解schedule（runtime），我们需要离题一会儿，讨论一下环境变量。正如名字所暗示的，环境变量是能够被运行时系统所访问的命名值，即它们在程序的环境中是可得的。一些经常被使用的环境变量是PATH,HOME和SHELL。PATH变量明确了当寻找一个可执行文件时shell应该搜索哪些目录。它通常在UNIX和Windows系统中定义。HOME变量指定用户主目录的位置，而SHELL变量指定用户shell的可执行位置。这样通常在UNIX系统中。在类UNIX系统（例如Linux和Mac OS X）和Windows，环境变量能够在命令行中检查和指定。在类UNIX系统中，能使用shell命令行；在windows中，能使用集成开发环境的命令行。</p>\n<p>例如，如果我们正使用bash shell，要检查一个环境变量的值只需要输入</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-variable\">$PATH</span></span><br></code></pre></div></td></tr></table></figure>\n\n<p>我们能够使用export命令来设置一个环境变量的值</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"><span class=\"hljs-built_in\">export</span> TEST_VAR = <span class=\"hljs-string\">&quot;hello&quot;</span></span><br></code></pre></div></td></tr></table></figure>\n\n<p>如何检查和设置特定系统的环境变量，请咨询本地系统的专家。</p>\n<p>当schedule（runtime）指定时，系统使用环境变量OMP_SCHEDULE在运行时来决定如何调度循环。OMP_SCHEDULE环境变量会呈现任何能够被static，dynamic或guided调度所使用的值。例如，假设在程序中有一条parallel for指令，并且它已经被schedule（runtime）修改了。那么如果使用bash shell，就能通过执行以下命令将一个循环分配所得到的迭代分配给线程：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"><span class=\"hljs-built_in\">export</span> OMP_SCHEDULE=<span class=\"hljs-string\">&quot;static,1&quot;</span></span><br></code></pre></div></td></tr></table></figure>\n\n<p>现在，当开始执行程序时，系统将调度for循环的迭代，就如同使用子句schedule（static，1）修改了parallel for指令那样。</p>\n<h3 id=\"6-调度选择\"><a href=\"#6-调度选择\" class=\"headerlink\" title=\"6.调度选择\"></a>6.调度选择</h3><p>如果需要并行化一个for循环，那么我们如何决定使用哪一种电镀和chuncksize的大小？实际上，每一中schedule子句有不同的系统开销。dynamic调度的系统开销要大于static调度，而guided调度的系统开销是三种方式中最大的。因此，如果不使用schedule子句就已经达到了令人满意的性能，就不需要进行多余的工作。但是，如果我们怀疑调度的性能可以提升，那么我们可以对各种调度进行试验。</p>\n<p>在本节开始提供的例子中，在程序使用两个线程的情况下，使用schedule（static，1）代替默认调度时，加速比从1.33提升到1.99。因为在两个线程的条件下，加速比几乎不可能比1.99更好，所以我们可以不用再尝试其他的调度方式，至少在只用两个线程并且迭代数为10000的情况下是这样。如果做更多的试验，改变线程的个数和迭代的次数，我们可能会发现：最优的调度方式是由线程的个数和迭代的次数共同决定的。</p>\n<p>如果我们断定默认的调度方式性能低下，那么我们会做大量的实验来寻找最优的调度方式和迭代次数。在进行了大量的工作以后，我们可能发现，这些循环没有得到很好的并行化，没有哪一种调度可以带来比较显著的性能提升。编程作业5.4就是这样一个例子。</p>\n<p>但在某些情况下，应该优先考虑有些调度：</p>\n<ol>\n<li>如果循环的每次迭代需要几乎相同的计算量，那么可能默认的调度方式能提供最好的性能</li>\n<li>如果随着循环的进行，迭代的计算量线性猛增（或递减），那么采用比较小的chuncksize的static调度可能会提供最好的性能</li>\n<li>如果每次迭代的开销事先不能确定，那么就可能需要尝试使用多种不同的调度策略。在这种情况下，应当使用schedule（runtime）子句，通过富裕环境变量OMP_SCHEDULE不同的值来比较不同调度策略下程序的性能</li>\n</ol>\n<h3 id=\"7-总结\"><a href=\"#7-总结\" class=\"headerlink\" title=\"7.总结\"></a>7.总结</h3><ol>\n<li>调度方式对加速效果的重要性</li>\n<li>合理分析任务特性，选择最适合的调度方式</li>\n</ol>\n<h3 id=\"8-参考资料\"><a href=\"#8-参考资料\" class=\"headerlink\" title=\"8.参考资料\"></a>8.参考资料</h3><p>并行程序导论 （美）Peter S.Pacheco</p>\n",
            "tags": [
                "OpenMP"
            ]
        },
        {
            "id": "http://example.com/2023/01/13/openmp004/",
            "url": "http://example.com/2023/01/13/openmp004/",
            "title": "OpenMP排序",
            "date_published": "2023-01-13T08:26:51.000Z",
            "content_html": "<h2 id=\"OpenMP排序\"><a href=\"#OpenMP排序\" class=\"headerlink\" title=\"OpenMP排序\"></a>OpenMP排序</h2><h3 id=\"1-冒泡排序\"><a href=\"#1-冒泡排序\" class=\"headerlink\" title=\"1.冒泡排序\"></a>1.冒泡排序</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">for</span>(list_length = n; list.length &gt;= <span class=\"hljs-number\">2</span>; list_length--)\t\t\t\t<span class=\"hljs-comment\">//升序排列</span><br>    <span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">0</span>;i &lt; list_length<span class=\"hljs-number\">-1</span>; i++)<br>        <span class=\"hljs-keyword\">if</span>(a[i] &gt; a[i+<span class=\"hljs-number\">1</span>])&#123;<br>            tmp = a[i];<br>            a[i] = a[i+<span class=\"hljs-number\">1</span>];<br>            a[i+<span class=\"hljs-number\">1</span>] = tmp;<br>        &#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>​\t\t显然，在外部循环中有一个循环依赖，在外部循环的任何一次迭代中，当前列表的内容依赖于外部循环的前一次迭代。例如，如果在算法开始时，a&#x3D;3,4,1,2，那么外部循环的第二次迭代将对列表3，1，2进行操作，因为4在第一次迭代中应该已经被移动到列表的最后了。但如果前两次迭代同时执行，则可能第二次迭代的有效列表包含4。\t</p>\n<p>​\t\t内部循环的循环依赖也很容易发现。在第i次迭代中，被比较的元素依赖于第i-1次迭代。如果在第i-1次迭代中a[i-1]和a[i]没有交换，那么第i次迭代将比较a[i]和a[i+1]。另一方面，如果第i-1次迭代交换了a[i-1]和a[i]，那么第i次迭代将比较原始的a[i-1] (现在是a[i]和a[i+1])。例如，假如当前列表是{3，1，2}。那么当i&#x3D;1时，我们将比较3和2，但如果i&#x3D;0和i&#x3D;1次迭代同时发生，则完全有可能i&#x3D;1次迭代回比较1和2。</p>\n<p>​\t\t我们完全不清楚怎样在不完全重写算法的情况下一处任何一个循环依赖。记住。即使我们总能找到循环依赖，但可能很难甚至不可能移除它。对于并行化for循环而言，parallel for指令不是一个通用的解决方法。</p>\n<h3 id=\"2-奇偶交换排序\"><a href=\"#2-奇偶交换排序\" class=\"headerlink\" title=\"2.奇偶交换排序\"></a>2.奇偶交换排序</h3><p>​\t\t奇偶交换排序是一个与冒泡排序相似的算法，但它相对来说更容易并行化。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">for</span>(phase = <span class=\"hljs-number\">0</span>;phase &lt; n ; phase++)<br>    <span class=\"hljs-keyword\">if</span>(phase % <span class=\"hljs-number\">2</span> == <span class=\"hljs-number\">0</span>)<br>        <span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">1</span>; i &lt; n ;i += <span class=\"hljs-number\">2</span>)<br>            <span class=\"hljs-keyword\">if</span>(a[i<span class=\"hljs-number\">-1</span>] &gt; a[i]) <span class=\"hljs-built_in\">swap</span>(a[i<span class=\"hljs-number\">-1</span>],a[i]);<br>\t<span class=\"hljs-keyword\">else</span><br>        <span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">1</span>;i &lt; n<span class=\"hljs-number\">-1</span> ;i += <span class=\"hljs-number\">2</span>)<br>            <span class=\"hljs-keyword\">if</span>(a[i] &gt; a[i+<span class=\"hljs-number\">1</span>]) <span class=\"hljs-built_in\">swap</span>(a[i],a[i+<span class=\"hljs-number\">1</span>]);<br></code></pre></div></td></tr></table></figure>\n\n<p>列表a存储n个整数，算法对他们进行升序排列。在一个“偶阶段”（phase %2 &#x3D;&#x3D;0 ）里，每个偶下标元素a[i]与它左边的元素a[i-1]相比较。如果他们是没有排好序的，就交换它们。在一个“奇阶段”里，每个奇下标元素与它右边的元素相比较。如果他们是没有排好序的，则交换他们。有定理证明：在n个阶段后，列表可以完成排序。</p>\n<p>​\t\t作为一个简单的例子，假设a&#x3D;{9,7,8,6}。表5-1显示了各个阶段的情况。在这个例子中，最后的阶段不是必要的，但算法并不在执行每个阶段前检查列表是否已经有序。</p>\n<p><img src=\"/2023/01/13/openmp004/image-20230113174202896.png\" alt=\"image-20230113174202896\"></p>\n<p>​\t\t不难看到外部循环有一个循环依赖。例如在a &#x3D; {9，7，8，6}之前。在阶段0中，内部循环将比较（9，7）和（8，6）这两对中的元素，这两对都会被交换。因此对于阶段1，列表将是{7，9，6，8}，并在阶段1中（9，6）中的元素被比较并交换。然而，如果阶段0和阶段1同时执行，则在阶段1中被检查可能是（7，8），是有序的。此外，我们尚不清楚如何消除这个循环依赖，因此并行化外部for循环不是一个好的选择。</p>\n<p>​\t\t但是，内部for循环并没有任何循环依赖。例如，在偶阶段循环中，变量i是奇数，所以对于两个不同的i值，例如，i&#x3D;j和i&#x3D;k，{j-1,j}和{k-1,k}将是不同的。（a[j-1],a[j]）和（a[k-1],a[k]）所产生的比较和可能的交换能够同时进行。</p>\n<p>​\t\t所以，我们试图使用程序5-4的代码并行化奇偶变化排序，但还是会有一些潜在的问题，首先，尽管任何一个偶阶段迭代并不依赖任何这个阶段的其他迭代，但是还需要注意，对p阶段和p+1阶段却并不是这样的。我们需要确定在任何一个线程开始p+1阶段之前，所有的线程必须先完成p阶段。然而，像parallel指令那样，parallel for指令在循环结束处有一个隐式的路障，因此，在所有的线程完成当前阶段（即阶段P之前），没有线程能够进入下一阶段，即p+1阶段。【这里需要注意在MPI中并没有隐式的路障来实现这个功能，需要程序员手动设置路障点】</p>\n<p>​\t\t其次，是创建和合并线程的开销。OpenMP实现可能会在每一遍外部循环都创建和合并thread__count个线程。表5-2的第一行显示了当输入列表包含20000个元素时，在我们系统上运行1，2，3，4个线程的运行时间。</p>\n<h3 id=\"3-程序5-4奇偶排序的第一个OpenMP实现\"><a href=\"#3-程序5-4奇偶排序的第一个OpenMP实现\" class=\"headerlink\" title=\"3.程序5-4\t奇偶排序的第一个OpenMP实现\"></a>3.程序5-4\t奇偶排序的第一个OpenMP实现</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">for</span>(phase = <span class=\"hljs-number\">0</span>;phase &lt; n; phase++)&#123;<br>    <span class=\"hljs-keyword\">if</span>(phase %<span class=\"hljs-number\">2</span> ==<span class=\"hljs-number\">0</span>)<br>    \t<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp parallel for num_threads(thread_count) default(none) shared(a,n) private(i,tmp)</span><br>        <span class=\"hljs-keyword\">for</span>(i=<span class=\"hljs-number\">1</span>;i&lt;n;i+=<span class=\"hljs-number\">2</span>)&#123;<br>            <span class=\"hljs-keyword\">if</span>(a[i<span class=\"hljs-number\">-1</span>]&gt;a[i])&#123;<br>                tmp = a[i<span class=\"hljs-number\">-1</span>];<br>                a[i<span class=\"hljs-number\">-1</span>] = a[i];<br>                a[i] =tmp;<br>            &#125;<br>        &#125;<br>    <span class=\"hljs-keyword\">else</span><br>        <span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp parallel for num_threads(thread_count) default(none) shared(a,n) private(i,tmp)</span><br>        <span class=\"hljs-keyword\">for</span>(i=<span class=\"hljs-number\">1</span>;i&lt;n<span class=\"hljs-number\">-1</span>;i+=<span class=\"hljs-number\">2</span>)&#123;<br>            <span class=\"hljs-keyword\">if</span>(a[i] &gt; a[i+<span class=\"hljs-number\">1</span>])&#123;<br>                tmp = a[i+<span class=\"hljs-number\">1</span>];<br>                a[i+<span class=\"hljs-number\">1</span>] = a[i];<br>                a[i] = tmp;<br>            &#125;<br>        &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/01/13/openmp004/image-20230113225724364.png\" alt=\"image-20230113225724364\"></p>\n<p>​\t\t这些时间耗费并不非常糟糕，但是我们想看看是否能做得更好。每次执行内部循环时，使用同样数量的线程。因此只创建一次线程，并在每次内部循环的执行中重用它们，这样做可能更好。幸运的是，OpenMP提供了允许这样做的指令。用parallel指令在外部循环前创建thread__count个线程的集合。然后，我们不在每次内部循环执行时创建一组新的线程，而是使用一个for指令，告诉OpenMP用已有的线程组来并行化for循环，对原有OpenMP实现的改动显示在程序5-5中。</p>\n<h3 id=\"4-程序5-5奇偶排序的第二个OpenMP实现\"><a href=\"#4-程序5-5奇偶排序的第二个OpenMP实现\" class=\"headerlink\" title=\"4.程序5-5\t奇偶排序的第二个OpenMP实现\"></a>4.程序5-5\t奇偶排序的第二个OpenMP实现</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp parallel for num_threads(thread_count) default(none) shared(a,n) private(i,tmp,phase)</span><br><span class=\"hljs-keyword\">for</span>(phase = <span class=\"hljs-number\">0</span>;phase &lt; n; phase++)&#123;<br>    <span class=\"hljs-keyword\">if</span>(phase %<span class=\"hljs-number\">2</span> ==<span class=\"hljs-number\">0</span>)<br>\t\t<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp for</span><br>        <span class=\"hljs-keyword\">for</span>(i=<span class=\"hljs-number\">1</span>;i&lt;n;i+=<span class=\"hljs-number\">2</span>)&#123;<br>            <span class=\"hljs-keyword\">if</span>(a[i<span class=\"hljs-number\">-1</span>]&gt;a[i])&#123;<br>                tmp = a[i<span class=\"hljs-number\">-1</span>];<br>                a[i<span class=\"hljs-number\">-1</span>] = a[i];<br>                a[i] =tmp;<br>            &#125;<br>        &#125;<br>    <span class=\"hljs-keyword\">else</span><br>\t\t<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp for</span><br>        <span class=\"hljs-keyword\">for</span>(i=<span class=\"hljs-number\">1</span>;i&lt;n<span class=\"hljs-number\">-1</span>;i+=<span class=\"hljs-number\">2</span>)&#123;<br>            <span class=\"hljs-keyword\">if</span>(a[i] &gt; a[i+<span class=\"hljs-number\">1</span>])&#123;<br>                tmp = a[i+<span class=\"hljs-number\">1</span>];<br>                a[i+<span class=\"hljs-number\">1</span>] = a[i];<br>                a[i] = tmp;<br>            &#125;<br>        &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>与parallel for指令不同的是，for指令并不创建任何线程。它使用已经在parallel块中创建的线程。在循环的末尾有一个隐式的路障。代码的结果（最终列表）将因此与原有的并行化代码所取得到的结果一样。</p>\n<p>​\t\t奇偶排序的第二个版本的运行时间显示在表5-2的第二行。当使用两个或更多线程时，使用两条for指令的版本要比使用两条parallel for指令的版本快17%。因此对于这个系统而言，为这点改变所做的小小努力是值得的。</p>\n<h3 id=\"5-总结\"><a href=\"#5-总结\" class=\"headerlink\" title=\"5.总结\"></a>5.总结</h3><ol>\n<li>循环依赖总会出现，我们可能会很难去解决它甚至根本无法解决。</li>\n<li>在构造并行区时要尽量减少创建和合并线程的开销</li>\n</ol>\n<h3 id=\"6-参考文献\"><a href=\"#6-参考文献\" class=\"headerlink\" title=\"6.参考文献\"></a>6.参考文献</h3><p>并行程序导论 （美）Peter S.Pacheco</p>\n",
            "tags": [
                "OpenMP"
            ]
        },
        {
            "id": "http://example.com/2023/01/09/openmp003/",
            "url": "http://example.com/2023/01/09/openmp003/",
            "title": "OpenMP π值估计",
            "date_published": "2023-01-09T07:06:18.000Z",
            "content_html": "<h2 id=\"π值估计\"><a href=\"#π值估计\" class=\"headerlink\" title=\"π值估计\"></a>π值估计</h2><h3 id=\"1-数学背景\"><a href=\"#1-数学背景\" class=\"headerlink\" title=\"1.数学背景\"></a>1.数学背景</h3><p><img src=\"/2023/01/09/openmp003/image-20230109150836877.png\" alt=\"image-20230109150836877\"></p>\n<p>我们能够在串行代码下实行这个公式：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">double</span> factor = <span class=\"hljs-number\">1.0</span>;<br><span class=\"hljs-keyword\">double</span> sum = <span class=\"hljs-number\">0.0</span>;<br><span class=\"hljs-keyword\">for</span>(k=<span class=\"hljs-number\">0</span> ; k &lt; n; k++)&#123;<br>    sum += factor /(<span class=\"hljs-number\">2</span>*k+<span class=\"hljs-number\">1</span>);<br>    factor = - factor;<br>&#125;<br>pi_approx = <span class=\"hljs-number\">4.0</span>*sum;<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"2-OpenMP并行化\"><a href=\"#2-OpenMP并行化\" class=\"headerlink\" title=\"2.OpenMP并行化\"></a>2.OpenMP并行化</h3><p>为了使用OpenMP来并行化，可以首先倾向于这样做：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">double</span> factor = <span class=\"hljs-number\">1.0</span>;<br><span class=\"hljs-number\">2</span> <span class=\"hljs-keyword\">double</span> sum = <span class=\"hljs-number\">0.0</span>;<br><span class=\"hljs-number\">3</span> <span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp parallel for num_threads(thread_count) reduction(+:sum)  <span class=\"hljs-comment\">//对sum进行求和归约</span></span><br><span class=\"hljs-number\">4</span> <span class=\"hljs-keyword\">for</span>(k=<span class=\"hljs-number\">0</span> ; k &lt; n; k++)&#123;<br><span class=\"hljs-number\">5</span>     sum += factor /(<span class=\"hljs-number\">2</span>*k+<span class=\"hljs-number\">1</span>);<br><span class=\"hljs-number\">6</span>     factor = - factor;<br><span class=\"hljs-number\">7</span> &#125;<br><span class=\"hljs-number\">8</span> pi_approx = <span class=\"hljs-number\">4.0</span>*sum;<br></code></pre></div></td></tr></table></figure>\n\n<p>然而，第k次迭代中对第6行的factor的更新和接下来的第k + 1次迭代中对第5行的sum的累加是一个循环依赖（数据依赖）。如果第k次迭代被分配·到一个线程，而第k + 1次迭代被分配给另一个线程，则我们不能保证第6行中factor的值是正确的。</p>\n<p>在这种情况下我们能通过检查系数来解决这个问题：</p>\n<p><img src=\"/2023/01/09/openmp003/image-20230109161031989.png\" alt=\"image-20230109161031989\"></p>\n<p>可以看到：在第k次迭代，factor的值应该是<img src=\"/2023/01/09/openmp003/image-20230109161206995.png\" alt=\"image-20230109161206995\">。如果k是偶数，那么值是+1；如果k是奇数，值是-1。</p>\n<h3 id=\"3-消除循环依赖（数据依赖）\"><a href=\"#3-消除循环依赖（数据依赖）\" class=\"headerlink\" title=\"3.消除循环依赖（数据依赖）\"></a>3.消除循环依赖（数据依赖）</h3><p>因此，如果将下述代码：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\">sum += factor /(<span class=\"hljs-number\">2</span>*k+<span class=\"hljs-number\">1</span>);<br>factor = - factor;<br></code></pre></div></td></tr></table></figure>\n\n<p>替换为：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">if</span>(k % <span class=\"hljs-number\">2</span> ==<span class=\"hljs-number\">0</span>)\t\t\t<span class=\"hljs-comment\">//通过奇偶性，来独立factor消除循环依赖（数据依赖）</span><br>    factor = <span class=\"hljs-number\">1.0</span>;<br><span class=\"hljs-keyword\">else</span><br>    factor = <span class=\"hljs-number\">-1.0</span>;<br>sum += factor/(<span class=\"hljs-number\">2</span>*k+<span class=\"hljs-number\">1</span>);<br></code></pre></div></td></tr></table></figure>\n\n<p>这样就消除了循环依赖（数据依赖）。</p>\n<h3 id=\"4-作用域\"><a href=\"#4-作用域\" class=\"headerlink\" title=\"4.作用域\"></a>4.作用域</h3><p>​\t然而，事情仍然不是完全正确的。如果在我们的系统上使用两个线程运行程序，并设n&#x3D;1000，那么结果仍然是错误的。例如，</p>\n<p><img src=\"/2023/01/09/openmp003/image-20230109164120205.png\" alt=\"image-20230109164120205\"></p>\n<p>另一方面，如果只有一个线程运行程序，我们总是得到：</p>\n<p><img src=\"/2023/01/09/openmp003/image-20230109164204808.png\" alt=\"image-20230109164204808\"></p>\n<p>为什么会有这种错误。在一个已经被parallel for指令并行化的块中，缺省情况下任何在循环前声明的变量（唯一的例外是循环变量）在线程间都是共享的。因此factor被共享（被所有线程所共享）。例如，线程0可能会给他赋值1，但在它能用这个值更新sum前，线程1可能又给他赋值为-1了。因此，除了消除计算factor时的循环依赖（数据依赖）外，我们还需要保证每个线程有它自己的factor副本，就是说，为了使代码正确，我们需要保证factor有私有作用域（简单来说就是保证当前线程的factor的值不能被其他线程修改，也只有当前线程能更新和使用factor）。通过添加一个private子句到parallel指令中来实现这一目标。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"> <span class=\"hljs-keyword\">double</span> factor = <span class=\"hljs-number\">1.0</span>;<br> <span class=\"hljs-keyword\">double</span> sum = <span class=\"hljs-number\">0.0</span>;<br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp parallel for num_threads(thread_count) reduction(+:sum) private(factor)  <span class=\"hljs-comment\">//对sum进行求和归约</span></span><br> <span class=\"hljs-keyword\">for</span>(k=<span class=\"hljs-number\">0</span> ; k &lt; n; k++)&#123;<br>     <span class=\"hljs-keyword\">if</span>(k % <span class=\"hljs-number\">2</span> ==<span class=\"hljs-number\">0</span>)\t\t\t<span class=\"hljs-comment\">//通过奇偶性，来独立factor消除循环依赖（数据依赖）</span><br>    \tfactor = <span class=\"hljs-number\">1.0</span>;<br>\t<span class=\"hljs-keyword\">else</span><br>    \tfactor = <span class=\"hljs-number\">-1.0</span>;<br>     sum += factor /(<span class=\"hljs-number\">2</span>*k+<span class=\"hljs-number\">1</span>);<br> &#125;<br> pi_approx = <span class=\"hljs-number\">4.0</span>*sum;<br></code></pre></div></td></tr></table></figure>\n\n<p>在private子句内列举的变量，在每个线程上都有一个私有副本被创建。因此，在我们的例子中，thread_count个线程中的每一个都有它自己的factor变量的副本，因此一个线程对factor的更新不会影响另一个线程的factor值。</p>\n<p>​\t\t要记住的重要的一点是，一个有私有作用域的变量的值在parallel块或者parallel for块的开始处是未指定的。它的值在parallel或parallel for块完成之后也是未指定的。例如，下列代码中的第一个printf语句的输出是非确定的，因为在它被现实初始化之前就打印了私有变量x。类似地，最终的printf输出也是非确定的，因为他在parallel块完成之后打印x。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">int</span> x = <span class=\"hljs-number\">5</span>;<br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp parallel num_threads(thread_count) private(x)</span><br>&#123;<br>    <span class=\"hljs-keyword\">int</span> my_rank = <span class=\"hljs-built_in\">omp_get_thread_num</span>();<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Thread %d &gt; before initialization,x = %d\\n&quot;</span>,myrank,x);<br>    x = <span class=\"hljs-number\">2</span>*my_rank + <span class=\"hljs-number\">2</span>;<br>    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Thread %d &gt; after initialization,x = %d\\n&quot;</span>,my_rank,x);<br>&#125;<br><span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;After parallel block, x = %d\\n&quot;</span>,x);<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"5-关于作用域的更多问题\"><a href=\"#5-关于作用域的更多问题\" class=\"headerlink\" title=\"5.关于作用域的更多问题\"></a>5.关于作用域的更多问题</h3><p>​\t\t关于变量factor的问题是常见问题中的一个。我们通常需要考虑在parallel块或parallel for块中的每个变量的作用域。因此，与其让OpenMP决定每个变量的作用域，还不如让程序员明确块中每个变量的作用域。事实上，OpenMP提供了一个子句default，该子句显示地要求我们这样做。如果我们添加子句：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-built_in\"><span class=\"hljs-keyword\">default</span></span>(none)<br></code></pre></div></td></tr></table></figure>\n\n<p>到parallel或parallel for指令中，那么编译器将要求我们明确在这个块中使用的每个变量和已经在块之外声明的变量的作用域。（在一个块中声明的变量都是私有的，因为它们会被分配给线程的栈。）</p>\n<p>​\t例如，使用一个default（none）子句，对π的计算将如下所示。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp parallel for num_threads(thread_count) default(none) reduction(+:sum) private(k,factor)  <span class=\"hljs-comment\">//对sum进行求和归约</span></span><br> <span class=\"hljs-keyword\">for</span>(k=<span class=\"hljs-number\">0</span> ; k &lt; n; k++)&#123;<br>     <span class=\"hljs-keyword\">if</span>(k % <span class=\"hljs-number\">2</span> ==<span class=\"hljs-number\">0</span>)\t\t\t<span class=\"hljs-comment\">//通过奇偶性，来独立factor消除循环依赖（数据依赖）</span><br>    \tfactor = <span class=\"hljs-number\">1.0</span>;<br>\t<span class=\"hljs-keyword\">else</span><br>    \tfactor = <span class=\"hljs-number\">-1.0</span>;<br>     sum += factor /(<span class=\"hljs-number\">2</span>*k+<span class=\"hljs-number\">1</span>);<br> &#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>在这个例子中，我们在for循环中使用4个变量。由于default子句，我们需要明确每个变量的作用域。正如我们已经注意到的，sum是一个归约变量（同时拥有私有和共享作用域的属性）。我们也已经注意到factor和循环变量中k应该有私有作用域。从未在parallel或parallel for块中更新的变量，如这个例子中的n，能够被安全的共享。与私有变量不同，共享变量在块内具有在parallel或parallel for块之前的值，在块之后的值与块内的最后一个值相同。因此，如果n在块之前被初始化为1000，则在parallel for语句中他将保持这个值。因为在for循环中值没有改变，所有在循环结束后它将保持这个值。</p>\n<h3 id=\"6-总结\"><a href=\"#6-总结\" class=\"headerlink\" title=\"6.总结\"></a>6.总结</h3><ol>\n<li>分析数学背景，解决循环依赖（数据依赖）</li>\n<li>判断变量的作用域</li>\n</ol>\n<h3 id=\"7-参考资料\"><a href=\"#7-参考资料\" class=\"headerlink\" title=\"7.参考资料\"></a>7.参考资料</h3><p>并行程序导论 （美）Peter S.Pacheco</p>\n",
            "tags": [
                "OpenMP"
            ]
        },
        {
            "id": "http://example.com/2023/01/06/openmp002/",
            "url": "http://example.com/2023/01/06/openmp002/",
            "title": "OpenMP寻找循环依赖",
            "date_published": "2023-01-06T09:15:48.000Z",
            "content_html": "<h3 id=\"1-OpenMP寻找循环依赖\"><a href=\"#1-OpenMP寻找循环依赖\" class=\"headerlink\" title=\"1.OpenMP寻找循环依赖\"></a>1.OpenMP寻找循环依赖</h3><p>​\t\t当我们试图使用一个parallel for指令时，首先应该注意的是：要小心发现循环依赖。我们不需要担心一般的数据依赖。例如，在下面循环中：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-keyword\">for</span>(i=<span class=\"hljs-number\">0</span>;i&lt;n;i++)&#123;<br>    x[i] = a + i*h;\t\t\t<span class=\"hljs-comment\">//2</span><br>    y[i] = <span class=\"hljs-built_in\">exp</span>(x[i]);\t\t<span class=\"hljs-comment\">//3</span><br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>在第二行和第三行之间有一个数据依赖。然而，如下的并行化没有问题。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp parallel num_threads(thread_count)</span><br><span class=\"hljs-keyword\">for</span>(i=<span class=\"hljs-number\">0</span>;i&lt;n;i++)&#123;<br>    x[i] = a + i*h;\t\t\t<span class=\"hljs-comment\">//3</span><br>    y[i] = <span class=\"hljs-built_in\">exp</span>(x[i]);\t\t<span class=\"hljs-comment\">//4</span><br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<p>因为x[ i ]的计算与它接下来的使用总是被分配给同一个进程。</p>\n<p>​\t\t我们也应该观察到，有依赖关系的语句，其中至少一条语句会有序地写或更新变量。因此为了检测循环依赖，我们只需要重点观察被循环体更新的变量，即我们应该寻找在一个迭代中被读或被写，而在另一个迭代中被写的变量。</p>\n<h3 id=\"2-总结\"><a href=\"#2-总结\" class=\"headerlink\" title=\"2.总结\"></a>2.总结</h3><ol>\n<li>数据依赖在优化过程中非常常见</li>\n<li>如何解决数据依赖对提升并行化的效果影响很大</li>\n</ol>\n<h3 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h3><p>并行程序导论 （美）Peter S.Pacheco</p>\n",
            "tags": [
                "OpenMP"
            ]
        },
        {
            "id": "http://example.com/2023/01/03/openmp001/",
            "url": "http://example.com/2023/01/03/openmp001/",
            "title": "OpenMP梯度积分法",
            "date_published": "2023-01-03T09:19:45.000Z",
            "content_html": "<h2 id=\"OpenMP梯度积分法\"><a href=\"#OpenMP梯度积分法\" class=\"headerlink\" title=\"OpenMP梯度积分法\"></a>OpenMP梯度积分法</h2><h3 id=\"1-梯度积分法\"><a href=\"#1-梯度积分法\" class=\"headerlink\" title=\"1.梯度积分法\"></a>1.梯度积分法</h3><p><img src=\"/2023/01/03/openmp001/image-20230106165434252.png\" alt=\"001\"></p>\n<p><img src=\"/2023/01/03/openmp001/image-20230106165507737.png\" alt=\"image-20230106165507737\"></p>\n<h3 id=\"2-识别两类任务\"><a href=\"#2-识别两类任务\" class=\"headerlink\" title=\"2.识别两类任务\"></a>2.识别两类任务</h3><p><img src=\"/2023/01/03/openmp001/image-20230106164847677.png\" alt=\"image-20230106164847677\"></p>\n<ol>\n<li>单个梯形的面积计算</li>\n<li>梯形面积求和</li>\n</ol>\n<p>在2.1的任务中，没有任务间的通信，但这一组任务中的每一组任务都与2.2的任务通信</p>\n<h3 id=\"3-累加线程结果\"><a href=\"#3-累加线程结果\" class=\"headerlink\" title=\"3.累加线程结果\"></a>3.累加线程结果</h3><p>​\t使用一个共享变量作为所有线程的和 ，每个线程可以将它计算的部分结果累加到共享变量中，让每个线程执行类似下面的语句：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp critical</span><br>global_result += myresult;                <span class=\"hljs-comment\">//需要互斥访问</span><br></code></pre></div></td></tr></table></figure>\n\n<p>竞争条件，使用临界区解决。保证每次只有一个线程执行这段结构性代码。</p>\n<h3 id=\"4-程序完整代码\"><a href=\"#4-程序完整代码\" class=\"headerlink\" title=\"4.程序完整代码\"></a>4.程序完整代码</h3><figure class=\"highlight c++\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdlib.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;omp.h&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">Trap</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">double</span> a,<span class=\"hljs-keyword\">double</span> b,<span class=\"hljs-keyword\">int</span> n,<span class=\"hljs-keyword\">double</span> *global_result_p)</span></span>;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> argc, <span class=\"hljs-keyword\">char</span> *argv[])</span></span>&#123;<br>\t<span class=\"hljs-keyword\">double</span> global_result = <span class=\"hljs-number\">0.0</span>;<br>\t<span class=\"hljs-keyword\">double</span> a,b;\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//为了区分local_a,local_b</span><br>\t<span class=\"hljs-keyword\">int</span> n;<br>\t<span class=\"hljs-keyword\">int</span> thread_count;<br>\t<br>\tthread_count = <span class=\"hljs-number\">8</span>;                                      \t<span class=\"hljs-comment\">//指定你的线程数</span><br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Enter a,b, and n\\n&quot;</span>);<br>\t<span class=\"hljs-built_in\">scanf</span>(<span class=\"hljs-string\">&quot;%lf %lf %d&quot;</span>,&amp;a,&amp;b,&amp;n);<br>    <br>    <span class=\"hljs-comment\">//并行区开始</span><br>\t<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp parallel num_threads(thread_count)\t\t\t<span class=\"hljs-comment\">//指定Trap函数由thread_count个线程执行</span></span><br>\t<span class=\"hljs-built_in\">Trap</span>(a,b,n,&amp;global_result);<br>\t<span class=\"hljs-comment\">//并行区结束</span><br>    <br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;With n = %d trapezoids, our estimate\\n&quot;</span>,n);<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;of the integral from %f to %f = %.4lf\\n&quot;</span>,a,b,global_result);<br>\t<br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">Trap</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">double</span> a,<span class=\"hljs-keyword\">double</span> b,<span class=\"hljs-keyword\">int</span> n,<span class=\"hljs-keyword\">double</span> *global_result_p)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>\t<span class=\"hljs-keyword\">double</span> h,x,my_result;<br>\t<span class=\"hljs-keyword\">double</span> local_a,local_b;<br>\t<span class=\"hljs-keyword\">int</span> i,local_n;\t\t\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//local_n代表本进程被分配了多少个任务</span><br>\t<span class=\"hljs-keyword\">int</span> my_rank = <span class=\"hljs-built_in\">omp_get_thread_num</span>();<br>\t<span class=\"hljs-keyword\">int</span> thread_count = <span class=\"hljs-built_in\">omp_get_num_threads</span>();<br>\t<br>\th = (b-a)/n;\t\t\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//梯形底的长度</span><br>\tlocal_n = n/thread_count;\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//每个线程分配的梯形数，保证能整除</span><br>\tlocal_a = a + my_rank*local_n*h;\t\t\t\t\t\t<span class=\"hljs-comment\">//区间的左端点</span><br>\tlocal_b = local_a + local_n*h;\t\t\t\t\t\t\t<span class=\"hljs-comment\">//区间的右端点</span><br>\t<span class=\"hljs-comment\">//对global_result共享部分和</span><br>    my_result = (<span class=\"hljs-built_in\">f</span>(local_a) + <span class=\"hljs-built_in\">f</span>(local_b))/<span class=\"hljs-number\">2.0</span>;\t\t\t\t<span class=\"hljs-comment\">//f(x)是目标函数</span><br>\t<span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">1</span> ; i&lt;=local_n<span class=\"hljs-number\">-1</span>; i++)&#123;<br>\t\tx = local_a + i*h;<br>\t\tmy_result += <span class=\"hljs-built_in\">f</span>(x);<br>\t&#125;<br>\tmy_result = my_result*h;<br>    <span class=\"hljs-comment\">//</span><br>\t<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">pragma</span> omp critical\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//临界区，这里可以直接使用OpenMP提供的reduction</span></span><br>\t*global_result_p += my_result;\t\t\t\t\t\t\t<span class=\"hljs-comment\">//线程将部分和结果累加到共享变量</span><br>&#125;<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"5-总结\"><a href=\"#5-总结\" class=\"headerlink\" title=\"5.总结\"></a>5.总结</h3><ol>\n<li>核心是拆分任务区域，把子任务分配到个个线程</li>\n<li>共享变量的选取决定了可并行度</li>\n<li>通过共享变量实现了归约的操作(这里使用到了临界区)</li>\n</ol>\n<h3 id=\"6-参考资料\"><a href=\"#6-参考资料\" class=\"headerlink\" title=\"6.参考资料\"></a>6.参考资料</h3><p>并行程序导论 （美）Peter S.Pacheco</p>\n",
            "tags": [
                "OpenMP"
            ]
        }
    ]
}