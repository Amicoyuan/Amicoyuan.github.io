{
    "version": "https://jsonfeed.org/version/1",
    "title": "Amicoyuan • All posts by \"avx\" tag",
    "description": "",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2022/06/12/AVX%E5%90%91%E9%87%8F%E5%8C%96%E5%AD%A6%E4%B9%A0(%E4%BA%8C)-%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90%E7%9A%84%E5%BA%94%E7%94%A8/",
            "url": "http://example.com/2022/06/12/AVX%E5%90%91%E9%87%8F%E5%8C%96%E5%AD%A6%E4%B9%A0(%E4%BA%8C)-%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90%E7%9A%84%E5%BA%94%E7%94%A8/",
            "title": "AVX向量化学习(二)-内存对齐的应用",
            "date_published": "2022-06-12T07:11:29.549Z",
            "content_html": "<h1 id=\"AVX指令集的简单操作-内存对齐版\"><a href=\"#AVX指令集的简单操作-内存对齐版\" class=\"headerlink\" title=\"AVX指令集的简单操作(内存对齐版)\"></a>AVX指令集的简单操作(内存对齐版)</h1><p>使用AVX指令集进行2个double型的数组相加操作</p>\n<h2 id=\"常用的内存对齐函数\"><a href=\"#常用的内存对齐函数\" class=\"headerlink\" title=\"常用的内存对齐函数\"></a>常用的内存对齐函数</h2><p>因为AVX中要求mem__addr必须在32字节边界上对齐，否则可能会产生通用保护异常。  </p>\n<h3 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1.\"></a>1.</h3><pre><code class=\"c++\">double*\ta =(double*)memalign(32,9*sizeof(double));\n</code></pre>\n<h3 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2.\"></a>2.</h3><pre><code class=\"c++\">double*\ta =(double*)_mm_malloc(9*sizeof(double),32);\n</code></pre>\n<h3 id=\"3\"><a href=\"#3\" class=\"headerlink\" title=\"3.\"></a>3.</h3><pre><code class=\"c++\">double*\ta =(double*)aligned_alloc(32,9*sizeof(double));\n</code></pre>\n<h3 id=\"4\"><a href=\"#4\" class=\"headerlink\" title=\"4.\"></a>4.</h3><pre><code class=\"c++\">__attribute__ ((aligned(32)))double a[9]  =&#123;1.1,2.2,3.3,4.4,5.5,6.6,7.7,8.8,2.1&#125;;\n</code></pre>\n<h2 id=\"使用到的AVX函数介绍\"><a href=\"#使用到的AVX函数介绍\" class=\"headerlink\" title=\"使用到的AVX函数介绍\"></a>使用到的AVX函数介绍</h2><h3 id=\"1-1\"><a href=\"#1-1\" class=\"headerlink\" title=\"1.\"></a>1.</h3><pre><code class=\"c++\">__m256d _mm256_load_pd (double const * mem_addr)\n</code></pre>\n<p><strong>Description</strong></p>\n<p>Load 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from memory into dst. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.</p>\n<p><strong>Operation</strong></p>\n<pre><code class=\"c++\">dst[255:0] := MEM[mem_addr+255:mem_addr]\ndst[MAX:256] := 0\n</code></pre>\n<h3 id=\"2-1\"><a href=\"#2-1\" class=\"headerlink\" title=\"2.\"></a>2.</h3><pre><code class=\"c++\">__m256 _mm256_add_ps (__m256 a, __m256 b)\n</code></pre>\n<p><strong>Description</strong></p>\n<p>Add packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst.</p>\n<p><strong>Operation</strong></p>\n<pre><code>FOR j := 0 to 7\n    i := j*32\n    dst[i+31:i] := a[i+31:i] + b[i+31:i]\nENDFOR\ndst[MAX:256] := 0\n</code></pre>\n<h3 id=\"3-stream的作用：绕过缓存直接写入内存\"><a href=\"#3-stream的作用：绕过缓存直接写入内存\" class=\"headerlink\" title=\"3.stream的作用：绕过缓存直接写入内存\"></a>3.stream的作用：绕过缓存直接写入内存</h3><pre><code class=\"c++\">void _mm256_stream_pd (double * mem_addr, __m256d a)\n</code></pre>\n<p><strong>Description</strong></p>\n<p>Store 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from a into memory using a non-temporal memory hint. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.</p>\n<p><strong>Operation</strong></p>\n<pre><code class=\"c++\">MEM[mem_addr+255:mem_addr] := a[255:0]\n</code></pre>\n<h2 id=\"样例程序举例：\"><a href=\"#样例程序举例：\" class=\"headerlink\" title=\"样例程序举例：\"></a>样例程序举例：</h2><pre><code class=\"c++\">#include&lt;stdio.h&gt;\n#include&lt;malloc.h&gt;\n#include &lt;immintrin.h&gt;\nint main()\n&#123;\n    double*\ta =(double*)memalign(32,9*sizeof(double));\n    double*\tb =(double*)memalign(32,4*sizeof(double));\n    double af[9]=&#123;1.1,2.2,3.3,4.4,5.5,6.6,7.7,8.8,2.1&#125; ;\n    double bf[9]=&#123;2.1,3.2,6.4,8.6,3.7,9.9,5.1,4.2,6.6&#125;;\n    double*\tc =(double*)memalign(32,4*sizeof(double));\n    for(int i =0;i&lt;9;i++)\n    &#123;\n        a[i]=af[i];\n        b[i]=bf[i];\n    &#125;\n    int i=0;\n    __m256d v0;\n    __m256d v1;\n    __m256d v2;\n    for(;i&lt;9-4;i+=4)\n    &#123;\t\n            v0 = _mm256_load_pd(a+i);\n            v1 = _mm256_load_pd(b+i);\n            v2=_mm256_add_pd(v0,v1);\n         \t_mm256_stream_pd(c+i,v2);\n            \n    &#125;\n    for(;i&lt;9;i++)\n    &#123;\n        c[i]=a[i]+b[i];\n    \n    &#125;\n    printf(&quot;this is c.\\n&quot;);\n        for(int i=0;i&lt;9;i++)\n    &#123;\n        printf(&quot;%lf\\n&quot;,c[i]);\n    &#125;\n    return 0;\n &#125; \n</code></pre>\n<h2 id=\"样例程序输出：\"><a href=\"#样例程序输出：\" class=\"headerlink\" title=\"样例程序输出：\"></a>样例程序输出：</h2><pre><code class=\"c++\">this is c.\n3.200000\n5.400000\n9.700000\n13.000000\n9.200000\n16.500000\n12.800000\n13.000000\n8.700000\n</code></pre>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><p>[<a href=\"https://software.intel.com/sites/landingpage/IntrinsicsGuide/]\">https://software.intel.com/sites/landingpage/IntrinsicsGuide/]</a>: \t“Intel® Intrinsics Guide”</p>\n",
            "tags": [
                "AVX"
            ]
        },
        {
            "id": "http://example.com/2022/06/12/AVX%E5%90%91%E9%87%8F%E5%8C%96%E5%AD%A6%E4%B9%A0(%E4%B8%80)/",
            "url": "http://example.com/2022/06/12/AVX%E5%90%91%E9%87%8F%E5%8C%96%E5%AD%A6%E4%B9%A0(%E4%B8%80)/",
            "title": "AVX向量化学习(一)",
            "date_published": "2022-06-12T07:11:29.538Z",
            "content_html": "<h1 id=\"AVX指令集的简单操作\"><a href=\"#AVX指令集的简单操作\" class=\"headerlink\" title=\"AVX指令集的简单操作\"></a>AVX指令集的简单操作</h1><p>使用AVX指令集进行2个double型的数组相加操作</p>\n<h2 id=\"使用到的AVX函数介绍\"><a href=\"#使用到的AVX函数介绍\" class=\"headerlink\" title=\"使用到的AVX函数介绍\"></a>使用到的AVX函数介绍</h2><h3 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1.\"></a>1.</h3><pre><code class=\"c++\">__m256 _mm256_loadu_ps (float const * mem_addr)\n</code></pre>\n<h3 id=\"Description\"><a href=\"#Description\" class=\"headerlink\" title=\"Description\"></a>Description</h3><p>Load 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from memory into dst. mem_addr does not need to be aligned on any particular boundary.</p>\n<h3 id=\"Operation\"><a href=\"#Operation\" class=\"headerlink\" title=\"Operation\"></a>Operation</h3><pre><code class=\"c++\">dst[255:0] := MEM[mem_addr+255:mem_addr]\ndst[MAX:256] := 0\n</code></pre>\n<h3 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2.\"></a>2.</h3><pre><code class=\"c++\">__m256d _mm256_add_pd (__m256d a, __m256d b)\n</code></pre>\n<h3 id=\"Description-1\"><a href=\"#Description-1\" class=\"headerlink\" title=\"Description\"></a>Description</h3><p>Add packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst.</p>\n<h3 id=\"Operation-1\"><a href=\"#Operation-1\" class=\"headerlink\" title=\"Operation\"></a>Operation</h3><pre><code class=\"c++\">FOR j := 0 to 3\n    i := j*64\n    dst[i+63:i] := a[i+63:i] + b[i+63:i]\nENDFOR\ndst[MAX:256] := 0\n</code></pre>\n<h3 id=\"3\"><a href=\"#3\" class=\"headerlink\" title=\"3.\"></a>3.</h3><pre><code class=\"c++\">void _mm256_storeu_pd (double * mem_addr, __m256d a)\n</code></pre>\n<h3 id=\"Description-2\"><a href=\"#Description-2\" class=\"headerlink\" title=\"Description\"></a>Description</h3><p>Store 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from a into memory. mem_addr does not need to be aligned on any particular boundary.</p>\n<h3 id=\"Operation-2\"><a href=\"#Operation-2\" class=\"headerlink\" title=\"Operation\"></a>Operation</h3><pre><code class=\"c++\">MEM[mem_addr+255:mem_addr] := a[255:0]\n</code></pre>\n<h2 id=\"未进行AVX向量化的情况\"><a href=\"#未进行AVX向量化的情况\" class=\"headerlink\" title=\"未进行AVX向量化的情况\"></a>未进行AVX向量化的情况</h2><h3 id=\"程序源代码\"><a href=\"#程序源代码\" class=\"headerlink\" title=\"程序源代码\"></a>程序源代码</h3><pre><code class=\"c++\">#include&lt;stdio.h&gt;\nint main()\n&#123;\n    double a[9] = &#123;1.1,2.2,3.3,4.4,5.5,6.6,7.7,8.8,2.1&#125;;\n    double b[9] = &#123;2.1,3.2,6.4,8.6,3.7,9.9,5.1,4.2,6.6&#125;;\n    double c[9] = &#123;0&#125;;\n    \n    for(int i=0 ;i&lt;9;i++)\t\n    &#123;\n        c[i]=a[i]+b[i];\n        \n    &#125;\n    \n    printf(&quot;this is c.\\n&quot;);\n    for(int i=0;i&lt;9;i++)\n    &#123;\n        printf(&quot;%lf\\n&quot;,c[i]);\n    &#125;\n    \n    return 0;\n &#125; \n</code></pre>\n<h3 id=\"程序输出\"><a href=\"#程序输出\" class=\"headerlink\" title=\"程序输出\"></a>程序输出</h3><pre><code class=\"c++\">this is c.\n3.200000\n5.400000\n9.700000\n13.000000\n9.200000\n16.500000\n12.800000\n13.000000\n8.700000\n</code></pre>\n<h2 id=\"进行AVX向量化的情况\"><a href=\"#进行AVX向量化的情况\" class=\"headerlink\" title=\"进行AVX向量化的情况\"></a>进行AVX向量化的情况</h2><h3 id=\"程序源代码-1\"><a href=\"#程序源代码-1\" class=\"headerlink\" title=\"程序源代码\"></a>程序源代码</h3><pre><code class=\"c++\">#include&lt;stdio.h&gt;\n#include &lt;immintrin.h&gt;\nint main()\n&#123;\n    double a[9] = &#123;1.1,2.2,3.3,4.4,5.5,6.6,7.7,8.8,2.1&#125;;\n    double b[9] = &#123;2.1,3.2,6.4,8.6,3.7,9.9,5.1,4.2,6.6&#125;;\n    double c[9] = &#123;0&#125;;\n    __m256d v0;\n    __m256d v1;\n    __m256d v2;\n    int i=0;\n    for(;i&lt;9-4;i+=4)\n    &#123;\t\n            v0 = _mm256_loadu_pd(a+i);\n            v1 = _mm256_loadu_pd(b+i);\n            v2=_mm256_add_pd(v0,v1);\n         \t_mm256_storeu_pd(c+i,v2);\n            \n    &#125;\n    for(;i&lt;9;i++)\n    &#123;\n        c[i]=a[i]+b[i];\n    \n    &#125;\n    printf(&quot;this is c with AVX.\\n&quot;);\n        for(int i=0;i&lt;9;i++)\n    &#123;\n        printf(&quot;%lf\\n&quot;,c[i]);\n    &#125;\n\n    return 0;\n &#125; \n</code></pre>\n<h3 id=\"程序输出-1\"><a href=\"#程序输出-1\" class=\"headerlink\" title=\"程序输出\"></a>程序输出</h3><pre><code class=\"c++\">this is c with AVX.\n3.200000\n5.400000\n9.700000\n13.000000\n9.200000\n16.500000\n12.800000\n13.000000\n8.700000\n</code></pre>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><p>[<a href=\"https://software.intel.com/sites/landingpage/IntrinsicsGuide/]\">https://software.intel.com/sites/landingpage/IntrinsicsGuide/]</a>: \t“ Intel® Intrinsics Guide”</p>\n",
            "tags": [
                "AVX"
            ]
        },
        {
            "id": "http://example.com/2022/01/17/AVX005/",
            "url": "http://example.com/2022/01/17/AVX005/",
            "title": "AVX向量化学习(五)-INT型数组相加操作",
            "date_published": "2022-01-17T13:28:22.000Z",
            "content_html": "<h1 id=\"AVX向量化学习-五-INT型数组相加操作\"><a href=\"#AVX向量化学习-五-INT型数组相加操作\" class=\"headerlink\" title=\"AVX向量化学习(五)-INT型数组相加操作\"></a>AVX向量化学习(五)-INT型数组相加操作</h1><p>使用AVX指令集进行2个INT型的数组相加操作</p>\n<h2 id=\"使用到的AVX函数介绍\"><a href=\"#使用到的AVX函数介绍\" class=\"headerlink\" title=\"使用到的AVX函数介绍\"></a>使用到的AVX函数介绍</h2><h3 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1.\"></a>1.</h3><pre><code class=\"c++\">__m256i _mm256_loadu_si256 (__m256i const * mem_addr)\n</code></pre>\n<p><strong>Synopsis</strong></p>\n<p>m256i _mm256_loadu_si256 (m256i const * mem_addr)<br>#include &lt;immintrin.h&gt;<br>Instruction: vmovdqu ymm, m256<br>CPUID Flags: AVX</p>\n<p><strong>Description</strong></p>\n<p>Load 256-bits of integer data from memory into dst. mem_addr does not need to be aligned on any particular boundary.</p>\n<p><strong>Operation</strong></p>\n<pre><code class=\"c++\">dst[255:0] := MEM[mem_addr+255:mem_addr] \ndst[MAX:256] := 0\n</code></pre>\n<p><strong>Performance</strong></p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Architecture</th>\n<th align=\"center\">Latency</th>\n<th align=\"center\">Throughput (CPI)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Icelake</td>\n<td align=\"center\">7</td>\n<td align=\"center\">0.5</td>\n</tr>\n<tr>\n<td align=\"left\">Skylake</td>\n<td align=\"center\">7</td>\n<td align=\"center\">0.5</td>\n</tr>\n<tr>\n<td align=\"left\">Broadwell</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0.25</td>\n</tr>\n<tr>\n<td align=\"left\">Haswell</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0.25</td>\n</tr>\n<tr>\n<td align=\"left\">Ivy Bridge</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0.5</td>\n</tr>\n</tbody></table>\n<h3 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2.\"></a>2.</h3><pre><code class=\"c++\">__m256i _mm256_add_epi32 (__m256i a, __m256i b)\n</code></pre>\n<p><strong>Synopsis</strong></p>\n<p>m256i _mm256_add_epi32 (m256i a, __m256i b)<br>#include &lt;immintrin.h&gt;<br>Instruction: vpaddd ymm, ymm, ymm<br>CPUID Flags: AVX2</p>\n<p><strong>Description</strong></p>\n<p>Add packed 32-bit integers in a and b, and store the results in dst.</p>\n<p><strong>Operation</strong></p>\n<pre><code>FOR j := 0 to 7 \n         i := j*32 \n         dst[i+31:i] := a[i+31:i] + b[i+31:i] \nENDFOR \ndst[MAX:256] := 0\n</code></pre>\n<p><strong>Performance</strong></p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Architecture</th>\n<th align=\"center\">Latency</th>\n<th align=\"center\">Throughput (CPI)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Icelake</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0.33</td>\n</tr>\n<tr>\n<td align=\"left\">Skylake</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0.33</td>\n</tr>\n<tr>\n<td align=\"left\">Broadwell</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0.5</td>\n</tr>\n<tr>\n<td align=\"left\">Haswell</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0.5</td>\n</tr>\n</tbody></table>\n<h2 id=\"程序源代码\"><a href=\"#程序源代码\" class=\"headerlink\" title=\"程序源代码\"></a>程序源代码</h2><pre><code class=\"c++\">#include&lt;stdio.h&gt;\n#include &lt;immintrin.h&gt;\nint main()\n&#123;\n    int a[40];\n    int b[40];\n    int i=0;\n    int ans1[40];    //记录串行结果 \n    int ans2[40];\t //记录AVX向量化后的结果\n    for (i=0;i&lt;40;i++)\n    &#123;\n        a[i]=i;\n        b[i]=2*i;\n    &#125;\n    for (i=0;i&lt;40;i++)\n    &#123;\n        ans1[i]=a[i]+b[i];\n    &#125;\n    printf(&quot;串行计算结果：\\n&quot;);\n    for (i=0;i&lt;40;i++)\n    &#123;\n        printf(&quot;%d &quot;,ans1[i]);\n    &#125;\n    printf(&quot;\\n&quot;);\n    __m256i v0;\n    __m256i v1;\n    __m256i v2;\n    for (i=0;i&lt;40-8;i+=8)\n    &#123;\t\n        v0 = _mm256_loadu_si256((const __m256i*)(a+i));\t //强制类型转换\n        v1 = _mm256_loadu_si256((const __m256i*)(b+i));\t //强制类型转化\n        v2 = _mm256_add_epi32(v0,v1);     //v0+v1\n        _mm256_storeu_si256((__m256i*)(ans2+i),v2);\n        \n    &#125;//边界处理\n    for (;i&lt;40;i++)\n    &#123;\n        ans2[i]=a[i]+b[i];\n    &#125;\n    printf(&quot;并行计算结果：\\n&quot;);\n    for (i=0;i&lt;40;i++)\n    &#123;\n        printf(&quot;%d &quot;,ans2[i]);\n    &#125;\n    return 0; \n&#125;\n</code></pre>\n<h2 id=\"程序输出\"><a href=\"#程序输出\" class=\"headerlink\" title=\"程序输出\"></a>程序输出</h2><pre><code class=\"c++\">串行计算结果：\n0 3 6 9 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60 63 66 69 72 75 78 81 84 87 90 93 96 99 102 105 108 111 114 117\n并行计算结果：\n0 3 6 9 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60 63 66 69 72 75 78 81 84 87 90 93 96 99 102 105 108 111 114 117\n</code></pre>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><p>[<a href=\"https://software.intel.com/sites/landingpage/IntrinsicsGuide/]\">https://software.intel.com/sites/landingpage/IntrinsicsGuide/]</a>: \t“ Intel® Intrinsics Guide”</p>\n",
            "tags": [
                "AVX"
            ]
        },
        {
            "id": "http://example.com/2022/01/17/AVX004/",
            "url": "http://example.com/2022/01/17/AVX004/",
            "title": "AVX向量化学习(四)-INT类型转化成DOUBLE类型",
            "date_published": "2022-01-17T12:41:56.000Z",
            "content_html": "<h1 id=\"AVX向量化学习-四-INT类型转化成DOUBLE类型\"><a href=\"#AVX向量化学习-四-INT类型转化成DOUBLE类型\" class=\"headerlink\" title=\"AVX向量化学习(四)-INT类型转化成DOUBLE类型\"></a>AVX向量化学习(四)-INT类型转化成DOUBLE类型</h1><p>使用AVX指令集把INT类型转化为DOUBLE类型</p>\n<h2 id=\"使用到的AVX函数介绍\"><a href=\"#使用到的AVX函数介绍\" class=\"headerlink\" title=\"使用到的AVX函数介绍\"></a>使用到的AVX函数介绍</h2><h3 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1.\"></a>1.</h3><pre><code class=\"c++\">__m128i _mm_setr_epi32 (int e3, int e2, int e1, int e0)\n</code></pre>\n<p><strong>Synopsis</strong></p>\n<p>__m128i _mm_setr_epi32 (int e3, int e2, int e1, int e0)<br>#include &lt;emmintrin.h&gt;<br>Instruction: <strong>Sequence</strong><br>CPUID Flags: SSE2</p>\n<p><strong>Description</strong></p>\n<p>Set packed 32-bit integers in dst with the supplied values in reverse order.</p>\n<p><strong>Operation</strong></p>\n<pre><code class=\"c++\">dst[31:0] := e3 \ndst[63:32] := e2 \ndst[95:64] := e1 \ndst[127:96] := e0\n</code></pre>\n<h3 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2.\"></a>2.</h3><pre><code class=\"c++\">__m256d _mm256_cvtepi32_pd (__m128i a)\n</code></pre>\n<p><strong>Synopsis</strong></p>\n<p>m256d _mm256_cvtepi32_pd (m128i a)<br>#include &lt;immintrin.h&gt;<br>Instruction: vcvtdq2pd ymm, xmm<br>CPUID Flags: AVX</p>\n<p><strong>Description</strong></p>\n<p>Convert packed signed 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.</p>\n<p><strong>Operation</strong></p>\n<pre><code class=\"c++\">FOR j := 0 to 3 \n    i := j*32 \n    m := j*64 \n    dst[m+63:m] := Convert_Int32_To_FP64(a[i+31:i]) \nENDFOR \ndst[MAX:256] := 0\n</code></pre>\n<p><strong>Performance</strong></p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Architecture</th>\n<th align=\"center\">Latency</th>\n<th align=\"center\">Throughput (CPI)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Icelake</td>\n<td align=\"center\">7</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"left\">Skylake</td>\n<td align=\"center\">7</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"left\">Broadwell</td>\n<td align=\"center\">6</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"left\">Haswell</td>\n<td align=\"center\">6</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"left\">Ivy Bridge</td>\n<td align=\"center\">4</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<h2 id=\"程序运行平台\"><a href=\"#程序运行平台\" class=\"headerlink\" title=\"程序运行平台\"></a>程序运行平台</h2><p>北京超级云计算中心A3分区</p>\n<h2 id=\"编译指令\"><a href=\"#编译指令\" class=\"headerlink\" title=\"编译指令\"></a>编译指令</h2><p>g++ int_to_double.cpp -msse2 -mavx -o test01</p>\n<h2 id=\"运行指令\"><a href=\"#运行指令\" class=\"headerlink\" title=\"运行指令\"></a>运行指令</h2><p>.&#x2F;test01</p>\n<h2 id=\"程序源代码\"><a href=\"#程序源代码\" class=\"headerlink\" title=\"程序源代码\"></a>程序源代码</h2><pre><code class=\"c++\">#include &lt;iostream&gt;\n#include &lt;immintrin.h&gt;\nusing namespace std;\nint main()\n&#123;\n    int a[4]=&#123;1,2,3,4&#125;;\n    double b[9]=&#123;0&#125;;\n    __m128i x = _mm_setr_epi32(a[0], a[1], a[2],a[3]);   //load\n     __m256d v5=_mm256_cvtepi32_pd(x);       //convert\n    _mm256_storeu_pd(b,v5);\n    for(int i=0;i&lt;9;i++)\n    &#123;\n        cout&lt;&lt;b[i]&lt;&lt;endl;\n    &#125;\n\n    return 0;\n&#125;\n</code></pre>\n<h2 id=\"程序输出\"><a href=\"#程序输出\" class=\"headerlink\" title=\"程序输出\"></a>程序输出</h2><pre><code class=\"c++\">1\n2\n3\n4\n0\n0\n0\n0\n0\n</code></pre>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><p>[<a href=\"https://software.intel.com/sites/landingpage/IntrinsicsGuide/]\">https://software.intel.com/sites/landingpage/IntrinsicsGuide/]</a>: \t“ Intel® Intrinsics Guide”</p>\n",
            "tags": [
                "AVX"
            ]
        },
        {
            "id": "http://example.com/2021/11/24/AVX003/",
            "url": "http://example.com/2021/11/24/AVX003/",
            "title": "AVX向量化学习(三)-if判断的处理",
            "date_published": "2021-11-24T09:42:35.000Z",
            "content_html": "<h1 id=\"AVX-if判断的处理\"><a href=\"#AVX-if判断的处理\" class=\"headerlink\" title=\"AVX-if判断的处理\"></a>AVX-if判断的处理</h1><p>使用AVX指令集对if判断进行处理</p>\n<h2 id=\"使用到的AVX函数介绍\"><a href=\"#使用到的AVX函数介绍\" class=\"headerlink\" title=\"使用到的AVX函数介绍\"></a>使用到的AVX函数介绍</h2><h3 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1.\"></a>1.</h3><pre><code class=\"c++\">__m256d _mm256_blendv_pd (__m256d a, __m256d b, __m256d mask)\n</code></pre>\n<p><strong>Description</strong></p>\n<p>Blend packed double-precision (64-bit) floating-point elements from a and b using mask, and store the results in dst.</p>\n<p><strong>Operation</strong></p>\n<pre><code class=\"c++\">FOR j := 0 to 3\n    i := j*64\n    IF mask[i+63]\n        dst[i+63:i] := b[i+63:i]\n    ELSE\n        dst[i+63:i] := a[i+63:i]\n    FI\nENDFOR\ndst[MAX:256] := 0\n</code></pre>\n<h3 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2.\"></a>2.</h3><pre><code class=\"c++\">__m256d _mm256_cmp_pd (__m256d a, __m256d b, const int imm8)\n</code></pre>\n<p><strong>Description</strong></p>\n<p>Compare packed double-precision (64-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in dst.</p>\n<p><strong>Operation</strong></p>\n<pre><code class=\"c++\">CASE (imm8[4:0]) OF\n0: OP := _CMP_EQ_OQ\n1: OP := _CMP_LT_OS\n2: OP := _CMP_LE_OS\n3: OP := _CMP_UNORD_Q \n4: OP := _CMP_NEQ_UQ\n5: OP := _CMP_NLT_US\n6: OP := _CMP_NLE_US\n7: OP := _CMP_ORD_Q\n8: OP := _CMP_EQ_UQ\n9: OP := _CMP_NGE_US\n10: OP := _CMP_NGT_US\n11: OP := _CMP_FALSE_OQ\n12: OP := _CMP_NEQ_OQ\n13: OP := _CMP_GE_OS\n14: OP := _CMP_GT_OS\n15: OP := _CMP_TRUE_UQ\n16: OP := _CMP_EQ_OS\n17: OP := _CMP_LT_OQ\n18: OP := _CMP_LE_OQ\n19: OP := _CMP_UNORD_S\n20: OP := _CMP_NEQ_US\n21: OP := _CMP_NLT_UQ\n22: OP := _CMP_NLE_UQ\n23: OP := _CMP_ORD_S\n24: OP := _CMP_EQ_US\n25: OP := _CMP_NGE_UQ \n26: OP := _CMP_NGT_UQ \n27: OP := _CMP_FALSE_OS \n28: OP := _CMP_NEQ_OS \n29: OP := _CMP_GE_OQ\n30: OP := _CMP_GT_OQ\n31: OP := _CMP_TRUE_US\nESAC\nFOR j := 0 to 3\n    i := j*64\n    dst[i+63:i] := ( a[i+63:i] OP b[i+63:i] ) ? 0xFFFFFFFFFFFFFFFF : 0\nENDFOR\ndst[MAX:256] := 0\n</code></pre>\n<h2 id=\"程序源代码\"><a href=\"#程序源代码\" class=\"headerlink\" title=\"程序源代码\"></a>程序源代码</h2><pre><code class=\"c++\">#include&lt;stdio.h&gt;\n#include &lt;immintrin.h&gt;\nint main()\n&#123;\n    double a[9]=&#123;1.1,2.2,3.3,4.4,5.5,6.6,7.7,8.8,2.1&#125;;\n    double b[9]=&#123;2.1,3.2,6.4,8.6,3.7,9.9,5.1,4.2,6.6&#125;;\n    double d[9]=&#123;0&#125;;     //记录原始if判断后的值\n    double e[9]=&#123;0&#125;;     //记录AVX-if判断后的值\n    \n    __m256d v0;\n    __m256d v1;\n    __m256d v2,v3;\n    __m256d v4;\n    \n    for(int i=0;i&lt;9;i++)\n    &#123;\n        if(a[i]&gt;b[i])\n        &#123;\n            d[i] = a[i];\n        &#125;\n        else\n        &#123;\n            d[i]=b[i];\n        &#125;\n    &#125;\n\n    int i=0;\n    \n    for(;i&lt;9-4;i+=4)\n    &#123;\t\n            v0 = _mm256_loadu_pd(a+i);\n            v1 = _mm256_loadu_pd(b+i);\n            v2=_mm256_add_pd(v0,v1);\n            v3 =_mm256_blendv_pd(v0,v1,_mm256_cmp_pd(v0,v1,_CMP_LE_OQ));\n            _mm256_storeu_pd(e+i,v3);\n            \n    &#125;\n    \n    for(;i&lt;9;i++)\n    &#123;\n        if(a[i]&gt;b[i])\n        &#123;\n            e[i] = a[i];\n        &#125;\n        else\n        &#123;\n            e[i]=b[i];\n        &#125;\n    &#125;\n    \n    printf(&quot;this is d.\\n&quot;);\n        for(int i=0;i&lt;9;i++)\n    &#123;\n        printf(&quot;%lf\\n&quot;,d[i]);\n    &#125;\n    \n    printf(&quot;this is e with AVX.\\n&quot;);\n        for(int i=0;i&lt;9;i++)\n    &#123;\n        printf(&quot;%lf\\n&quot;,e[i]);\n    &#125;\n    return 0;\n &#125; \n</code></pre>\n<h2 id=\"程序输出\"><a href=\"#程序输出\" class=\"headerlink\" title=\"程序输出\"></a>程序输出</h2><pre><code class=\"c++\">this is d.\n2.100000\n3.200000\n6.400000\n8.600000\n5.500000\n9.900000\n7.700000\n8.800000\n6.600000\nthis is e with AVX.\n2.100000\n3.200000\n6.400000\n8.600000\n5.500000\n9.900000\n7.700000\n8.800000\n6.600000\n</code></pre>\n<h2 id=\"相关链接\"><a href=\"#相关链接\" class=\"headerlink\" title=\"相关链接\"></a>相关链接</h2><p>[<a href=\"https://software.intel.com/sites/landingpage/IntrinsicsGuide/]\">https://software.intel.com/sites/landingpage/IntrinsicsGuide/]</a>: \t“ Intel® Intrinsics Guide”</p>\n<p>[<a href=\"https://stackoverflow.com/questions/16988199/how-to-choose-avx-compare-predicate-variants\">simd - How to choose AVX compare predicate variants - Stack Overflow</a>]: \t“Stack Overflow”</p>\n<p>[<a href=\"https://www.officedaytime.com/simd512e/simdimg/si.php?f=blendvpd\">blendvpd (officedaytime.com)</a>]: \t“_mm256_Blendv_pd()原理解释”</p>\n",
            "tags": [
                "AVX"
            ]
        }
    ]
}