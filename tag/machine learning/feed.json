{
    "version": "https://jsonfeed.org/version/1",
    "title": "Amicoyuan â€¢ All posts by \"machine learning\" tag",
    "description": "",
    "home_page_url": "https://xingyuanjie.top",
    "items": [
        {
            "id": "https://xingyuanjie.top/2023/03/13/ML003/",
            "url": "https://xingyuanjie.top/2023/03/13/ML003/",
            "title": "çº¿æ€§å›å½’çš„æ¢¯åº¦ä¸‹é™",
            "date_published": "2023-03-13T06:37:12.000Z",
            "content_html": "<h2 id=\"çº¿æ€§å›å½’çš„æ¢¯åº¦ä¸‹é™\"><a href=\"#çº¿æ€§å›å½’çš„æ¢¯åº¦ä¸‹é™\" class=\"headerlink\" title=\"çº¿æ€§å›å½’çš„æ¢¯åº¦ä¸‹é™\"></a>çº¿æ€§å›å½’çš„æ¢¯åº¦ä¸‹é™</h2><p><img src=\"/2023/03/13/ML003/image-20230313145346118.png\" alt=\"image-20230313145346118\"></p>\n<h2 id=\"Goals\"><a href=\"#Goals\" class=\"headerlink\" title=\"Goals\"></a>Goals</h2><p>åœ¨æœ¬å®éªŒä¸­ï¼Œæ‚¨å°†:</p>\n<ul>\n<li>ä½¿ç”¨æ¢¯åº¦ä¸‹é™è‡ªåŠ¨ä¼˜åŒ–wå’Œbçš„è¿‡ç¨‹</li>\n</ul>\n<h2 id=\"Tools\"><a href=\"#Tools\" class=\"headerlink\" title=\"Tools\"></a>Tools</h2><p>åœ¨æœ¬å®éªŒä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨:</p>\n<ul>\n<li>NumPyï¼Œä¸€ä¸ªç”¨äºç§‘å­¦è®¡ç®—çš„æµè¡Œåº“</li>\n<li>Matplotlibï¼Œç”¨äºç»˜åˆ¶æ•°æ®çš„æµè¡Œåº“</li>\n<li>åœ¨æœ¬åœ°ç›®å½•çš„lab_utils.pyæ–‡ä»¶ä¸­ç»˜åˆ¶ä¾‹ç¨‹</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> math, copy<br><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br>plt.style.use(<span class=\"hljs-string\">&#x27;./deeplearning.mplstyle&#x27;</span>)<br><span class=\"hljs-keyword\">from</span> lab_utils_uni <span class=\"hljs-keyword\">import</span> plt_house_x, plt_contour_wgrad, plt_divergence, plt_gradients<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"Problem-Statement\"><a href=\"#Problem-Statement\" class=\"headerlink\" title=\"Problem Statement\"></a>Problem Statement</h2><p>è®©æˆ‘ä»¬ä½¿ç”¨ä¸ä¹‹å‰ç›¸åŒçš„ä¸¤ä¸ªæ•°æ®ç‚¹â€”â€”1000å¹³æ–¹è‹±å°ºçš„æˆ¿å­ä»¥30ä¸‡ç¾å…ƒçš„ä»·æ ¼å‡ºå”®ï¼Œ2000å¹³æ–¹è‹±å°ºçš„æˆ¿å­ä»¥50ä¸‡ç¾å…ƒçš„ä»·æ ¼å‡ºå”®ã€‚</p>\n<table>\n<thead>\n<tr>\n<th>Size(1000 sqft)</th>\n<th>Price(1000s of dollars)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>300</td>\n</tr>\n<tr>\n<td>2</td>\n<td>500</td>\n</tr>\n</tbody></table>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\">#Load our data set</span><br>x_train = np.array([<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">2.0</span>])\t<span class=\"hljs-comment\">#features</span><br>y_train = np.array([<span class=\"hljs-number\">300.0</span>,<span class=\"hljs-number\">500.0</span>])\t<span class=\"hljs-comment\">#target value</span><br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"Compute-Cost\"><a href=\"#Compute-Cost\" class=\"headerlink\" title=\"Compute_Cost\"></a>Compute_Cost</h2><p>è¿™æ˜¯ä¸Šä¸€ä¸ªå®éªŒå®¤å¼€å‘çš„ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œè¿˜ä¼šç”¨åˆ°å®ƒã€‚</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs pyhton\">#Function to calculate the cost<br>def compute_cost(x, y, w, b,):<br>\t<br>\tm = x.shape[0]<br>\tcost = 0<br>\t<br>\tfor i in range(m):<br>\t\tf_wb = w * x[i] + b<br>\t\tcost = cost + (f_wb - y[i])**2<br>\ttotal_cost = 1 / (2 * m)*cost<br>\t<br>\treturn total_cost<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"Gradient-descent-summary\"><a href=\"#Gradient-descent-summary\" class=\"headerlink\" title=\"Gradient descent summary\"></a>Gradient descent summary</h2><p>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œåœ¨è¿™é—¨è¯¾ç¨‹ä¸­ï¼Œä½ å·²ç»å»ºç«‹äº†ä¸€ä¸ªçº¿æ€§æ¨¡å‹æ¥é¢„æµ‹f_w,b(x^i):</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313150848463.png\" alt=\"image-20230313150848463\"></p>\n<p>åœ¨çº¿æ€§å›å½’ä¸­ï¼Œæ‚¨ä½¿ç”¨è¾“å…¥è®­ç»ƒæ•°æ®æ¥æ‹Ÿåˆå‚æ•°ğ‘¤,ğ‘;æ¥æœ€å°åŒ–æˆ‘ä»¬çš„é¢„æµ‹ä¹‹é—´çš„è¯¯å·®æµ‹é‡f_ğ‘¤ï¼Œğ‘(ğ‘¥^(ğ‘–))å’Œå®é™…æ•°æ®ğ‘¦(ğ‘–)ã€‚è¿™ç§æµ‹é‡æˆä¸ºä»£ä»·ï¼ŒJï¼ˆw,bï¼‰ã€‚åœ¨è®­ç»ƒä¸­ï¼Œä½ å¯ä»¥è¡¡é‡æˆ‘ä»¬æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„æˆæœ¬ğ‘¥(ğ‘–)ï¼Œğ‘¦(ğ‘–)ã€‚</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313151251919.png\" alt=\"image-20230313151251919\"></p>\n<p>åœ¨è¯¾å ‚ä¸Šï¼Œæ¢¯åº¦ä¸‹é™è¢«æè¿°ä¸º:</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313151329621.png\" alt=\"image-20230313151329621\"></p>\n<p>å…¶ä¸­å‚æ•°ğ‘¤,ğ‘åŒæ—¶æ›´æ–°ã€‚</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313151450500.png\" alt=\"image-20230313151450500\"></p>\n<p>è¿™é‡ŒåŒæ—¶æ„å‘³ç€åœ¨æ›´æ–°ä»»ä½•å‚æ•°ä¹‹å‰è®¡ç®—æ‰€æœ‰å‚æ•°çš„åå¯¼æ•°ã€‚</p>\n<h2 id=\"Implement-Gradient-Descent\"><a href=\"#Implement-Gradient-Descent\" class=\"headerlink\" title=\"Implement Gradient Descent\"></a>Implement Gradient Descent</h2><p>ä½ å°†ä¸ºä¸€ä¸ªç‰¹å¾å®ç°æ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚ä½ éœ€è¦ä¸‰ä¸ªå‡½æ•°ã€‚</p>\n<ul>\n<li>compute_gradientå®ç°ä¸Šè¿°å¼(4)å’Œ(5)</li>\n<li>ä¸Šé¢çš„compute_costå®ç°æ–¹ç¨‹(2)(ä»£ç æ¥è‡ªä»¥å‰çš„å®éªŒå®¤)</li>\n<li>gradient_descentï¼Œä½¿ç”¨compute_gradientå’Œcompute_cost</li>\n</ul>\n<p>Conventions:</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313151857315.png\" alt=\"image-20230313151857315\"></p>\n<h2 id=\"compute-gradient\"><a href=\"#compute-gradient\" class=\"headerlink\" title=\"compute_gradient\"></a>compute_gradient</h2><p><img src=\"/2023/03/13/ML003/image-20230313151947363.png\" alt=\"image-20230313151947363\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">compute_gradient</span>(<span class=\"hljs-params\">x, y, w, b</span>):</span><br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    Computes the gradient for linear regression</span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">    \tx (ndarray (m,)): Data, m examples</span><br><span class=\"hljs-string\">    \ty (ndarray (m,)): target values</span><br><span class=\"hljs-string\">    \tw,b (scalar)\t: model parameters</span><br><span class=\"hljs-string\">    Returns</span><br><span class=\"hljs-string\">    \tdj_dw (scalar): The gradient of the cost w.r.t. the parameters w</span><br><span class=\"hljs-string\">    \tdj_db (scalar): The gradient of the cost w.r.t. the parameter b </span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <br>    <span class=\"hljs-comment\">#Number of training examples</span><br>    m = x.shape[<span class=\"hljs-number\">0</span>]<br>    dj_de = <span class=\"hljs-number\">0</span><br>    dj_db = <span class=\"hljs-number\">0</span><br>    <br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(m):<br>        f_wb = w * x[i] + b;<br>        dj_dw_i = (f_wb - y[i]) * x[i]<br>        dj_db_i = f_wb - y[i]<br>        dj_db += dj_db_i<br>        dj_dw += dj_dw_i<br>    dj_dw = dj_dw / m<br>    dj_db = dj_db / m<br>    <br>    <span class=\"hljs-keyword\">return</span> dj_dw, dj_db<br></code></pre></div></td></tr></table></figure>\n\n<p>è¯¾ç¨‹æè¿°äº†æ¢¯åº¦ä¸‹é™å¦‚ä½•åˆ©ç”¨åœ¨æŸä¸€ç‚¹ä¸Šå¯¹å‚æ•°ä»£ä»·çš„åå¯¼æ•°æ¥æ›´æ–°è¯¥å‚æ•°ã€‚</p>\n<p>è®©æˆ‘ä»¬ä½¿ç”¨compute_gradientå‡½æ•°æ¥æŸ¥æ‰¾å¹¶ç»˜åˆ¶ä»£ä»·å‡½æ•°ç›¸å¯¹äºå…¶ä¸­ä¸€ä¸ªå‚æ•°ğ‘¤0çš„åå¯¼æ•°ã€‚</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313154012173.png\" alt=\"image-20230313154012173\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">plt_gradients(x_train,y_train, compute_cost, compute_gradient)<br>plt.show()<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/ML003/image-20230313154210478.png\" alt=\"image-20230313154210478\"></p>\n<p><img src=\"/2023/03/13/ML003/image-20230313154333429.png\" alt=\"image-20230313154333429\"></p>\n<h2 id=\"Gradient-Descent\"><a href=\"#Gradient-Descent\" class=\"headerlink\" title=\"Gradient Descent\"></a>Gradient Descent</h2><p>ç°åœ¨å¯ä»¥è®¡ç®—æ¢¯åº¦ï¼Œä¸Šé¢å…¬å¼(3)ä¸­æè¿°çš„æ¢¯åº¦ä¸‹é™å¯ä»¥åœ¨ä¸‹é¢çš„gradient_descentä¸­å®ç°ã€‚æ³¨é‡Šä¸­æè¿°äº†å®ç°çš„ç»†èŠ‚ã€‚ä¸‹é¢ï¼Œæ‚¨å°†åˆ©ç”¨è¿™ä¸ªå‡½æ•°åœ¨è®­ç»ƒæ•°æ®ä¸Šæ‰¾åˆ°wå’Œbçš„æœ€ä½³å€¼ã€‚</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">gradient_descent</span>(<span class=\"hljs-params\">x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function</span>):</span> <br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    Performs gradient descent to fit w,b. Updates w,b by taking </span><br><span class=\"hljs-string\">    num_iters gradient steps with learning rate alpha</span><br><span class=\"hljs-string\">    </span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">      x (ndarray (m,))  : Data, m examples </span><br><span class=\"hljs-string\">      y (ndarray (m,))  : target values</span><br><span class=\"hljs-string\">      w_in,b_in (scalar): initial values of model parameters  </span><br><span class=\"hljs-string\">      alpha (float):     Learning rate</span><br><span class=\"hljs-string\">      num_iters (int):   number of iterations to run gradient descent</span><br><span class=\"hljs-string\">      cost_function:     function to call to produce cost</span><br><span class=\"hljs-string\">      gradient_function: function to call to produce gradient</span><br><span class=\"hljs-string\">      </span><br><span class=\"hljs-string\">    Returns:</span><br><span class=\"hljs-string\">      w (scalar): Updated value of parameter after running gradient descent</span><br><span class=\"hljs-string\">      b (scalar): Updated value of parameter after running gradient descent</span><br><span class=\"hljs-string\">      J_history (List): History of cost values</span><br><span class=\"hljs-string\">      p_history (list): History of parameters [w,b] </span><br><span class=\"hljs-string\">      &quot;&quot;&quot;</span><br>    <br>    w = copy.deepcopy(w_in) <span class=\"hljs-comment\"># avoid modifying global w_in</span><br>    <span class=\"hljs-comment\"># An array to store cost J and w&#x27;s at each iteration primarily for graphing later</span><br>    J_history = []<br>    p_history = []<br>    b = b_in<br>    w = w_in<br>    <br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(num_iters):<br>        <span class=\"hljs-comment\"># Calculate the gradient and update the parameters using gradient_function</span><br>        dj_dw, dj_db = gradient_function(x, y, w , b)     <br><br>        <span class=\"hljs-comment\"># Update Parameters using equation (3) above</span><br>        b = b - alpha * dj_db                            <br>        w = w - alpha * dj_dw                            <br><br>        <span class=\"hljs-comment\"># Save cost J at each iteration</span><br>        <span class=\"hljs-keyword\">if</span> i&lt;<span class=\"hljs-number\">100000</span>:      <span class=\"hljs-comment\"># prevent resource exhaustion </span><br>            J_history.append( cost_function(x, y, w , b))<br>            p_history.append([w,b])<br>        <span class=\"hljs-comment\"># Print cost every at intervals 10 times or as many iterations if &lt; 10</span><br>        <span class=\"hljs-keyword\">if</span> i% math.ceil(num_iters/<span class=\"hljs-number\">10</span>) == <span class=\"hljs-number\">0</span>:<br>            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;Iteration <span class=\"hljs-subst\">&#123;i:<span class=\"hljs-number\">4</span>&#125;</span>: Cost <span class=\"hljs-subst\">&#123;J_history[-<span class=\"hljs-number\">1</span>]:<span class=\"hljs-number\">0.2</span>e&#125;</span> &quot;</span>,<br>                  <span class=\"hljs-string\">f&quot;dj_dw: <span class=\"hljs-subst\">&#123;dj_dw: <span class=\"hljs-number\">0.3</span>e&#125;</span>, dj_db: <span class=\"hljs-subst\">&#123;dj_db: <span class=\"hljs-number\">0.3</span>e&#125;</span>  &quot;</span>,<br>                  <span class=\"hljs-string\">f&quot;w: <span class=\"hljs-subst\">&#123;w: <span class=\"hljs-number\">0.3</span>e&#125;</span>, b:<span class=\"hljs-subst\">&#123;b: <span class=\"hljs-number\">0.5</span>e&#125;</span>&quot;</span>)<br> <br>    <span class=\"hljs-keyword\">return</span> w, b, J_history, p_history <span class=\"hljs-comment\">#return w and J,w history for graphing</span><br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">Iteration    <span class=\"hljs-number\">0</span>: Cost <span class=\"hljs-number\">7.93e+04</span>  dj_dw: -<span class=\"hljs-number\">6.500e+02</span>, dj_db: -<span class=\"hljs-number\">4.000e+02</span>   w:  <span class=\"hljs-number\">6.500e+00</span>, b: <span class=\"hljs-number\">4.00000e+00</span><br>Iteration <span class=\"hljs-number\">1000</span>: Cost <span class=\"hljs-number\">3.41e+00</span>  dj_dw: -<span class=\"hljs-number\">3.712e-01</span>, dj_db:  <span class=\"hljs-number\">6.007e-01</span>   w:  <span class=\"hljs-number\">1.949e+02</span>, b: <span class=\"hljs-number\">1.08228e+02</span><br>Iteration <span class=\"hljs-number\">2000</span>: Cost <span class=\"hljs-number\">7.93e-01</span>  dj_dw: -<span class=\"hljs-number\">1.789e-01</span>, dj_db:  <span class=\"hljs-number\">2.895e-01</span>   w:  <span class=\"hljs-number\">1.975e+02</span>, b: <span class=\"hljs-number\">1.03966e+02</span><br>Iteration <span class=\"hljs-number\">3000</span>: Cost <span class=\"hljs-number\">1.84e-01</span>  dj_dw: -<span class=\"hljs-number\">8.625e-02</span>, dj_db:  <span class=\"hljs-number\">1.396e-01</span>   w:  <span class=\"hljs-number\">1.988e+02</span>, b: <span class=\"hljs-number\">1.01912e+02</span><br>Iteration <span class=\"hljs-number\">4000</span>: Cost <span class=\"hljs-number\">4.28e-02</span>  dj_dw: -<span class=\"hljs-number\">4.158e-02</span>, dj_db:  <span class=\"hljs-number\">6.727e-02</span>   w:  <span class=\"hljs-number\">1.994e+02</span>, b: <span class=\"hljs-number\">1.00922e+02</span><br>Iteration <span class=\"hljs-number\">5000</span>: Cost <span class=\"hljs-number\">9.95e-03</span>  dj_dw: -<span class=\"hljs-number\">2.004e-02</span>, dj_db:  <span class=\"hljs-number\">3.243e-02</span>   w:  <span class=\"hljs-number\">1.997e+02</span>, b: <span class=\"hljs-number\">1.00444e+02</span><br>Iteration <span class=\"hljs-number\">6000</span>: Cost <span class=\"hljs-number\">2.31e-03</span>  dj_dw: -<span class=\"hljs-number\">9.660e-03</span>, dj_db:  <span class=\"hljs-number\">1.563e-02</span>   w:  <span class=\"hljs-number\">1.999e+02</span>, b: <span class=\"hljs-number\">1.00214e+02</span><br>Iteration <span class=\"hljs-number\">7000</span>: Cost <span class=\"hljs-number\">5.37e-04</span>  dj_dw: -<span class=\"hljs-number\">4.657e-03</span>, dj_db:  <span class=\"hljs-number\">7.535e-03</span>   w:  <span class=\"hljs-number\">1.999e+02</span>, b: <span class=\"hljs-number\">1.00103e+02</span><br>Iteration <span class=\"hljs-number\">8000</span>: Cost <span class=\"hljs-number\">1.25e-04</span>  dj_dw: -<span class=\"hljs-number\">2.245e-03</span>, dj_db:  <span class=\"hljs-number\">3.632e-03</span>   w:  <span class=\"hljs-number\">2.000e+02</span>, b: <span class=\"hljs-number\">1.00050e+02</span><br>Iteration <span class=\"hljs-number\">9000</span>: Cost <span class=\"hljs-number\">2.90e-05</span>  dj_dw: -<span class=\"hljs-number\">1.082e-03</span>, dj_db:  <span class=\"hljs-number\">1.751e-03</span>   w:  <span class=\"hljs-number\">2.000e+02</span>, b: <span class=\"hljs-number\">1.00024e+02</span><br>(w,b) found by gradient descent: (<span class=\"hljs-number\">199.9929</span>,<span class=\"hljs-number\">100.0116</span>)<br></code></pre></div></td></tr></table></figure>\n\n<p>èŠ±ç‚¹æ—¶é—´ï¼Œæ³¨æ„ä¸Šé¢æ‰“å°çš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹çš„ä¸€äº›ç‰¹å¾ã€‚</p>\n<ul>\n<li>æ­£å¦‚è¯¾å ‚ä¸Šçš„å¹»ç¯ç‰‡æ‰€æè¿°çš„ï¼Œæˆæœ¬å¼€å§‹å¾ˆå¤§ï¼Œç„¶åè¿…é€Ÿä¸‹é™ã€‚</li>\n<li>åå¯¼æ•°dj_dwå’Œdj_dbä¹Ÿå˜å°äº†ï¼Œèµ·åˆå¾ˆå¿«ï¼Œç„¶åå˜æ…¢ã€‚æ­£å¦‚è¯¾å ‚ä¸Šçš„å›¾è¡¨æ‰€ç¤ºï¼Œéšç€è¿‡ç¨‹æ¥è¿‘â€œç¢—åº•â€ï¼Œç”±äºåœ¨è¿™ä¸€ç‚¹ä¸Šçš„å¯¼æ•°å€¼è¾ƒå°ï¼Œè¿›ç¨‹ä¼šå˜æ…¢ã€‚</li>\n<li>å°½ç®¡å­¦ä¹ ç‡alphaä¿æŒä¸å˜ï¼Œä½†è¿›ç¨‹ä¼šå‡æ…¢</li>\n</ul>\n<p><img src=\"/2023/03/13/ML003/image-20230313155614815.png\" alt=\"image-20230313155614815\"></p>\n<h2 id=\"Cost-versus-iterations-of-gradient-descent\"><a href=\"#Cost-versus-iterations-of-gradient-descent\" class=\"headerlink\" title=\"Cost versus iterations of gradient descent\"></a>Cost versus iterations of gradient descent</h2><p>æˆæœ¬ä¸è¿­ä»£çš„å…³ç³»å›¾æ˜¯è¡¡é‡æ¢¯åº¦ä¸‹é™æŠ€æœ¯è¿›å±•çš„æœ‰ç”¨æ–¹æ³•ã€‚åœ¨æˆåŠŸçš„è¿è¡Œä¸­ï¼Œæˆæœ¬æ€»æ˜¯ä¼šé™ä½ã€‚æœ€åˆæˆæœ¬çš„å˜åŒ–å¦‚æ­¤ä¹‹å¿«ï¼Œç”¨ä¸åŒäºæœ€ç»ˆä¸‹é™çš„å°ºåº¦æ¥æç»˜æœ€åˆçš„ä¸Šå‡æ˜¯æœ‰ç”¨çš„ã€‚</p>\n<p>åœ¨ä¸‹é¢çš„å›¾è¡¨ä¸­ï¼Œè¯·æ³¨æ„è½´ä¸Šçš„æˆæœ¬è§„æ¨¡å’Œè¿­ä»£æ­¥éª¤ã€‚</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># plot cost versus iteration  </span><br>fig, (ax1, ax2) = plt.subplots(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, constrained_layout=<span class=\"hljs-literal\">True</span>, figsize=(<span class=\"hljs-number\">12</span>,<span class=\"hljs-number\">4</span>))<br>ax1.plot(J_hist[:<span class=\"hljs-number\">100</span>])<br>ax2.plot(<span class=\"hljs-number\">1000</span> + np.arange(<span class=\"hljs-built_in\">len</span>(J_hist[<span class=\"hljs-number\">1000</span>:])), J_hist[<span class=\"hljs-number\">1000</span>:])<br>ax1.set_title(<span class=\"hljs-string\">&quot;Cost vs. iteration(start)&quot;</span>);  ax2.set_title(<span class=\"hljs-string\">&quot;Cost vs. iteration (end)&quot;</span>)<br>ax1.set_ylabel(<span class=\"hljs-string\">&#x27;Cost&#x27;</span>)            ;  ax2.set_ylabel(<span class=\"hljs-string\">&#x27;Cost&#x27;</span>) <br>ax1.set_xlabel(<span class=\"hljs-string\">&#x27;iteration step&#x27;</span>)  ;  ax2.set_xlabel(<span class=\"hljs-string\">&#x27;iteration step&#x27;</span>) <br>plt.show()<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/ML003/image-20230313160112122.png\" alt=\"image-20230313160112122\"></p>\n<h2 id=\"Predictions\"><a href=\"#Predictions\" class=\"headerlink\" title=\"Predictions\"></a>Predictions</h2><p>ç°åœ¨æ‚¨å·²ç»å‘ç°äº†å‚æ•°ğ‘¤çš„æœ€ä½³å€¼å’Œğ‘ï¼Œæ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨è¯¥æ¨¡å‹æ ¹æ®æˆ‘ä»¬å­¦ä¹ çš„å‚æ•°æ¥é¢„æµ‹æˆ¿å±‹ä»·å€¼ã€‚æ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œåœ¨ç›¸åŒçš„ä½æˆ¿æ¡ä»¶ä¸‹ï¼Œé¢„æµ‹å€¼ä¸è®­ç»ƒå€¼å‡ ä¹ç›¸åŒã€‚è¿›ä¸€æ­¥ï¼Œä¸åœ¨é¢„æµ‹ä¸­çš„å€¼ä¸æœŸæœ›å€¼ä¸€è‡´ã€‚</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;1000 sqft house prediction <span class=\"hljs-subst\">&#123;w_final*<span class=\"hljs-number\">1.0</span> + b_final:<span class=\"hljs-number\">0.1</span>f&#125;</span> Thousand dollars&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;1200 sqft house prediction <span class=\"hljs-subst\">&#123;w_final*<span class=\"hljs-number\">1.2</span> + b_final:<span class=\"hljs-number\">0.1</span>f&#125;</span> Thousand dollars&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;2000 sqft house prediction <span class=\"hljs-subst\">&#123;w_final*<span class=\"hljs-number\">2.0</span> + b_final:<span class=\"hljs-number\">0.1</span>f&#125;</span> Thousand dollars&quot;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-number\">1000</span> sqft house prediction <span class=\"hljs-number\">300.0</span> Thousand dollars<br><span class=\"hljs-number\">1200</span> sqft house prediction <span class=\"hljs-number\">340.0</span> Thousand dollars<br><span class=\"hljs-number\">2000</span> sqft house prediction <span class=\"hljs-number\">500.0</span> Thousand dollars<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"Plotting\"><a href=\"#Plotting\" class=\"headerlink\" title=\"Plotting\"></a>Plotting</h2><p>æ‚¨å¯ä»¥é€šè¿‡åœ¨ä»£ä»·(w,b)çš„ç­‰é«˜çº¿å›¾ä¸Šç»˜åˆ¶è¿­ä»£çš„ä»£ä»·æ¥æ˜¾ç¤ºæ¢¯åº¦ä¸‹é™åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­çš„è¿›åº¦ã€‚</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">fig, ax = plt.subplots(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>, figsize=(<span class=\"hljs-number\">12</span>, <span class=\"hljs-number\">6</span>))<br>plt_contour_wgrad(x_train, y_train, p_hist, ax)<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/ML003/image-20230313160446994.png\" alt=\"image-20230313160446994\"></p>\n<p>ä¸Šé¢çš„ç­‰é«˜çº¿å›¾æ˜¾ç¤ºäº†ğ‘¤å’Œğ‘èŒƒå›´å†…çš„ğ‘ğ‘œğ‘ ğ‘¡(ğ‘¤ï¼Œğ‘)ã€‚æˆæœ¬æ°´å¹³ç”±åœ†ç¯è¡¨ç¤ºã€‚ç”¨çº¢è‰²ç®­å¤´è¦†ç›–çš„æ˜¯æ¢¯åº¦ä¸‹é™çš„è·¯å¾„ã€‚è¿™é‡Œæœ‰ä¸€äº›éœ€è¦æ³¨æ„çš„äº‹æƒ…:</p>\n<ul>\n<li>è¿™æ¡è·¯å¾„æœç€å®ƒçš„ç›®æ ‡ç¨³æ­¥(å•è°ƒ)å‰è¿›ã€‚</li>\n<li>æœ€åˆçš„æ­¥éª¤æ¯”æ¥è¿‘ç›®æ ‡çš„æ­¥éª¤è¦å¤§å¾—å¤šã€‚</li>\n</ul>\n<p>æ”¾å¤§ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¢¯åº¦ä¸‹é™çš„æœ€åæ­¥éª¤ã€‚æ³¨æ„ï¼Œé˜¶æ¢¯ä¹‹é—´çš„è·ç¦»éšç€æ¢¯åº¦è¶‹è¿‘äºé›¶è€Œç¼©å°ã€‚</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">fig, ax = plt.subplots(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>, figsize=(<span class=\"hljs-number\">12</span>, <span class=\"hljs-number\">4</span>))<br>plt_contour_wgrad(x_train, y_train, p_hist, ax, w_range=[<span class=\"hljs-number\">180</span>, <span class=\"hljs-number\">220</span>, <span class=\"hljs-number\">0.5</span>], b_range=[<span class=\"hljs-number\">80</span>, <span class=\"hljs-number\">120</span>, <span class=\"hljs-number\">0.5</span>],<br>            contours=[<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">5</span>,<span class=\"hljs-number\">10</span>,<span class=\"hljs-number\">20</span>],resolution=<span class=\"hljs-number\">0.5</span>)<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/ML003/image-20230313160944244.png\" alt=\"image-20230313160944244\"></p>\n<h2 id=\"Increased-Learning-Rate\"><a href=\"#Increased-Learning-Rate\" class=\"headerlink\" title=\"Increased Learning Rate\"></a>Increased Learning Rate</h2><p>åœ¨è¿™èŠ‚è¯¾ä¸­ï¼Œåœ¨å¼(3)ä¸­æœ‰ä¸€ä¸ªå…³äºå­¦ä¹ ç‡çš„åˆé€‚å€¼ğ›¼çš„è®¨è®ºã€‚ğ›¼è¶Šå¤§ï¼Œæ¢¯åº¦ä¸‹é™æ”¶æ•›åˆ°è§£çš„é€Ÿåº¦å°±è¶Šå¿«ã€‚ä½†æ˜¯ï¼Œå¦‚æœå®ƒå¤ªå¤§ï¼Œæ¢¯åº¦ä¸‹é™å°±ä¼šå‘æ•£ã€‚ä¸Šé¢æœ‰ä¸€ä¸ªå¾ˆå¥½æ”¶æ•›çš„è§£çš„ä¾‹å­ã€‚è®©æˆ‘ä»¬è¯•ç€å¢åŠ ğ›¼çš„å€¼çœ‹çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆ:</p>\n<p><img src=\"/2023/03/13/ML003/image-20230313161516209.png\" alt=\"image-20230313161516209\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># initialize parameters</span><br>w_init = <span class=\"hljs-number\">0</span><br>b_init = <span class=\"hljs-number\">0</span><br><span class=\"hljs-comment\"># set alpha to a large value</span><br>iterations = <span class=\"hljs-number\">10</span><br>tmp_alpha = <span class=\"hljs-number\">8.0e-1</span><br><span class=\"hljs-comment\"># run gradient descent</span><br>w_final, b_final, J_hist, p_hist = gradient_descent(x_train ,y_train, w_init, b_init, tmp_alpha, <br>                                                    iterations, compute_cost, compute_gradient)<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs pyhton\">Iteration    0: Cost 2.58e+05  dj_dw: -6.500e+02, dj_db: -4.000e+02   w:  5.200e+02, b: 3.20000e+02<br>Iteration    1: Cost 7.82e+05  dj_dw:  1.130e+03, dj_db:  7.000e+02   w: -3.840e+02, b:-2.40000e+02<br>Iteration    2: Cost 2.37e+06  dj_dw: -1.970e+03, dj_db: -1.216e+03   w:  1.192e+03, b: 7.32800e+02<br>Iteration    3: Cost 7.19e+06  dj_dw:  3.429e+03, dj_db:  2.121e+03   w: -1.551e+03, b:-9.63840e+02<br>Iteration    4: Cost 2.18e+07  dj_dw: -5.974e+03, dj_db: -3.691e+03   w:  3.228e+03, b: 1.98886e+03<br>Iteration    5: Cost 6.62e+07  dj_dw:  1.040e+04, dj_db:  6.431e+03   w: -5.095e+03, b:-3.15579e+03<br>Iteration    6: Cost 2.01e+08  dj_dw: -1.812e+04, dj_db: -1.120e+04   w:  9.402e+03, b: 5.80237e+03<br>Iteration    7: Cost 6.09e+08  dj_dw:  3.156e+04, dj_db:  1.950e+04   w: -1.584e+04, b:-9.80139e+03<br>Iteration    8: Cost 1.85e+09  dj_dw: -5.496e+04, dj_db: -3.397e+04   w:  2.813e+04, b: 1.73730e+04<br>Iteration    9: Cost 5.60e+09  dj_dw:  9.572e+04, dj_db:  5.916e+04   w: -4.845e+04, b:-2.99567e+04<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/ML003/image-20230313161636772.png\" alt=\"image-20230313161636772\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">plt_divergence(p_hist, J_hist,x_train, y_train)<br>plt.show()<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/13/ML003/image-20230313161959222.png\" alt=\"image-20230313161959222\"></p>\n<p>ä¸Šå›¾ä¸­ï¼Œå·¦å›¾æ˜¾ç¤ºäº†ğ‘¤åœ¨æ¢¯åº¦ä¸‹é™çš„å‰å‡ ä¸ªæ­¥éª¤ä¸­çš„è¿›å±•ã€‚ğ‘¤ä»æ­£æŒ¯è¡åˆ°è´Ÿï¼Œæˆæœ¬è¿…é€Ÿå¢é•¿ã€‚æ¢¯åº¦ä¸‹é™åŒæ—¶åœ¨ğ‘¤å’Œğ‘ä¸Šè¿è¡Œï¼Œæ‰€ä»¥éœ€è¦å³è¾¹çš„3då›¾æ‰èƒ½çœ‹åˆ°å®Œæ•´çš„å›¾ç‰‡ã€‚</p>\n<h2 id=\"Congratulations\"><a href=\"#Congratulations\" class=\"headerlink\" title=\"Congratulations!\"></a>Congratulations!</h2><p>åœ¨è¿™ä¸ªå®éªŒå®¤é‡Œï¼Œä½ :</p>\n<ul>\n<li>æ·±å…¥ç ”ç©¶å•ä¸ªå˜é‡çš„æ¢¯åº¦ä¸‹é™çš„ç»†èŠ‚ã€‚</li>\n<li>å¼€å‘äº†ä¸€ä¸ªè®¡ç®—æ¢¯åº¦çš„ç¨‹åº</li>\n<li>çœ‹çœ‹æ¢¯åº¦æ˜¯ä»€ä¹ˆ</li>\n<li>å®Œæˆä¸€ä¸ªæ¢¯åº¦ä¸‹é™ç¨‹åº</li>\n<li>åˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•å¯»æ‰¾å‚æ•°</li>\n<li>æ£€æŸ¥äº†å­¦ä¹ ç‡å¤§å°çš„å½±å“</li>\n</ul>\n<h2 id=\"å‚è€ƒèµ„æ–™\"><a href=\"#å‚è€ƒèµ„æ–™\" class=\"headerlink\" title=\"å‚è€ƒèµ„æ–™\"></a>å‚è€ƒèµ„æ–™</h2><p><a href=\"https://www.bilibili.com/video/BV1Pa411X76s?p=5&amp;vd_source=3ae32e36058f58c5b85935fca9b77797\">https://www.bilibili.com/video/BV1Pa411X76s?p=5&amp;vd_source=3ae32e36058f58c5b85935fca9b77797</a></p>\n<p><a href=\"https://github.com/kaieye/2022-Machine-Learning-Specialization\">kaieye&#x2F;2022-Machine-Learning-Specialization (github.com)</a></p>\n",
            "tags": [
                "Tensorflow",
                "Machine Learning"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/12/ML002/",
            "url": "https://xingyuanjie.top/2023/03/12/ML002/",
            "title": "ä»£ä»·å‡½æ•°",
            "date_published": "2023-03-12T08:33:17.000Z",
            "content_html": "<h2 id=\"ä»£ä»·å‡½æ•°\"><a href=\"#ä»£ä»·å‡½æ•°\" class=\"headerlink\" title=\"ä»£ä»·å‡½æ•°\"></a>ä»£ä»·å‡½æ•°</h2><p><img src=\"/2023/03/12/ML002/image-20230312164306128.png\" alt=\"image-20230312164306128\"></p>\n<h2 id=\"ç›®æ ‡\"><a href=\"#ç›®æ ‡\" class=\"headerlink\" title=\"ç›®æ ‡\"></a>ç›®æ ‡</h2><p>åœ¨æœ¬å®éªŒä¸­ï¼Œä½ å°†:</p>\n<ul>\n<li>ä½ å°†å®ç°å’Œæ¢ç´¢æˆæœ¬å‡½æ•°çš„çº¿æ€§å›å½’ä¼´éšä¸€ä¸ªå˜é‡ã€‚</li>\n</ul>\n<h2 id=\"å·¥å…·\"><a href=\"#å·¥å…·\" class=\"headerlink\" title=\"å·¥å…·\"></a>å·¥å…·</h2><p>åœ¨æœ¬å®éªŒå®¤ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨:</p>\n<ul>\n<li>NumPyï¼Œä¸€ä¸ªç”¨äºç§‘å­¦è®¡ç®—çš„æµè¡Œåº“</li>\n<li>Matplotlibï¼Œç”¨äºç»˜åˆ¶æ•°æ®çš„æµè¡Œåº“</li>\n<li>æœ¬åœ°ç›®å½•çš„lab_utils_uni.pyæ–‡ä»¶ä¸­çš„æœ¬åœ°ç»˜å›¾ä¾‹ç¨‹</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> nunpy <span class=\"hljs-keyword\">as</span> np<br>%matplotlib widget<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">from</span> lab_utils_uni <span class=\"hljs-keyword\">import</span> plt_intuition, plt_stationary, plt_updata_onclick, soup_bowl<br>plt.style.use(<span class=\"hljs-string\">&#x27;./deeplearning.mplstyle&#x27;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"é—®é¢˜æ„å¢ƒ\"><a href=\"#é—®é¢˜æ„å¢ƒ\" class=\"headerlink\" title=\"é—®é¢˜æ„å¢ƒ\"></a>é—®é¢˜æ„å¢ƒ</h2><p>ä½ æƒ³è¦ä¸€ä¸ªæ¨¡å‹ï¼Œå®ƒå¯ä»¥æ ¹æ®æˆ¿å­çš„å¤§å°é¢„æµ‹æˆ¿ä»·ã€‚è®©æˆ‘ä»¬ä½¿ç”¨ä¸ä¸Šä¸€ä¸ªå®éªŒå®¤ä¹‹å‰ç›¸åŒçš„ä¸¤ä¸ªæ•°æ®ç‚¹â€”â€”ä¸€ä¸ª1000å¹³æ–¹è‹±å°ºçš„æˆ¿å­å–äº†30ä¸‡ç¾å…ƒï¼Œä¸€ä¸ª2000å¹³æ–¹è‹±å°ºçš„æˆ¿å­å–äº†50ä¸‡ç¾å…ƒã€‚</p>\n<table>\n<thead>\n<tr>\n<th>Size(1000 sqft)</th>\n<th>Price(1000s of dollars)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>300</td>\n</tr>\n<tr>\n<td>2</td>\n<td>500</td>\n</tr>\n</tbody></table>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">x_train = np.array([<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">2.0</span>])   <span class=\"hljs-comment\">#(size in 1000 square feet)</span><br>y_train = np.zrray([<span class=\"hljs-number\">300.0</span>, <span class=\"hljs-number\">500.0</span>])\t<span class=\"hljs-comment\">#(price in 1000s of dollars)</span><br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"è®¡ç®—ä»£ä»·\"><a href=\"#è®¡ç®—ä»£ä»·\" class=\"headerlink\" title=\"è®¡ç®—ä»£ä»·\"></a>è®¡ç®—ä»£ä»·</h2><p>è¿™ä¸ªä½œä¸šä¸­çš„æœ¯è¯­â€œæˆæœ¬â€å¯èƒ½ä¼šè®©äººæœ‰ç‚¹å›°æƒ‘ï¼Œå› ä¸ºæ•°æ®æ˜¯ä½æˆ¿æˆæœ¬ã€‚åœ¨è¿™é‡Œï¼Œæˆæœ¬æ˜¯è¡¡é‡æˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹æˆ¿å­ç›®æ ‡ä»·æ ¼çš„å¥½åã€‚â€œä»·æ ¼â€ä¸€è¯æŒ‡çš„æ˜¯ä½æˆ¿æ•°æ®ã€‚</p>\n<p>å«ä¸€ä¸ªå˜é‡çš„æˆæœ¬æ–¹ç¨‹ä¸º:</p>\n<p><img src=\"/2023/03/12/ML002/image-20230312165434160.png\" alt=\"image-20230312165434160\"></p>\n<p>åœ¨è¿™é‡Œ</p>\n<p><img src=\"/2023/03/12/ML002/image-20230312165503613.png\" alt=\"image-20230312165503613\"></p>\n<ul>\n<li>f_w,b(x^i)æ˜¯æˆ‘ä»¬ä½¿ç”¨å‚æ•°w,bæ¥é¢„æµ‹ä¾‹å­iã€‚</li>\n<li>ï¼ˆf_w,b(x^i) - y^iï¼‰^2  æ˜¯ç›®æ ‡å€¼ä¸é¢„æµ‹å€¼ä¹‹é—´çš„å·®çš„å¹³æ–¹</li>\n<li>è¿™äº›å·®å¼‚è¢«åŠ åœ¨æ‰€æœ‰mä¾‹å­ä¸Šï¼Œå†é™¤ä»¥2mï¼Œå¾—åˆ°ä»£ä»·å‡½æ•° <strong>Jï¼ˆw,bï¼‰</strong></li>\n</ul>\n<p>æ³¨æ„ï¼Œåœ¨è®²åº§ä¸­ï¼Œæ€»å’Œçš„èŒƒå›´é€šå¸¸æ˜¯ä»1åˆ°mï¼Œè€Œä»£ç å°†ä»0åˆ°m-1ã€‚</p>\n<p>ä¸‹é¢çš„ä»£ç é€šè¿‡éå†æ¯ä¸ªç¤ºä¾‹æ¥è®¡ç®—æˆæœ¬ã€‚åœ¨æ¯ä¸ªå¾ªç¯ä¸­:</p>\n<ul>\n<li>f_wbï¼Œè®¡ç®—ä¸€ä¸ªé¢„æµ‹</li>\n<li>ç›®æ ‡å’Œé¢„æµ‹ä¹‹é—´çš„å·®å€¼è¢«è®¡ç®—å’Œå¹³æ–¹ã€‚</li>\n<li>è¿™è¢«åŠ åˆ°æ€»æˆæœ¬ä¸­ã€‚</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">compute_cost</span>(<span class=\"hljs-params\">x, y, w, b</span>):</span><br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    Computes the cost function for linear regression</span><br><span class=\"hljs-string\">    </span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">    \tx (ndarray (m,)):Data, m examples</span><br><span class=\"hljs-string\">    \ty (ndarray (m,)):target values</span><br><span class=\"hljs-string\">    \tw,b (scalar)\t:model parameters</span><br><span class=\"hljs-string\">    </span><br><span class=\"hljs-string\">    Returns</span><br><span class=\"hljs-string\">    \ttotal_cost (float):The cost of using w,b as the parameters for linear regression to fit the data points in x and y</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\">#number of training examples</span><br>    m = x.shape[<span class=\"hljs-number\">0</span>]<br>    <br>    cost_sum = <span class=\"hljs-number\">0</span><br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(m):<br>        f_wb = w * x[i] + b<br>        cost = (f_wb - y[i])**<span class=\"hljs-number\">2</span><br>        cost_sum = cost_sum + cost<br>    total_cost = (<span class=\"hljs-number\">1</span>/(<span class=\"hljs-number\">2</span>*m)) * cost_sum<br>    <br>    <span class=\"hljs-keyword\">return</span> total_cost<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"Cost-Function-Intuition\"><a href=\"#Cost-Function-Intuition\" class=\"headerlink\" title=\"Cost Function Intuition\"></a>Cost Function Intuition</h2><p><img src=\"/2023/03/12/ML002/image-20230312172325465.png\" alt=\"image-20230312172325465\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">plt_intuition(x_train, y_train)<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/12/ML002/image-20230313144221393.png\" alt=\"image-20230313144221393\"></p>\n<p>æƒ…èŠ‚ä¸­æœ‰å‡ ç‚¹å€¼å¾—ä¸€æã€‚</p>\n<ul>\n<li>å½“ğ‘¤&#x3D;200æ—¶ï¼Œæˆæœ¬æœ€å°åŒ–ï¼Œè¿™ä¸ä¹‹å‰å®éªŒå®¤çš„ç»“æœç›¸å»åˆã€‚</li>\n<li>å› ä¸ºåœ¨æˆæœ¬æ–¹ç¨‹ä¸­ï¼Œç›®æ ‡å’Œé¢„æµ‹ä¹‹é—´çš„å·®å¼‚æ˜¯å¹³æ–¹ï¼Œå½“ğ‘¤æ—¶ï¼Œæˆæœ¬è¿…é€Ÿå¢åŠ ä¸æ˜¯å¤ªå¤§å°±æ˜¯å¤ªå°ã€‚</li>\n<li>ä½¿ç”¨é€šè¿‡æœ€å°åŒ–æˆæœ¬é€‰æ‹©çš„wå’Œbï¼Œå¯ä»¥å¾—åˆ°ä¸æ•°æ®å®Œç¾åŒ¹é…çš„ç›´çº¿ã€‚</li>\n</ul>\n<h2 id=\"Cost-Function-Visualiztion-3D\"><a href=\"#Cost-Function-Visualiztion-3D\" class=\"headerlink\" title=\"Cost Function Visualiztion-3D\"></a>Cost Function Visualiztion-3D</h2><p>ä½ å¯ä»¥é€šè¿‡ä¸‰ç»´ç»˜å›¾æˆ–ç­‰é«˜çº¿å›¾çœ‹åˆ°æˆæœ¬æ˜¯å¦‚ä½•éšwå’Œbå˜åŒ–çš„ã€‚</p>\n<p>å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™é—¨è¯¾çš„ä¸€äº›æƒ…èŠ‚ä¼šå˜å¾—ç›¸å½“å¤æ‚ã€‚æœ¬æ–‡æä¾›äº†ç»˜å›¾ä¾‹ç¨‹ï¼Œè™½ç„¶é€šè¯»ä»£ç ä»¥ç†Ÿæ‚‰è¿™äº›æ–¹æ³•æ˜¯æœ‰æŒ‡å¯¼æ„ä¹‰çš„ï¼Œä½†è¦æˆåŠŸå®Œæˆè¯¾ç¨‹å¹¶ä¸éœ€è¦è¿™æ ·åšã€‚ä¾‹ç¨‹åœ¨æœ¬åœ°ç›®å½•lab_utils_uni.pyä¸­ã€‚</p>\n<h2 id=\"Larger-Data-Set\"><a href=\"#Larger-Data-Set\" class=\"headerlink\" title=\"Larger Data Set\"></a>Larger Data Set</h2><p>è¾ƒå¤§çš„æ•°æ®é›†ç”¨æ›´å¤šçš„æ•°æ®ç‚¹æ¥è§‚å¯Ÿä¸€ä¸ªåœºæ™¯æ˜¯å¾ˆæœ‰æŒ‡å¯¼æ„ä¹‰çš„ã€‚è¯¥æ•°æ®é›†åŒ…æ‹¬ä¸åœ¨åŒä¸€çº¿ä¸Šçš„æ•°æ®ç‚¹ã€‚è¿™å¯¹æˆæœ¬æ–¹ç¨‹æ„å‘³ç€ä»€ä¹ˆ?æˆ‘ä»¬èƒ½æ‰¾åˆ°ğ‘¤ã€ğ‘é‚£æ ·ä½¿å¾—ä»£ä»·æ˜¯0?</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">x_train = np.array([<span class=\"hljs-number\">1.0</span>,<span class=\"hljs-number\">1.7</span>,<span class=\"hljs-number\">2.0</span>,<span class=\"hljs-number\">2.5</span>,<span class=\"hljs-number\">3.0</span>,<span class=\"hljs-number\">3.2</span>])<br>y_train = np.array([<span class=\"hljs-number\">250</span>,<span class=\"hljs-number\">300</span>,<span class=\"hljs-number\">480</span>,<span class=\"hljs-number\">430</span>,<span class=\"hljs-number\">630</span>,<span class=\"hljs-number\">730</span>])<br></code></pre></div></td></tr></table></figure>\n\n<p>åœ¨ç­‰é«˜çº¿å›¾ä¸­ï¼Œç‚¹å‡»ä¸€ä¸ªç‚¹ï¼Œé€‰æ‹©wå’Œbï¼Œä»¥è¾¾åˆ°æœ€ä½çš„æˆæœ¬ã€‚ä½¿ç”¨è½®å»“æ¥æŒ‡å¯¼ä½ çš„é€‰æ‹©ã€‚æ³¨æ„ï¼Œæ›´æ–°å›¾å½¢å¯èƒ½éœ€è¦å‡ ç§’é’Ÿçš„æ—¶é—´ã€‚</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">plt.close(<span class=\"hljs-string\">&#x27;all&#x27;</span>)<br>fig, ax ,dyn_items = plt_stationary(x_train, y_train)<br>updater = plt_update_onclick(fig, ax, x_train,y_train,dyn_items)<br></code></pre></div></td></tr></table></figure>\n\n<p>ä¸Šé¢ï¼Œæ³¨æ„å·¦è¾¹å›¾ä¸­çš„è™šçº¿ã€‚è¿™äº›ä»£è¡¨äº†ä½ çš„è®­ç»ƒé›†ä¸­æ¯ä¸ªä¾‹å­æ‰€è´¡çŒ®çš„ä»£ä»·çš„éƒ¨åˆ†ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œå€¼çº¦ä¸ºğ‘¤&#x3D;209å’Œğ‘&#x3D; 2.4æä¾›ä½ä»£ä»·ã€‚è¯·æ³¨æ„ï¼Œå› ä¸ºæˆ‘ä»¬çš„è®­ç»ƒç¤ºä¾‹ä¸åœ¨ä¸€æ¡çº¿ä¸Šï¼Œæ‰€ä»¥æœ€å°ä»£ä»·ä¸ä¸ºé›¶ã€‚</p>\n<h2 id=\"Convex-Cost-surface\"><a href=\"#Convex-Cost-surface\" class=\"headerlink\" title=\"Convex Cost surface\"></a>Convex Cost surface</h2><p>æˆæœ¬å‡½æ•°å¹³æ–¹æŸå¤±çš„äº‹å®ç¡®ä¿äº†â€œè¯¯å·®æ›²é¢â€åƒæ±¤ç¢—ä¸€æ ·å‡¸å‡ºã€‚å®ƒæ€»æ˜¯æœ‰ä¸€ä¸ªæœ€å°å€¼ï¼Œå¯ä»¥é€šè¿‡åœ¨æ‰€æœ‰ç»´åº¦ä¸Šè·Ÿéšæ¢¯åº¦æ¥è¾¾åˆ°ã€‚åœ¨å‰é¢çš„å›¾ä¸­ï¼Œå› ä¸ºğ‘¤å’Œğ‘å°ºå¯¸æ¯”ä¾‹ä¸åŒï¼Œè¿™æ˜¯ä¸å®¹æ˜“è¯†åˆ«çš„ã€‚ä¸‹å›¾ï¼Œå…¶ä¸­ğ‘¤å’Œğ‘éƒ½æ˜¯å¯¹ç§°çš„ï¼Œåœ¨è®²åº§ä¸­å±•ç¤ºè¿‡:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">soup_bowl()<br></code></pre></div></td></tr></table></figure>\n\n<h2 id=\"Congratulations\"><a href=\"#Congratulations\" class=\"headerlink\" title=\"Congratulations!\"></a>Congratulations!</h2><p>æ‚¨å·²ç»å­¦ä¹ äº†ä»¥ä¸‹å†…å®¹:</p>\n<ul>\n<li>æˆæœ¬æ–¹ç¨‹æä¾›äº†ä¸€ç§è¡¡é‡é¢„æµ‹ä¸è®­ç»ƒæ•°æ®åŒ¹é…ç¨‹åº¦çš„æ–¹æ³•ã€‚</li>\n<li>æœ€å°åŒ–æˆæœ¬å¯ä»¥æä¾›ğ‘¤å’Œbçš„æœ€ä¼˜å€¼ã€‚</li>\n</ul>\n<h2 id=\"å‚è€ƒèµ„æ–™\"><a href=\"#å‚è€ƒèµ„æ–™\" class=\"headerlink\" title=\"å‚è€ƒèµ„æ–™\"></a>å‚è€ƒèµ„æ–™</h2><p><a href=\"https://www.bilibili.com/video/BV1Pa411X76s?p=5&amp;vd_source=3ae32e36058f58c5b85935fca9b77797\">https://www.bilibili.com/video/BV1Pa411X76s?p=5&amp;vd_source=3ae32e36058f58c5b85935fca9b77797</a></p>\n<p><a href=\"https://github.com/kaieye/2022-Machine-Learning-Specialization\">kaieye&#x2F;2022-Machine-Learning-Specialization (github.com)</a></p>\n",
            "tags": [
                "Tensorflow",
                "Machine Learning"
            ]
        },
        {
            "id": "https://xingyuanjie.top/2023/03/06/ML001/",
            "url": "https://xingyuanjie.top/2023/03/06/ML001/",
            "title": "çº¿æ€§å›å½’æ¨¡å‹",
            "date_published": "2023-03-06T11:00:34.000Z",
            "content_html": "<h2 id=\"çº¿æ€§å›å½’æ¨¡å‹\"><a href=\"#çº¿æ€§å›å½’æ¨¡å‹\" class=\"headerlink\" title=\"çº¿æ€§å›å½’æ¨¡å‹\"></a>çº¿æ€§å›å½’æ¨¡å‹</h2><h3 id=\"MOdel-Representation\"><a href=\"#MOdel-Representation\" class=\"headerlink\" title=\"MOdel Representation\"></a>MOdel Representation</h3><p><img src=\"/2023/03/06/ML001/image-20230306195956356.png\" alt=\"image-20230306195956356\"></p>\n<h3 id=\"Goals\"><a href=\"#Goals\" class=\"headerlink\" title=\"Goals\"></a>Goals</h3><p>In this lab you will:</p>\n<ul>\n<li>learn to implement the model f_{w,b} for linear regression with one variable</li>\n</ul>\n<h3 id=\"Notation\"><a href=\"#Notation\" class=\"headerlink\" title=\"Notation\"></a>Notation</h3><p>Here is a summary of some of the notation you will encounter.</p>\n<p><img src=\"/2023/03/06/ML001/image-20230306200250050.png\" alt=\"image-20230306200250050\"></p>\n<h3 id=\"Tools\"><a href=\"#Tools\" class=\"headerlink\" title=\"Tools\"></a>Tools</h3><p>In this lab you will make use of:</p>\n<ul>\n<li><p>NumPy,a popular library for scientific computing</p>\n</li>\n<li><p>Matplotlib,a popular library for plotting data</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br>plt.style.use(<span class=\"hljs-string\">&#x27;./deeplearning.mpstyle&#x27;</span>)<br></code></pre></div></td></tr></table></figure></li>\n</ul>\n<h3 id=\"Problem-Statement\"><a href=\"#Problem-Statement\" class=\"headerlink\" title=\"Problem Statement\"></a>Problem Statement</h3><p><img src=\"/2023/03/06/ML001/image-20230306200642937.png\" alt=\"image-20230306200642937\"></p>\n<p>As in the lecture,you will use the motivating example of housing price prediction. This lab will use a simple data set with only two data points - a house with 1000 square feet(sqft) sold for $300,000 and a house with 2000 square feet sold for $500,000.These two points will constitute our data or training set. In this lab, the units of size are 1000 sqft and the units of price are 1000s of dollars.</p>\n<table>\n<thead>\n<tr>\n<th>Size (1000 sqft)</th>\n<th>Price (1000s of dollars)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1.0</td>\n<td>300</td>\n</tr>\n<tr>\n<td>2.0</td>\n<td>500</td>\n</tr>\n</tbody></table>\n<p>You would like to fit a linear regression model(shown above as the blue straight line)through these two points, so you can then predict price for other houses - say, a house with 1200 sqft.</p>\n<p>Please run the following code cell to create your x_train and y_train variables. The data is stored in one-dimensional NumPy arrays.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\">#x_train is the input variable (size in 1000 square feet)</span><br><span class=\"hljs-comment\">#y_train is the target (price in 1000s of dollars)</span><br>x_train = np.array([<span class=\"hljs-number\">1.0</span>,<span class=\"hljs-number\">2.0</span>])<br>y_train = np.array([<span class=\"hljs-number\">300.0</span>,<span class=\"hljs-number\">500.0</span>])<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;x_train = <span class=\"hljs-subst\">&#123;x_train&#125;</span>&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;y_train = <span class=\"hljs-subst\">&#123;y_train&#125;</span>&quot;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"Number-of-training-examples-m\"><a href=\"#Number-of-training-examples-m\" class=\"headerlink\" title=\"Number of training examples m\"></a>Number of training examples m</h3><p>you will use m to denote the number of training examples. Numpy arrays have a .shape parameter. x_train.shape return a python tuple with an entry for each dimension. x_train.shape[0] is the length of the array and number of examples as shown below.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># m is the number of training examples</span><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;x_train.shape: <span class=\"hljs-subst\">&#123;x_train.shape&#125;</span>&quot;</span>)<br>m = x_train.shape[<span class=\"hljs-number\">0</span>]<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;Number of training example is: <span class=\"hljs-subst\">&#123;m&#125;</span>&quot;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<p>x.train.shape: (2,)</p>\n<p>Number of training examples is: 2</p>\n<p><strong>One can also use the Python len() function as shown below.</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># m is the number of training examples</span><br>m = <span class=\"hljs-built_in\">len</span>(x_train)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;Number of training example is: <span class=\"hljs-subst\">&#123;m&#125;</span>&quot;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<p>Number of training examples  is:\t2</p>\n<h3 id=\"Training-example-x-i-y-i\"><a href=\"#Training-example-x-i-y-i\" class=\"headerlink\" title=\"Training example x_i, y_i\"></a>Training example x_i, y_i</h3><p>You will use (x(ğ‘–), y(ğ‘–)) to denote the ğ‘–(th) training example. Since Python is zero indexed, (x(0), y(0) is (1.0, 300.0) and (x(1), y(1) is (2.0, 500.0).</p>\n<p>To access a value in a Numpy array, one indexes the array with the desired offset. For example the syntax to access location zero of x_train is x_train[0]. Run the next code block below to get the i(th) training example.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">i = <span class=\"hljs-number\">0</span> <span class=\"hljs-comment\">#Change this to 1 to see (x^1,y^1)</span><br><br>x_i = x_train[i]<br>y_i = y_train[i]<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;(x^(<span class=\"hljs-subst\">&#123;i&#125;</span>), y^(<span class=\"hljs-subst\">&#123;i&#125;</span>)) = (<span class=\"hljs-subst\">&#123;x_i&#125;</span>, <span class=\"hljs-subst\">&#123;y_i&#125;</span>)&quot;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">(x^(<span class=\"hljs-number\">0</span>), y^(<span class=\"hljs-number\">0</span>)) = (<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">300.0</span>)<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"Plotting-the-data\"><a href=\"#Plotting-the-data\" class=\"headerlink\" title=\"Plotting the data\"></a>Plotting the data</h3><p>You can plot these two points using the scatter() function is the matplotlib library,as shown in the cell below.</p>\n<ul>\n<li>The function arguments marker and c show the points as red crosses(the default is blue dots.)</li>\n</ul>\n<p>You can use other functions in the matplotlib library to set title and labels to display.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\">#Plot the data points</span><br>plt.scatter(x_train, y_train, marker=<span class=\"hljs-string\">&#x27;x&#x27;</span> c=<span class=\"hljs-string\">&#x27;r&#x27;</span>)<br><span class=\"hljs-comment\">#Set the title</span><br>plt.title(<span class=\"hljs-string\">&quot;Housing Prices&quot;</span>)<br><span class=\"hljs-comment\">#Set the y-axis label</span><br>plt.ylabel(<span class=\"hljs-string\">&#x27;Price (in 1000s of dollars)&#x27;</span>)<br><span class=\"hljs-comment\">#Set the x-axis lbel</span><br>plt.xlabel(<span class=\"hljs-string\">&#x27;Size (1000 sqft)&#x27;</span>)<br>plt.show()<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/06/ML001/image-20230306204822102.png\" alt=\"image-20230306204822102\"></p>\n<h3 id=\"Model-function\"><a href=\"#Model-function\" class=\"headerlink\" title=\"Model function\"></a>Model function</h3><p><img src=\"/2023/03/06/ML001/image-20230306204918585.png\" alt=\"image-20230306204918585\"></p>\n<p>As described in lecture, the model function for linear regression (which is a function that maps from x to y)is represented as</p>\n<p><img src=\"/2023/03/06/ML001/image-20230306205107527.png\" alt=\"image-20230306205107527\"></p>\n<p>The formula above is how you can represent straight lines - different values of w and b give you different straight lines on the plot.</p>\n<p>Letâ€™s try to get a better intuition for this through the code blocks below. Letâ€™s start with w &#x3D; 100 and b &#x3D;100.</p>\n<p>Note: You can come back to this cell to adjust the modelâ€™s w and b parameters.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">w = <span class=\"hljs-number\">100</span><br>b = <span class=\"hljs-number\">100</span><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;w: <span class=\"hljs-subst\">&#123;w&#125;</span>&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;b: <span class=\"hljs-subst\">&#123;b&#125;</span>&quot;</span>)<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">w:\t<span class=\"hljs-number\">100</span><br>b:\t<span class=\"hljs-number\">100</span><br></code></pre></div></td></tr></table></figure>\n\n<p>Now,letâ€™s compute the value of f_{w,b}(x^i) for your two data points. You can explicitly write this out for each data poins as -</p>\n<p>for x(0),f_wb &#x3D; w * x[0] + b</p>\n<p>for x(1),f_wb &#x3D; w * x[1] + b</p>\n<p>For a large number of data points, this can get unwieldy and repetitive. So instead, you can calculate the function output in a for loop as shown in the compute_model_output function below.</p>\n<p>Note:The argument description (ndarray (m,)) describes a Numpy n-dimensional array of shape (m,). (scalar) describes an argument without dimensions, just a magnitude.</p>\n<p>Note: np.zero(n) will return a one-dimensional numpy array with n entries</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">compute_model_output</span>(<span class=\"hljs-params\">x, w, b</span>):</span><br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    Computes the prediction of a linear model</span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">    \tx (ndarray (m,)):Data, m examples</span><br><span class=\"hljs-string\">    \tw,b (scalar)\t:model parameters</span><br><span class=\"hljs-string\">    Returns</span><br><span class=\"hljs-string\">    \ty (ndarray (m,)):target values</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <br>    m = x.shape[<span class=\"hljs-number\">0</span>]<br>    f_wb = np.zeros(m)<br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(m)<br>    \tf_wb[i] = w * x[i] + b<br>    <br>    <span class=\"hljs-keyword\">return</span> f_wb<br></code></pre></div></td></tr></table></figure>\n\n<p>Now letâ€™s call the compute_model_output function and plot the output.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">tmp_f_wb = compute_model_output(x_train, w, b,)<br><br><span class=\"hljs-comment\">#Plot our model prediction</span><br>plt.plot(x_train, tmp_f_wb, c=<span class=\"hljs-string\">&#x27;b&#x27;</span>,label=<span class=\"hljs-string\">&#x27;Our Prediction&#x27;</span>)<br><br><span class=\"hljs-comment\">#Plot the data points</span><br>plt.scatter(x_train, y_train, marker=<span class=\"hljs-string\">&#x27;x&#x27;</span>, c=<span class=\"hljs-string\">&#x27;r&#x27;</span>,label=<span class=\"hljs-string\">&#x27;Actual Values&#x27;</span>)<br><br><span class=\"hljs-comment\">#Set the title</span><br>plt.title(<span class=\"hljs-string\">&quot;Housing Prices&quot;</span>)<br><span class=\"hljs-comment\">#Set the y-axis label</span><br>plt.ylabel(<span class=\"hljs-string\">&#x27;Price (in 1000s of dollars)&#x27;</span>)<br><span class=\"hljs-comment\">#Set the x-axis label</span><br>plt.xlabel(<span class=\"hljs-string\">&#x27;Size (1000 sqft)&#x27;</span>)<br>plt.legend()<br>plt.show()<br></code></pre></div></td></tr></table></figure>\n\n<p><img src=\"/2023/03/06/ML001/image-20230306211337338.png\" alt=\"image-20230306211337338\"></p>\n<p>As you can see, setting w &#x3D; 100 and b &#x3D; 100 does not result in a line that fits our data.</p>\n<h3 id=\"Challenge\"><a href=\"#Challenge\" class=\"headerlink\" title=\"Challenge\"></a>Challenge</h3><p>Try experimenting with different values of w and b. What should the values be for a line that fits our data?</p>\n<p><strong>Tips:</strong></p>\n<p>You can use  your mouse to click on the triangle to the left of the green â€œHintsâ€ below to reveal some hints for choosing b and w.</p>\n<p><strong>Hints</strong></p>\n<h3 id=\"Prediction\"><a href=\"#Prediction\" class=\"headerlink\" title=\"Prediction\"></a>Prediction</h3><p>Now that we have a model, we can use it to make our original prediction. Letâ€™s predict the price of a house with 1200 sqft. Since the units of x are in 1000â€™s of sqft, x is 1.2.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">w = <span class=\"hljs-number\">200</span><br>b = <span class=\"hljs-number\">100</span><br>x_i = <span class=\"hljs-number\">1.2</span><br>cost_1200sqft = w * x_i + b<br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;$<span class=\"hljs-subst\">&#123;cost_1200sqft:<span class=\"hljs-number\">.0</span>f&#125;</span> thousand dollars&quot;</span> )<br></code></pre></div></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs python\">$<span class=\"hljs-number\">340</span> thousand dollars<br></code></pre></div></td></tr></table></figure>\n\n<h3 id=\"Congratulations\"><a href=\"#Congratulations\" class=\"headerlink\" title=\"Congratulations!\"></a>Congratulations!</h3><p>In this lab you have learned:</p>\n<ul>\n<li>Linear regression bulids a model which establishes a relationship between features and targets</li>\n<li>In the example above, the feature was house size and the target was house price</li>\n<li>for simple linear regression, the model has two parameters w and b whose calue are â€˜fitâ€™ using training data.</li>\n<li>once a modelâ€™s parameters have been determined, the model can be used to make predictions on novel data.</li>\n</ul>\n<h2 id=\"å‚è€ƒèµ„æ–™\"><a href=\"#å‚è€ƒèµ„æ–™\" class=\"headerlink\" title=\"å‚è€ƒèµ„æ–™\"></a>å‚è€ƒèµ„æ–™</h2><p><a href=\"https://www.bilibili.com/video/BV1Pa411X76s?p=5&amp;vd_source=3ae32e36058f58c5b85935fca9b77797\">https://www.bilibili.com/video/BV1Pa411X76s?p=5&amp;vd_source=3ae32e36058f58c5b85935fca9b77797</a></p>\n<p><a href=\"https://github.com/kaieye/2022-Machine-Learning-Specialization\">kaieye&#x2F;2022-Machine-Learning-Specialization (github.com)</a></p>\n",
            "tags": [
                "Tensorflow",
                "Machine Learning"
            ]
        }
    ]
}